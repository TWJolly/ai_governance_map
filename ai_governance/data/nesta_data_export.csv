name,sector,categories,tags,scope,date,resources,description,countries,actors
Policy on the Use of AI in the Healthcare Sector,Health,Policy,"Transparency; safety, privacy; accountability;",National,4/1/2018 0:00,"<a target=""_blank"" href=""https://www.haad.ae/HAAD/LinkClick.aspx?fileticket=C5W0f0QCVto%3d&tabid=1276"">Policy text</a>","The policy was issued by the Department of Health (DOH), which is the regulatory body of the health system in the Emirate of Abu Dhabi. Recognising the central role AI can play across the healthcare sector and seeking to capitalise on the benefits to be gained from its use the DOH supports and encourages the development, use and adoption of customized AI technologies and software for healthcare in Abu Dhabi, while seeking to minimize its risks.<br>The policy opens with a definition of key terms, including that of ‘graceful degradation’, which plays an important role in the policy and is understood as “the ability of a computer, machine, electronic system or network to maintain limited functionality even when a large portion of it has been destroyed or rendered inoperative.”<br>The purpose of the policy is to outline the Emirates’ vision for AI in healthcare and to outline key roles and responsibilities of stakeholders. The policy applies to licensed healthcare providers, pharmaceutical manufacturers, health insurers, healthcare researchers, as well as anyone who uses Abu Dhabi-based population or patient clinical or non-clinical data in an AI endeavour.<br>The policy sets out 6 key principles:<br>[ul]<br><li>Transparency: verifiable and explainable AI to ascertain the reasons of any system failures.</li><br><li>User Assistance / Supportive technology: AI should assist users in making intelligent decisions.</li><br><li>Safety and Security: Robust and dependable AI is essential to ensure it doesn’t harm the lives or bodies of users or third parties.</li><br><li>Privacy: AIs should not infringe the privacy rights of users or third parties.</li><br><li>Ethics: human dignity and individual autonomy should be respected in AI R&D.</li><br><li>Accountability: researchers and developers need to be accountable to users and other stakeholders, disclosing relevant information and maintaining adequate communications with stakeholders.</li><br>[/ul]<br>DOH is committed to maximising the benefits and minimising the risks of AI. In order to achieve this, it will create a regulatory framework building on its 6 key principles. <br>The policy also formulates a set minimum acceptable requirements against healthcare AI applications. These include the requirement of AI systems to be robust and responsive evidenced by certification from international agencies, compliance with Abu Dhabi Smart Solutions & Services Authority regulations, and auditable validation statements. AI tools must also have mechanisms for graceful degradation built-in, and should be continuously updated and improved on the basis of user feedback. Systems should also be subjected to audits but the criteria for such audits are not outlined. AI tools must also comply with Health Information Exchange Policy (HIEP) regulations, which includes privacy and transparency requirements. However, the HIEP has only one provision on transparency, establishing it as a guiding principle and calling for broad stakeholder engagement. <br>The policy sets out requirements for non-patient users/providers of AI services as well, including the requirement of guidelines about access to and use of patient information, adequate education on AI tools, reporting of audits to DOH, compliance with all regulatory requirements, and the submission of end-user feedback to DOH. <br>A monitoring and evaluation framework on the effectiveness of AI in healthcare is to be developed, focusing on inputs, activities, outputs and outcomes.",United Arab Emirates,Abu Dhabi Department of Health
Artificial Intelligence Mission Austria 2030 (AIM AT 2030),AI in general,Strategy,accountability,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.bmvit.gv.at/innovation/publikationen/ikt/downloads/aimat_ua.pdf"">Austrian AI Strategy</a><br><a target=""_blank"" href=""https://www.digitalroadmap.gv.at/en/"">Austrian Digital Roadmap</a>","In November 2018 two Austrian ministers called on the Council of Ministers to support the development of a national AI strategy. The Council of Ministers voted in favour of the proposal, which would also support the realisation of the aims outlined in the Austrian Digital Roadmap, presented in January 2017. The roadmap laid out a comprehensive vision of digital modernisation until 2025 mentioning the need to consider the ethical and regulatory questions surrounding AI. <br><br>The proposal frames the need for a national strategy as a matter of preserving the country’s “digital sovereignty”, and as a way of capitalising on the opportunities, while avoiding the risks and unforeseen consequences of broad AI adoption. The working title of the strategy is Artificial Intelligence Mission Austria 2030 (AIM AT 2030) and it is meant to establish the conditions for responsible AI in the service of prosperity. The strategy should be developed in close cooperation with the Council on Robotics and AI, involving a broad range of societal stakeholders, and paying due attention to the principle of subsidiarity. The call highlights both the economic benefits that AI might bring about as well as its disruptive effects on the job market, its potential to threaten democratic processes and to influence public opinion through automated and targeted disinformation campaigns. <br><br>The proposal also formulates suggestions for what the aims of the strategy should be. It reiterates the importance of achieving digital sovereignty and independence from global monopolies through the application of AI for the public good, informed by core European values, like human dignity, respect for privacy and equality. It should support the development of measures to quickly respond to risks and negative developments, as well as inform the creation of a legal framework in accordance with European requirements. The strategy should help elevate AI R&D in a few niche areas and in basic science to a world class level, and support the country’s global competitiveness in terms of innovation, supporting SMEs in particular. The strategy should also address public engagement measures and the application of AI in the domains of medicine, national security, policing and government services.<br><br>The proposal advised the creation of 7 working groups, with representatives from the relevant ministries, government agencies, academic, industrial and civil society stakeholders. The 7 working groups are:<br><br>[ul]<br><li>Research and Innovation <em>(Federal Ministry of Transportation, Innovation and Technology)</em></li><br><li>AI in the public sector <em>(Federal Ministry of Digital and Economic Affairs)</em></li><br><li>AI for the industry and the economy <em>(Federal Ministry of Digital and Economic Affairs)</em></li><br><li>Society, ethics and the labour market <em>(Federal Ministry of Digital and Economic Affairs)</em></li><br><li>Infrastructure for industrial leadership <em>(Federal Ministry of Labour, Social Affairs, Health and Consumer Protection)</em></li><br><li>AI governance, security and the law <em>(Federal Ministry of Digital and Economic Affairs)</em></li><br><li>Qualifications and education <em>(Federal Ministry of Education)</em></li><br>[/ul]<br><br>The Federal Ministry of Transportation, Innovation and Technology and the Federal Ministry of Digital and Economic Affairs, which led the proposal, also produced a short document surveying the state-of-the-art in AI technology development, describing the main ethical issues and providing an overview of the state of the AI industry in Austria. The overview expressed a commitment to a humane and socially acceptable development of artificial intelligence, calling for the proactive engagement of the whole of society.",Austria,"Austrian Federal Ministry of Transportation, Innovation and Technology ; Austrian Federal Ministry of Digital and Economic Affairs"
Austrian Council on Robotics and AI,AI in general,Advisory body,,National,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.acrai.at/en/"">Austrian Council on Robotics & AI</a>","The Austrian Council on Robotics and Artificial Intelligence is set up by the Federal Ministry for Transport, Innovation and Technology, whose recommendations are available to all Austrians. It consists of experts on Robotics and Artificial Intelligence from research, teaching and industry and identifies and discusses current and future opportunities, risks and challenges arising from the use of Robotics and Autonomous Systems (RAS) and Artificial Intelligence (AI).",Austria,"Federal Ministry on Transport, Innovation and Technology"
Regulation on Autonomous Driving,Autonomous mobility,Regulation,,National,12/1/2016 0:00,"<a target=""_blank"" href=""http://www.austriatech.at/files/get/a8d601dc11a94cd3d431b68c4f846dbe/bgbla_2016_ii_402.pdf"">Regulation text [German]</a>","The regulation specifies different rules for 3 specific cases of autonomous driving, namely, an autonomous minibus, vehicles equipped with highway cruise control and lane change, and autonomous army vehicles. <br>An autonomous minibus must have a maximum of 8 seats in addition to the driver and may only use autonomous driving features at a maximum speed of 20km/h. It may only be tested on public roads when 1000 kilometers of prior testing had already been completed. Testing may not be done on a commercial basis. In the event of a critical situation the driver must regain control of the vehicle. <br>Vehicles with autonomous highway cruise control and lange change may be tested on public roads after 10 000 kms of prior testing. The vehicle may perform longitudinal guidance of the vehicle, such as accelerating, braking, stopping, and distance control, as well as transverse guidance of the vehicle, such as holding lane, changing lane, and overtaking. In the event of a critical situation the driver must regain control of the vehicle and before leaving the highway the human driver must regain full control. <br>In the case of army vehicles, the vehicle must be able to accomplish all driving tasks autonomously or by teleoperation. It may only be tested on public roads by the Ministry of Defense, following 300 kms of prior testing. Such testing may include autonomous driving, teleoperated driving, and platooning. This is the only vehicle type which may be tested on any type of road. <br>Regardless of the type of vehicle, their use is only allowed if they have been approved, they are in serial production, and are used only for the purposes of testing. The vehicles must also comply with existing regulations on road traffic, air pollution, and railroad crossing.<br>Vehicles with assistance or autonomous driving features may only be tested on public roads with the appropriate insurance, evidence of which must carried in the vehicle. In addition, the Federal Ministry for Transport, Innovation and Technology must receive certain information, such as the type of autonomous use case, details about the organisation performing testing, as well as the driver in the vehicle during testing, the number of real, virtual or experimental test kilometers to date with the system to be tested, and information about the duration and location of testing. <br>Public road testing may only be conducted if sufficient previous tests have been done. This must be evidenced to the Ministry, which issues a permit, which must be carried in the vehicle at all times. At the end of the test period the Ministry must be informed about the learning derived from tests, especially about any accidents, failures or critical situations.<br>Furthermore, a suitably qualified driver must always be present behind the wheel, who may hand over certain tasks to the autonomous system but they remain responsible for regaining control whenever necessary. The driver must also consent to the collection of data about the vehicle’s control system. <br>Vehicles equipped with assistance systems or automated or networked driving systems that are not authorized for traffic may be equipped with a test-drive number plate and be allowed on public roads. <br>Vehicles must be equipped with an accident data capture system, which must be operational during testing. This may only capture data about the electronic control system of the car and the data must not be alterable. The data may only be used for the purposes of the test and to reconstruct critical situations or accidents. Data about accidents, including recordings from a 30 second timespan preceding and following the event must be provided to authorities at their request. <br>In case video data is also to be captured during a test, this must be approved by the Data Protection Authority and all recordings of number plates and persons must be made unrecognizable.",Austria,"Federal Ministry for Transport, Innovation and Technology"
Positively Shaping the Future of Austria with Robotics and AI,AI in general,White paper,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.acrai.at/images/download/ACRAI_whitebook_online_2018.pdf"">White paper</a>","The Council published its White Paper in November 2018, at the same time when two ministries called on the Federal Government to develop an Austrian national strategy. This document offered key principles and ‘cornerstones’ for the development of such a strategy. It identified 4 fields of action and 3 cornerstones.<br>The fields of action are Technology, R&D and the economy; Workplace and qualification; Society and law; Awareness raising, communication and public relations.<br>The 3 cornerstones are Smart Governance; Smart Innovation; and Smart Regulation.<br>Under Smart Governance, the Council recommends that the Austrian national strategy should be developed in an iterative manner, building on institutionalized learning processes and feedback loops as well as on a continuous monitoring of AI R&D, and with broad involvement of citizens and stakeholders from affected fields. Further, the Council recommends strong networking with strategic EU initiatives and cites the Montreal Declaration on Responsible AI as an inspiring model. <br>In relation to Smart Innovation the Council recommends significant investment in AI technologies and the necessary infrastructure, as well as targeted measures for the training of professionals and the retraining of employees. Furthermore, a distinction should be introduced between unproblematic and sensitive areas of AI applications. “For sensitive application areas with high risk and unclear technology assessment, ""sandboxes"" and ""testbeds"" should be set up, which enable rapid learning, for all involved stakeholders (research and development, business and politics), and rapid knowledge transfer.” Innovation policy should build on the experiences derived from the various use cases, and incorporate feedback loops and procedures for reflection.<br>Finally, under Smart Regulation, the Council recommends reviewing the existing ethical and legal framework and creating new rules and standards as necessary. This work should be undertaken in close coordination with the activities and decisions of the European Commission. Certification and auditing tools for robotics and AI technologies should be developed as well.",Austria,Austrian Council on Robotics and AI
Declaration of Amsterdam,Autonomous mobility,International agreement,Legal harmonization; interoperability;,International - EU,4/1/2018 0:00,"<a href=""https://www.regjeringen.no/contentassets/ba7ab6e2a0e14e39baa77f5b76f59d14/2016-04-08-declaration-of-amsterdam---final1400661.pdf"" target=_blank>Declaration of Amsterdam</a>","The Amsterdam Declaration was signed in April 2016 by 28 European Member States. The objectives of the declaration are to work towards:<br>[ul]<br><li>“a coherent European framework for the deployment of interoperable connected and automated driving, which should be available, if possible, by 2019; </li><br><li>to bring together developments of connected and automated driving in order to reach their full potential to improve road safety, human health, traffic flows, and to reduce the environmental impact of road transport; </li><br><li>to adopt a “learning by experience” approach, including, where possible, cross-border cooperation, sharing and expanding knowledge on connected and automated driving and to develop practical guidelines to ensure interoperability of systems and services;</li><br><li>to support further innovation in connected and automated vehicle technologies to strengthen the global market position of European industry; and to ensure data protection and privacy.” </li><br>[/ul]<br>The parties agree to develop a joint agenda that would include several key elements, such as coherent international, European and national rules (legal harmonisation), clarification about the availability of data for private and public uses, while ensuring privacy and data protection. In addition, the joint agenda would address vehicle-to-vehicle and vehicle-to-infrastructure communication to ensure that new services and systems are compatible and interoperable at European level and to coordinate investments towards reliable communication coverage. In relation to security, the development common trust models and certification policies is put forward. Further, the agenda should formulate steps to manage societal expectations, to raise awareness and increase acceptance and appreciation of connected and automated vehicle technologies; develop common definitions of connected and automated driving systems based on SAE levels as a starting point and develop and maintain close cooperation with other regions, particularly the US and Japan, to work towards a global framework and international standards. <br>Concrete actions for Member States, the EU Commission and industry have also been identified. <br>Member states should work to adapt national regulations by identifying and removing legal barriers to testing and deployment of AVs. Member states were also encouraged to exchange best practices, especially around the testing of AVs under various circumstances. Updating the Vienna and Geneva Conventions on Road Traffic will be an essential step going forward.<br>According to the Declaration, the European Commission should review and adapt the EU regulatory framework, and capitalise on a joint learning process. The Join Agenda also advocated the development of a coordinated effort towards research and innovation in the field of AVs.<br>The Declaration invited industry actors to participate in the development of the EU strategy and to help identify barriers to development, as well as to continue working on V2V and V2I systems and standards.",European Union,EU Member States
Coalition on Artificial Intelligence,AI in general,Network ; Strategy,,National,10/1/2018 0:00,"<a target=""_blank"" href=""https://digitalisjoletprogram.hu/hu/tartalom/mesterseges-intelligencia-koalicio"">Digital Welfare Programme website [Hungarian]</a>","The Coalition on AI was launched by the Hungarian Ministry for Innovation and Technology in October 2018. The Coalition’s activities unfold under the Government’s Digital Welfare Programme, which was launched in 2015 and is meant to allow Hungarian citizens and businesses to reap the benefits of digitization. The Coalition is envisioned as a long-term forum for AI developers, government and market users, academic and professional stakeholders to collectively define the course and framework for AI development and use in Hungary. <br> <br>The aim of the Coalition is to position Hungary among the European leaders of AI development and applications; to strengthen Hungarian competitiveness through AI adoption; to support Hungarian startups and SMEs undertake AI development, and to support their partnerships with academic and industry players locally and internationally; and to support the development of the Hungarian economy and society through a considered, fair and regulated use of data-assets both by government and all other actors of the digital ecosystem.<br> <br>The Coalition will provide a platform to discuss broad ranging issues and create consensus, while the Government will seek to expedite the process of lawmaking in the area. The Coalition is comprised of 140 partner organisations, including representatives of several Government Ministries, universities, local and multinational corporations, banks, SMEs and some civil society organisations. The Coalition has formed 6 working groups:<br> <br>[ul]<br><li>AI strategy</li><br><li>Technology and security</li><br><li>Data-industry and data-assets</li><br><li>Regulation and ethics</li><br><li>Applications and market development</li><br><li>Education and public engagement</li><br>[/ul]<br> <br>The national AI strategy is due to be completed by the end of 2019.",Hungary,Ministry for Innovation and Technology
Committee for Standardisation in AI,AI in general,Standardisation,Certification,National,3/1/2018 0:00,"<a target=""_blank"" href=""https://www.iitp.ac.in/index.php/latest-news/3248-ai-standardization-meeting-at-iitp-15th-november.html"">News coverage announcing the Committee</a>","The Bureau of Indian Standards set up a Committee for Standardisation in AI. The Committee includes ABB,BOSCH, NASSCOM, TCS, IIT Delhi, DSF, IIT Kanpur, NITI Aayog, Mahindra,IIT Patna and Intel. The Committee is working on a Road Map for standardisation and works in collaboration with international efforts under ISO. The work is meant to address certification methodologies, trustworthiness and Foundational AI standards.",India,Bureau of Indian Standards
Personal Data Protection Bill,Data protection,Proposed law,Data privacy; transparency; right to be forgotten; automated decision-making,National,9/1/2018 0:00,"<a target=""_blank"" href=""http://meity.gov.in/data-protection-framework"">Bill text</a><br><a target=""_blank"" href=""http://www.digitaleurope.org/DesktopModules/Bring2mind/DMX/Download.aspx?Command=Core_Download&entryID=2742&language=en-US&PortalId=0&TabId=353"">Digital Europe analysis</a><br><a target=""_blank"" href=""https://www.cfr.org/blog/three-problems-indias-draft-data-protection-bill"">Council on Foreign Relations analysis</a>","The draft bill proposes a complex new legal framework for data protection that is similar to the European GDPR. <br><br>The bill will apply to every organization (State, companies, individuals) that processes personal data, and extends to entities offering goods or services in India and those who profile Indian individuals. It defines personal data as “any data that allows an individual to be directly or indirectly identified.” According to the bill, data processing must be based on consent, obtained no later than at the commencement of data processing, and this consent must be free, informed, specific, clear, and capable of being withdrawn. The bill grants data subjects (principals) similar rights as the GDPR: right to access, correction, data portability and the right to be forgotten. However, the right to be forgotten is not erasure, rather, prevention or restriction of disclosure of personal data by a fiduciary. Unlike the GDPR, which allows data subjects to object to decisions made solely on the basis of automated processing, the Indian bill doesn’t have such a provision. <br><br>Data protection obligations include fair and reasonable processing, purpose limitation, collection limitation, lawful processing, notice, data quality, data storage limitation, and accountability. The bill also establishes a Data Protection Authority (DPA), with members appointed by the Central Government.<br><br>The bill calls for several transparency and accountability measures. <br><br>First and foremost, every data fiduciary must implement Privacy by Design policies extending to managerial, organisational, business practices and technical systems to anticipate, identify and avoid harm. Business interests should be pursued without compromising privacy interests and data processing should be carried out in a transparent manner. <br><br>Moreover, a record of data processing must be kept, and there is an obligation to run data protection impact assessments, annual audit of policies and conduct. The impact assessment is mandated when a data fiduciary undertakes large-scale profiling or uses sensitive personal data, such as biometric data. Such an impact assessment must at minimum include a detailed description of the proposed processing and its purpose, as well as the data to be used; an assessment of the potential harm to data principals; and measures for managing or removing the risk of such harms occurring. The Data Protection Authority will review these assessments and set further conditions or direct the fiduciary to stop its  relevant activities. Organizations involved in such high-risk processing are considered “significant data fiduciaries” and will need to appoint a data protection officer (“DPO”). Organizations not present in India who are under the scope of the Bill will need to appoint a DPO who is based in India.<br><br>The data localization requirements mandate that copies of recorded data must be stored on Indian servers. In addition, the government defines certain ‘critical’ types of data, which may only be processed on Indian servers.",India,Ministry of Electronics & Information Technology
Task Force on Artificial Intelligence,AI in general,Task force,Transparency; Safety; Labour market; Bias;,National,8/1/2017 0:00,"<a target=""_blank"" href=""http://dipp.nic.in/sites/default/files/Report_of_Task_Force_on_ArtificialIntelligence_20March2018_2.pdf"">Task force report</a><br><a target=""_blank"" href=""https://cis-india.org/internet-governance/blog/the-ai-task-force-report-the-first-steps-towards-indias-ai-framework"">Centre for Internet and Society analysis</a>","The Task Force was set up in August 2017 to provide recommendations on how to leverage AI for India’s economic benefit, to advise on the creation of policy and a legal framework to accelerate deployment of AI technologies and to craft concrete 5-year horizon recommendations for specific government, industry and research programs.<br>The Task Force had 18 members comprised of AI entrepreneurs, scientists and government officials. It formulated 6 concrete suggestions for the next 5 years:<br><ol><br><li>Establish an Inter-Ministerial National Artificial Intelligence Mission to:<br>[ul]<br><li>create and seed fund 6 centres of excellence </li><br><li>set up a generic AI test bed to serve as a validation platform for AI developers</li><br><li>set up an interdisciplinary data centre to aggregate and interpret the generated data</li><br><li>coordinate with relevant ministries to accelerate AI commercialization</li><br><li>raise awareness of AU through talent competitions</li><br><li>conduct surveys for data collection</li><br><li>Manage challenge funds</li><br>[/ul]<br></li><br><li>Create data banks, marketplaces and exchanges for cross-industry data availability for AI applications and craft the appropriate data sharing regulations</li><br><li>Create standards for the design and development of AI systems</li><br><li>Put in place measures to boost AI development, including data sharing policies and tax incentives</li><br><li>Support the creation of AI-based curricula, education, re-skilling</li><br><li>Leverage international relationships and participate in international standard setting activities</li><br></ol><br>The report has a brief section on the responsible use of AI, which highlights the need for AI systems to be explainable, engineered for safety and rigorously audited to exclude human biases and prejudices. According to the Task Force, legal provisions applying to natural or legal persons as users of AI should apply mutatis mutandis to machines, however, it acknowledges that specific liability provisions will have to be worked out. It should also be transparent to users whenever they are dealing with an AI system, and the performance of such systems must be auditable, and test and evaluation data should be shared with users. The Task Force calls on AI researchers to have their proposals evaluated by independent ethics panels, but no similar requirement is raised in relation to commercial or government AI projects. The Task Force calls for new standards on robotics to be developed and states that complete autonomy should not be given to weapons systems. The Government should supper interdisciplinary work on AI-human interaction to plan for various scenarios and create appropriate transition plans to deal with possible scenarios.",India,The Ministry of Commerce and Industry
Data Broker Accountability and Transparency Act of 2018 (H.R. 6548),Data protection,Proposed law,Privacy;,National,9/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/house-bill/6548/text"">Data broker accountability act</a>","Several similar bills have been introduced in the House and the Senate in previous years. <br>The 2018 Act recognises that “processing of personal information by data brokers and the commercial clients of data brokers affects economic marketplace opportunities available to individuals.” In addition, processing by the Federal Government and state agencies may affect an individual’s ability to travel, work, obtain government benefits, and receive government services. Existing laws don’t provide sufficient privacy or due process rights, as individuals don’t always have access to or can seek correction of personal information maintained about them by data brokers.<br>A data broker is defined as a “commercial entity that collects, assembles, or maintains personal information concerning an individual who is not a customer or an employee of that entity in order to sell the information or provide third party access to the information.” <br>The bill requires data brokers to establish procedures to ensure the accuracy of collected personal information and prohibits obtaining or soliciting personal information by false pretenses. Data brokers shall also provide an individual a means to review any personal information, or other information that specifically identifies that individual, that the covered data broker collects, assembles, or maintains on that individual.",USA,US House of Representatives
Software Pre-Certification Pilot,Health,Pilot ; Regulation,Data quality; Safety;,National,7/1/2017 0:00,"<a target=""_blank"" href=""https://www.fda.gov/MedicalDevices/DigitalHealth/DigitalHealthPreCertProgram/default.htm"">FDA Pre-Cert Pilot</a><br><a target=""_blank"" href=""https://www.warren.senate.gov/imo/media/doc/2018.10.10%20Letter%20to%20FDA%20on%20regulation%20of%20sofware%20as%20medical%20device.pdf"">Senator's open letter</a>","The Software Pre-certification Programme is an initiative of the US Food and Drug Administration.<br>In order to implement the US Congress’ 21st Century Cures Act of 2016, which sought to streamline the drug and medical device approval process, the FDA’s Center for Devices and Radiological Health (CDRH) created a Digital Health Innovation Action Plan. The Plan issued guidance on the implementation of the legislation and included the launch of a pilot software precertification program to develop a new approach to digital health technology oversight. The work also builds on the FDA’s work since 2010 developing guidance in relation to mobile medical apps and working with software manufacturers.<br>The pilot Pre-Cert program explores a potential voluntary pathway to assess the safety and effectiveness of certain Software as a Medical Device (SaMD) products by focusing on the manufacturer/developer, rather than primarily the product. Companies that undergo the assessment may receive pre-certified status, based on their demonstrated robust culture of quality and organizational excellence, as well as the commitment to monitoring the real-world performance of their products. As a result, pre-certified companies would have a less burdensome route to market. This is a new approach compared to FDA’s standard method of individual product reviews and is meant to test the use of real-world evidence in evaluating the safety and effectiveness of new products.<br>One of the key challenges for regulation in this domain is that devices based on machine learning are not static but change over time, which calls for a new approach to the evaluation of safety and efficacy. The pilot is meant to inform the creation of a modern, flexible, risk-based approach to the regulation of quickly evolving digital health technologies, thereby reducing time and cost to market entry. It is an attempt at an innovation-enabling approach that still maintains the Agency’s scientific gold standard and ensures patient safeguards.<br>In September 2017 nine companies out of over 100 applicants were selected to participate in the development of the pilot program: Apple, Fitbit, Johnson & Johnson, Pear Therapeutics, Phosphorus, Roche, Samsung, Tidepool, and Verily.<br>The program is being developed iteratively as mechanisms to measure real-world performance and risk-benefit benchmarks are established, and the FDA periodically releases its working draft of the pilot for public commentary. While Pre-Cert 1.0, the first version of the program is limited to manufacturers of SaMD, FDA will later offer the voluntary program to manufacturers of software in a medical device (SiMD), and other software that could be considered accessories to hardware medical devices. <br>A test plan for running the pilot in 2019 with [font=""Helvetica Neue"", Helvetica, Arial, sans-serif]certain SaMD De Novo Requests has been released.",USA,Food and Drug Administration
FUTURE of AI Act of 2017 (HR 4625 / S 2217),AI in general,Proposed law,Bias; accountability; labour market effects; data sharing; ethics training;,National,12/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/house-bill/4625/text"">House of Representative bill</a><br><a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/senate-bill/2217/text"">Senate bill</a>","The Act, simultaneously introduced in the House and the Senate, would direct the Department of Commerce to establish a Federal Advisory Committee (FAC) to advise the Secretary on topics related to the development of artificial intelligence, to study various aspects of it, and to report administrative and legislative recommendations back to the Secretary eighteen months after enactment of the Act. <br>The purpose of the Committee is threefold.<br>First, to advise the Secretary on matters relating to the development of artificial general intelligence and narrow artificial intelligence. Specifically, the Committee should advise on AI as it relates to:<br>[ul]<br><li>US competitiveness and public and private investment, </li><br><li>The workforce and the use of AI for worker retraining due to technological unemployment, </li><br><li>Education, including STEM and the need to meet the changing needs of employers,</li><br><li>Ethics training of technologists,</li><br><li>The open sharing of data and research,</li><br><li>International cooperation and competitiveness,</li><br><li>Accountability and legal rights, including matters relating to the responsibility for any violations of laws by an artificial intelligence system and the compatibility of international regulations,</li><br><li>Machine bias,</li><br><li>The prospects of machine learning to increase the opportunities of  rural communities,</li><br><li>Government efficiency, including the streamlining of services.</li><br>[/ul]<br>Second, the Committee should assess a range of economic, societal, legal and ethical questions, including the conditions of creating of a favourable climate for public and private investment in AI, the economic benefits of AI, as well as the likely job displacement and new employment opportunities engendered by AI. With respect to ethics, the Committee shall study how bias can be identified and eliminated in algorithms, with attention to the training data, diversity in AI development, and the potential harmful outcomes of AI deployment. In addition, the Committee would assess the utility of ethical standards in AI development and implementation and how the Federal Government can encourage technological progress for the benefit of all social and economic classes. The assessment should extend to a consideration of the suitability of existing legal and regulatory regimes to ensure consumer protection and privacy rights, with a view to modernising these in order to enable the potential of AI. The Committee should study how the Federal Government utilizes artificial intelligence to handle large or complex data sets and explore the possibilities of using AI to affect cost savings and streamline operations. Finally, the Committee should study how ongoing multi-stakeholder dialogues can maximize the potential of artificial intelligence in an inclusive way.<br>A report discussing the findings of the above questions and recommendations on administrative or legislative action would be due to the Secretary and to Congress within 540 days of the enactment of the Act. <br>The FAC’s 19 members would include 5 members from academia, 6 members from industry (including one representing small business), 6 members from civil society, and 2 members from labor organizations. The committee will also include eight or more members selected from the Department of Education, Department of Justice, Department of Labor, Department of Transportation, Federal Trade Commission, National Institute of Standards and Technology, National Science Foundation, and National Science and Technology Council.",USA,US Senate ; US House of Representatives
New York City Automated Decision Systems Task Force,Public services; Automated Decision Systems;,Local law; Task force,,City,5/1/2018 0:00,"<a target=""_blank"" href=""https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=3137815&GUID=437A6A6D-62E1-47E2-9C42-461253F9C6D0"">Bill establishing the task force</a> <br><a target=""_blank"" href=""https://www1.nyc.gov/site/adstaskforce/index.page"">ADS Tak Force</a> <br><a target=""_blank"" href=""https://www.newyorker.com/tech/annals-of-technology/new-york-citys-bold-flawed-attempt-to-make-algorithms-accountable"">'New York City’s Bold, Flawed Attempt to Make Algorithms Accountable""</a><br><a target=""_blank"" href=""https://cdt.org/files/2018/08/2018-08-17-NYC-ADS-Task-Force-Letter.pdf"">Centre for Democracy and Technology Recommendations</a>","The New York City Council passed a bill in November 2017 mandating the creation of an Automated Decision Systems Task Force (ADS Task Force). Its mandate is to formulate recommendations on a process for reviewing government automated decision systems. <br>The originally proposed bill would have required that the source code for the algorithms used by the City be made public. However, in response to concerns about exposing proprietary information and creating security threats, the New York City Automated Decisions Task Force was created instead - announced in May 2018. ""The Task Force is the first of its kind in the US and is composed of representatives from various government agencies and offices as well as partners in the nonprofit, research, and higher education communities.” <br>Tasks: <br>(1) identify which city agencies should be subject to review; <br>(2) recommend procedures so that people affected by an algorithmic decision can request an explanation upon what the decision was based, as well as how adverse impacts can be addressed; <br>(3) explain the development and implementation of a procedure in which the city may determine if an automated decision system used by a city agency ""disproportionately impacts persons based upon age, race, creed, colour, religion, national origin, gender, disability, marital status, partnership status, caregiver status, sexual orientation, alienage or citizenship status"" <br>The task force has no legal authority to force or penalize City agencies that do not comply with their recommendations. <br>Final report due December 2019.",USA,New York City Council
An act relating to data brokers and consumer protection H.764 (Act 171),Data protection,State legislation,Data security;,Regional,5/1/2018 0:00,"<a target=""_blank"" href=""https://legislature.vermont.gov/bill/status/2018/H.764"">Vermont data broker act</a>","The bill recognises that information services, such as credit reporting, background checks, risk mitigation and fraud detection provided by data brokers are essential to the modern economy. However, there are also risks associated with the widespread aggregation and sale of data. Specifically, risks related to consumers’ control over the kinds of data being collected and traded about them, as well as unauthorised access to these data. Moreover, consumers are normally not in a contractual relationship with data brokers themselves and may therefore be unaware of how their data is being used and by whom. <br>Therefore, this bill seeks to provide consumers with more information about data brokers, to ensure that data brokers have adequate security standards, to prohibit the acquisition of personal information with the intent to commit wrongful acts (data breaches), and to remove financial barriers to protect consumer credit information.<br>Data brokers are defined as businesses that aggregate and sell the personal information of consumers with whom they do not have a direct relationship. Such companies are required to adopt an information security program with appropriate administrative, technical, and physical safeguards to protect sensitive personal information. Data brokers are also required to register annually with the Secretary of State and make certain disclosures in order to provide consumers, policy makers, and regulators with relevant information. Such information includes the name and primary physical, e-mail, and Internet addresses of the data broker; details on whether and under what conditions the data broker permits a consumer to opt out of the data broker’s collection of personal information, as well as a statement specifying the data collection, databases, or sales activities from which a consumer may not opt out and a statement whether the data broker implements a purchaser credentialing process. In addition, the number of security breaches during the previous year must be disclosed, including the total number of consumers affected by the breaches.",USA,Vermont General Assembly
Top 10 Principles for Ethical AI,AI in general,Ethics guidelines,Labour market; Bias; Transparency; Accountability;,International - Global,12/1/2017 0:00,"<a target=""_blank"" href=""http://www.thefutureworldofwork.org/media/35420/uni_ethical_ai.pdf"">UNI AI Principles</a>","UNI is a global union representing over 20 million workers from the skills and services industries. The organisation “calls on all companies and governments to engage with the union movement, to co-create a just transition to a future of decent work.” <br>The core principle is that “Artificial intelligence must put people and planet first. This is why ethical AI discussions on a global scale are essential. A global convention on ethical AI that encompasses all is the most viable guarantee for human survival.”<br>The aim of the 10 principles outlined by UNI is to ensure workers’ rights and influence in the age of growing AI use and its audiences are unions, shop stewards and workers.<br><ol><br><li>Demand That AI Systems Are Transparent</li><br><li>Equip AI Systems With an “Ethical Black Box” - A device, which records information about the system, as well as about the ethical considerations built into the system.</li><br><li>Make AI Serve People and Planet - AI systems should be compatible with core values of human dignity, integrity, freedom, privacy and cultural and gender diversity, as well as with fundamental human rights. In addition, AI should improve the Earth’s ecosystem and biodiversity.</li><br><li>Adopt a Human-In-Command Approach - AI systems must retain the legal status of tools and legal persons must remain in control of and bear responsibility for the actions of the system. In addition, workers must have a right to an explanation if AI systems are used to make decisions about them.</li><br><li>Ensure a Genderless, Unbiased AI</li><br><li>Share the Benefits of AI Systems - Global and national policies to minimise the digital divide are necessary.</li><br><li>Secure a Just Transition and Ensuring Support for Fundamental Freedoms and Rights. As AI developments reshape the labour market, displacing workers, corporate accountability measures and government policies must be put in place, for example in the form of retraining programmes. States and companies are responsible for ensuring opportunities for lifelong learning and workers’ continued employability. AI systems must protect workers’ fundamental rights and come equipped with algorithms that embody key human rights laws, International Labour Organisation Conventions and other collective agreements.</li><br><li>Establish Global Governance Mechanisms - Decent Work and Ethical AI governance bodies on global and regional levels. </li><br><li>Ban the Attribution of Responsibility to Robots - Whistleblowing procedures must be established, and such bodies should recommend on compliance procedures.</li><br><li>Ban AI Arms Race - LAWS and cyber warfare should be banned.</li><br></ol>",Switzerland,UNI Global Union
Guiding Principles for Ethical AI,AI in general,Self-regulation,Bias; accountability; fairness;,International - Global,11/1/2018 0:00,"<a target=""_blank"" href=""https://blogs.unity3d.com/2018/11/28/introducing-unitys-guiding-principles-for-ethical-ai/"">Unity AI Principles</a>","Unity is one of the leading 3D engines. The principles are meant as the first version of an iteratively developed blueprint for the responsible use of AI at the company as a whole, by its community and its developers. The guide is short and seemingly adopts an approach whereby certain behaviours/virtues should be cultivated by those working on AI system development or deployment.<br>The six principles proposed by Unity are:<br><ol><br><li>Be Unbiased.</li><br><li>Be Accountable.</li><br><li>Be Fair.</li><br><li>Be Responsible.</li><br><li>Be Honest.</li><br><li>Be Trustworthy.</li><br></ol><br>Point nr. 3 explicitly includes the commitment to not creating AIs that would interfere with democratic systems of government and invites developers to decline working on developing products that would suppress human rights.<br>Responsibility entails not manipulating users through ML-based predictive tools. <br>Trustworthiness means guarding AI-derived data and using only in line with the other 5 values.",Global,Unity3d
Automated Driving Action Plan 2016-2018,Autonomous mobility,Action plan,,National,6/1/2016 0:00,"<a target=""_blank"" href=""https://www.bmvit.gv.at/en/service/publications/downloads/action_automated_driving_2016-2018.pdf"">Action Plan: Automated - Connected - Mobile</a>","In Austria, autonomous vehicles are considered to be a central element of long-term transportation policy, that is ultimately human-centred. An Action Plan was formulated in collaboration with 140 experts from the fields of economics, tech R&D and the public sector. It proposes 9 measures for the 2016-18 period that are to be iteratively developed and refined in light of data and insights. The Ministry for Transport, Innovation and Technology committed on the order of 20 million Euros to create the foundations for developing autonomous driving in Austria, in the hope that it would be followed by similar investment by other actors, like industry and other authorities.<br>The Ministry has been pursuing a holistic approach to the modernisation of Austria’s entire transportation system. It has a similar Action Plan on intelligent traffic systems, a strategy on Cooperative Intelligent Transport Systems (C-ITS), an implementation plan on e-mobility, and more. With the Action Plan, the Federal Ministry of Transport, Innovation and Technology has set clear priorities and steps for the future implementation and use of automated vehicles and mobility services, thus starting a long-term process<br>To develop the Action Plan 4 working groups were formed with well-defined goals. They tackled the legal and infrastructural requirements of performing AV testing; the systems-level architecture required for connectivity between vehicles and infrastructure; the development of user-centered and action-oriented use-cases and scenarios; and the necessary digital infrastructure, such as video detection, HD maps, traffic control, etc.<br>The Action Plan states that the development of autonomous driving is still in its early phases of development, especially, if one considers its broader aspects beyond mere technology readiness levels. Therefore, it proposes the adoption of a more encompassing, impact-oriented approach. Use-cases and scenarios are especially helpful in drawing out the various issues, capacities and criteria that different cases highlight. In the context of the Action Plan, seven scenarios and use-cases were developed together with a broad range of stakeholders. These scenarios were evaluated according to the key criteria of safety, efficiency, sustainability, and value creation, which resulted in the selection of 3 use-cases as priorities for immediate implementation. <br>[ul]<br><li>Use case “Security+ through 360° view” - drawing on predictive sensing assistance systems can intervene in the process of driving to avoid dangers. Information from other vehicles on the road as well as from the traffic infrastructure feed into these systems, thereby increasing safety in the immediate environment of the vehicle.</li><br><li>Use case “New Flexibility - Automated vehicles offer new, user-friendly transportation options. In particular as feeder systems to public transport nodes in urban and rural areas. On-demand not only increases the flexibility of mobility users but also relieves the environment.</li><br><li>Use case “Well Supplied” - Increasingly automated freight transport and optimized feeder services with efficient long-haul transports and corresponding concepts for the ""last mile"".</li><br>[/ul]<br>These three use-cases form the basis of the 9 concrete measures outlined in the Action Plan 2016-2018. <br><ol><br><li>Enable test drives through an amendment of the Motor Vehicles Act and statutory authorization.</li><br><li>Develop a Code of Practice to establish and unify the conditions of conducting AV tests, covering issues from licensing requirements to questions of liability.</li><br><li>Initiate 4-6 preliminary studies for setting up test environments (€1m funding)</li><br><li>Construction and operation of integrated test environments and structures (€10m funding for 2-3 test environments for the first 3 years)</li><br><li>Develop a technology promotion portfolio that strengthens the synergies between other R&D and Innovation programmes, such as Mobility of the Future and ICT of the Future, and strengthen international collaborations (funding €6m for 3 years)</li><br><li>Expand the digital infrastructure in collaboration with industry, the Austrian autobahn corporation, telco companies, and municipalities</li><br><li>Build scientific competences through funded professorships in topics like autonomous vehicle operation, and traffic operation and planning of AVs</li><br><li>Develop evaluation tools and detailed scientific impact analysis, including public acceptance and ethics (funding: €300k, including the definition of KPIs)</li><br><li>Establish a contact point for automated driving to develop competencies in the AustriaTech and to act as an advice centre.</li><br></ol>",Austria,"Federal Ministry for Transport, Innovation and Technology"
AV Code of Practice,Autonomous mobility,Self-regulation,,National,6/1/2016 0:00,"<a target=""_blank"" href=""http://www.austriatech.at/files/get/ff2b99d60657b228a4c176ed11d6dfa3/codeofpractice_20160607_endfassung.pdf"">AV Code of Practice</a>","In addition to the Regulation on Autonomous Driving, the Federal Ministry for Transport, Innovation and Technology has also created a code of practice for testing automated vehicles. <br>When submitting an application, testing companies will disclose whether they have read all the requirements of the Code of Practice and they volunteer to comply with these requirements. The provisions of the Code of Practice are not legally binding but are intended to promote responsible testing. The Code of Practice guidelines are intended to serve as a supplementary guide to testing organizations in addition to regulatory requirements. <br>The Code of Practice contains guidelines for generally observed safety requirements and behavioural instructions during and before the test drives, requirements for the test drivers, permissions as well as minimum technical requirements for the test vehicles.",Austria,"Federal Ministry for Transport, Innovation and Technology"
Responsible AI and Robotics,AI in general,Ethics guidelines,Liability; Transparency; Bias; Data protection;,National,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.accenture.com/gb-en/company-responsible-ai-robotics"">Accenture report</a>","Accenture’s ethical framework highlights the importance of predictability and trust, which are seen as interrelated factors necessary for AI’s success. It underlines the role of developing flexible and robust legal frameworks, however, Accenture’s view is that such frameworks must be accompanied by an ethical code, developed collaboratively by the government, business, academia and society more widely. Such a code must provide guidance on 7 key ethical challenges:<br>[ul]<br><li>Decision making and liability - who is liable when systems make mistakes?</li><br><li>Transparency - when must AI systems (not) explain their actions to humans?</li><br><li>Bias - stop systemic bias and promote core values of equality, diversity and lack of discrimination</li><br><li>Alignment with human values - what should AI’s core ethical values be?</li><br><li>Data protection & IP - how to balance data protection with the promotion of innovation?</li><br><li>Social dislocation - what obligations do AI deployers have to mitigate the resulting social consequences?</li><br><li>Cybersecurity - ensure strong protection against hacking.</li><br>[/ul]<br>Accenture identifies 5 areas where such a code should apply: <br>[ul]<br><li>Autonomous vehicles</li><br><li>Healthcare</li><br><li>Finance</li><br><li>Energy</li><br><li>Defence</li><br>[/ul]<br>The framework proposes the establishment of an AI Advisory Body to issue guidance to industry and regulators. In collaboration with key stakeholders, core ethical principles should be developed, along with sector-specific codes for the above-identified 5 areas.",United Kingdom,Accenture
Montreal Declaration on Responsible AI,AI in general,Declaration,Well-being; Autonomy; Privacy; Solidarity; Intimacy; Literacy; Bias; Sustainability; Participation; Equity; Diversity; Responsibility;,International - Global,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.montrealdeclaration-responsibleai.com/the-declaration"">Montreal Declaration</a><br><a target=""_blank"" href=""https://docs.wixstatic.com/ugd/ebc3a3_c5c1c196fc164756afb92466c081d7ae.pdf"">Text</a>","The Montreal Declaration proposes an ethical framework for the development and deployment of AI. It is meant to guide the digital transition for the benefit of all, and to open a national and international dialogue. Its 10 principles are abstract, non-hierarchical and require appropriate interpretation in particular circumstances. Although they are formulated as ethical principles, they may easily be translated into legal norms. The Declaration is intended for anyone engaging with AI in any capacity, including scientists, technologists and political representatives. <br>The Declaration came about through a deliberative process that started with a forum in November 2017 followed by a stage of gathering expert and public input through workshops, panels, citizens’ meetings and online commentary. It is to be viewed as an evolving open guidance document and its current state represents the starting point “for an open and inclusive conversation surrounding the future of humanity being served by artificial intelligence technologies.” <br>Some of the demands outlined in the Declaration formulate requirements that technological systems or their developers must meet, while others put forward expectations against society, such as digital literacy, which must be supported and enabled by governance mechanisms. <br>Members of the public are invited to sign the Declaration online as an expression of their support of its principles. <br><ol><br><li><strong>Well-being Principle</strong> - “the development and use of artificial intelligence systems (AIS) must permit the growth of the well-being of all sentient beings.” </li><br><li><strong>Respect for Autonomy Principle </strong>- “AIS must be developed and used while respecting people’s autonomy, and with the goal of increasing people’s control over their lives and their surroundings.” This includes the prohibition of using AIs to suppress certain conceptions of the good life and subjecting people to oppressive regimes of surveillance, classification and incentivization. Furthermore, AIs must not be used to spread misinformation or create confusion between humans and AIs.</li><br><li><strong>Protection of Privacy and Intimacy Principle - </strong>introduces the notion of “data acquisition and archiving systems” and states that privacy and intimacy must be protected from intrusion by such systems. Protection extends to personal spaces and to the intimacy of thoughts and emotions. The Declaration states that people’s right to disconnect digitally must be guaranteed. It calls for people’s right to maintain extensive control over information regarding their preferences and to not be subject to influence based on profiling, without consent. In addition, confidentiality and profile anonymity must be guaranteed. Importantly, access to AIS services must not be conditional on giving up control over personal data, and individuals should be free to donate their data for research purposes.</li><br><li><strong>Solidarity Principle</strong> - “the development of AIS must be compatible with maintaining the bonds of solidarity among people and generations.” AIS should support human collaboration and foster human relationships. Health care applications must especially consider the patients’ relationships to relatives and the care team. AIS should foster societal conditions with a more equitable distribution of individual and collective risks.</li><br><li><strong>Democratic Participation Principle </strong>- “AIS must meet intelligibility, justifiability, and accessibility criteria, and must be subjected to democratic scrutiny, debate, and control.” This Principle includes transparency and understandability requirements for situations when AIS make decisions affecting individuals’ life, quality of life, or reputation. It also calls for the source code of algorithms, public and private, to be available to public authorities and stakeholders for verification. Errors and breaches must be reported to authorities and those affected. The Principle requires that citizens be in a position to deliberate on the objectives and limits of AI systems. Individuals must also always be aware whether they are interacting with an AIS and whether a decision about them has been made by an AIS. </li><br><li><strong>Equity Principle </strong>- “The development and use of AIS must contribute to the creation of a just and equitable society.”  AIS must be free of bias, help eliminate relationships of domination between groups of people, and produce social and economic benefits for all. The Principle extends to requiring acceptable working conditions across the entire life cycle of an AIS, from natural resource extraction to data processing. In addition, the activity of AIS users generating data should be recognized as labour. The development and use of ‘commons algorithms’ and open data should be supported. </li><br><li><strong>Diversity Inclusion Principle </strong>- “The development and use of AIS must be compatible with maintaining social and cultural diversity and must not restrict the scope of lifestyle choices or personal experiences.” The principle calls for broad inclusion of social diversity in the conceptualisation, development and deployment of algorithms, as well as in their environments of development. AIS must not be used to lock individuals into certain data-derived profiles restricting their personal development or to limit expressions of free expression. AIS offerings must be diversified in each service category to avoid the formation of monopolies. </li><br><li><strong>Prudence Principle</strong> - “Every person involved in AI development must exercise caution by anticipating, as far as possible, the adverse consequences of AIS use and by taking the appropriate measures to avoid them.” Especially, mechanisms to monitor dual-use potential must be developed, and open access to applications with a high probability of causing public harms must be restricted. Extensive evaluation measures should be undertaken prior to marketing, and the testing should be open to public authorities and stakeholders. </li><br><li><strong><strong>Responsibility Principle</strong></strong><strong> - </strong>“The development and use of AIS must not contribute to lessen the responsibility of human beings when decisions must be made.” Humans remain responsible for decisions made by AIS, and in cases where someone’s life, quality of life or reputation are at stake, humans should make informed decisions instead of AIs. Lethal decisions must always be made by humans and can’t be delegated. When harms occur from AIS that are reliable and used as intended, blame should not be placed on its developers. </li><br><li>Sustainable Development Principle - “The development and use of AIS must be carried out so as to ensure strong environmental sustainability of the planet.” Strong environmental sustainability does not allow the substitution of the loss of natural resources with artificial capital, such as carbon trading. The Principle requires that all digital infrastructure operate at maximum energy efficiency to reduce greenhouse gas emissions, that they generate the least amount of waste, and reduce their impact on the ecosystem and biodiversity from resource extraction to disposal.</li><br></ol>",Global,University of Montreal
National Strategy for AI - Discussion Document,AI in general,Strategy,"Bias, Fairness; Labour market impacts; Privacy;",National,6/1/2018 0:00,"<a target=""_blank"" href=""http://www.niti.gov.in/writereaddata/files/document_publication/NationalStrategy-for-AI-Discussion-Paper.pdf"">Strategy document</a><br><a target=""_blank"" href=""https://cis-india.org/internet-governance/files/niti-aayog-discussion-paper"">Centre for Internet and Society analysis</a>","In the fiscal year, 2018-19 India is launching a National Program on AI to guide R&D in this domain. The National Institution for Transforming India is pursuing multiple activities around AI, which include working towards a national strategy, running proof-of-concept studies in critical areas like health and agriculture, and collaborating with experts and stakeholders. The two latter activities support the creation of a national strategy, about which a first discussion paper was released in June 2018. <br>The document is meant to lay the groundwork for an evolving strategy and puts forward the #AIforAll brand, which seeks to position India as a global leader in the field. The brand suggests an inclusive approach, in line with the country’s development goals. AI is viewed as a ‘once-in-a-generation’ opportunity, the benefits of which should extend beyond financial impact and support the greater good. The report suggests that India may be an ideal ‘playground’ for global enterprises to develop scalable solutions for the rest of the world’s developing and emerging economies. These regions share a commonality of issues that need to be solved, hence, ‘Solved in India’ could act as a seal of approval and become a model for developing AI as a Service for other economies.  The report thus proposes making India an ‘AI Garage for 40% of the world’.<br>The document focuses on 5 key sectors where AI could bring the greatest societal benefit:<br>[ul]<br><li>Healthcare;</li><br><li>Agriculture;</li><br><li>Education;</li><br><li>Smart cities and infrastructure;</li><br><li>Smart mobility and transportation.</li><br>[/ul]<br>In addition, cross-cutting barriers are also identified, which could hinder AI deployment at scale, and thus call for an integrated approach:<br>[ul]<br><li>Lack of enabling data ecosystems;</li><br><li>Low intensity of AI research, both core and applied;</li><br><li>Inadequate availability of AI expertise;</li><br><li>High resource cost and low awareness of adopting AI;</li><br><li>Unclear privacy, security and ethical regulations;</li><br><li>Unattractive IP regime.</li><br>[/ul]<br>Recommendations to address these barriers are put forward in 4 categories:<br>[ul]<br><li>Research;</li><br><li>Skilling for the AI age;</li><br><li>Accelerating adoption;</li><br><li>Ethics, privacy and security.</li><br>[/ul]<br>With regard to research, a two-tiered structure is proposed to address the fact AI research in India is still in its infancy:<br>[ul]<br><li>Establishing Centres of Research Excellence (CORE) dedicated to core research;</li><br><li>Establishing International Centers of Transformational AI (ICTAI) to develop and deploy application-based research in collaboration with the private sector.</li><br>[/ul]<br>COREs would focus on basic research and act as ‘technology feeders’ to ICTAIs, dedicated to creating AI-based applications and accelerating adoption in key domains.<br>In addition, it is suggested the Government of India should take the lead in bringing together parties to create ‘People’s AI’, an initiative similar in scale and scope to that of CERN. However, unlike CERN, such a centre would not need a physical location and could be distributed across the world, with India acting as the initial funding and coordinating agency. The centre’s mandate should be to focus on cross-cutting, foundational issues that can make AI inclusive, such as General Artificial Intelligence; explainable AI; advanced anonymisation protocols; ethics in AI; and leveraging AI in the service of the world’s biggest problems in health, education, agriculture, etc. <br>With regard to the skills shortage, the document proposes a set of interventions for students and another set aimed at the workforce.<br>Measures should be taken incentivise job creation in the new service industry, ideally, roles that are part of the AI solution development value chain but require low levels of expertise, such as data annotation, image classification, speech transcription, etc. These can provide employment at scale. In addition, the quality of informal training institutions that offer to reskill workers into technology-related professions should be standardised. Open online platforms for self-learning - similar to Coursera and edX - should also be created and their offerings standardised through certification and quality measurement. Finally, models for co-funding reskilling by government and companies should be explored. This may take multiple forms, such as income tax deductions, special taxes to be paid if a training budget is not distributed, or grants subsidizing training. <br>The interventions addressing students are broad and encompass basic reforms to the whole of the Indian education system, including the introduction of skill-based learning in subjects relevant to AI, increasing the amount of project related work across education levels, and increasing collaboration between industry and academia. To address the lack of qualified faculty, credit-bearing MOOCs and other decentralised teaching mechanisms should be explored. Bridge courses at the postgraduate level should be established for non-computer science students who have other domain expertise. <br>Establishing a task force to monitor changes in employment caused by AI in India is suggested as a solution for creating a longer-term, sustainable framework.<br>The document describes how India is lagging in AI adoption, despite its strong presence in the IT industry. Therefore, government involvement seems necessary to promote AI adoption. This extends to private enterprises, public sector undertakings and the government itself. Several recommendations are advanced to address this issue.<br><ol><br><li>A decentralised, blockchain-based multi-stakeholder National AI Marketplace (NAIM) is proposed, that would allow businesses to offer various parts of the AI value chain as a stand-alone service, from data capture to the deployment of solutions. It is hoped that such a marketplace could level the playing field and address information asymmetry while incentivising and simplifying collaboration between the various stakeholders in the AI ecosystem. According to the report, all businesses, government agencies, startups, and research institutions would sign up to the marketplace and engage in their respective activities. Its 3 elements would be a data marketplace, a data annotation marketplace and a deployable model/solutions marketplace. The government doesn’t intend to build such marketplaces itself, rather, to create enabling regulations for private players to do so. This would entail creating standards for personal data use, anonymisation, annotation accuracy and cybersecurity. </li><br><li>The government could assist the creation of large annotated national datasets to spur research and innovation. </li><br><li>Partnerships and collaboration should be supported, especially collaboration between research organisations (AI+X), where AI researchers work with other domain experts, as well as collaborations between research and industry, trade bodies, and venture capital. </li><br><li>Low visibility of AI research and its benefits is a hurdle, which could be overcome by a government managed online AI Database with information about existing projects, networks and results, as well as expert profiles. In addition, efforts at spreading awareness among government agencies and the public sector are also recommended.</li><br><li>Supporting AI startups through dedicated incubation hubs in collaboration with State Governments and private sector stakeholders, and establishing a fund to provide grants to startups.</li><br></ol><br>With regard to ethics, security and privacy, the document discusses several issues. On fairness and biases, it suggests a reactive approach, identifying biases built into systems and assessing their impacts in order to reduce them, until techniques are developed to create neutral solutions. The strategy acknowledges the importance of the issues around transparency and suggests aiming at explainability, which must be balanced against the risk of attempts at ‘gaming the system’. On privacy, the strategy takes the position that the main worry about companies harvesting large amounts of consumer data and deriving insights is that consumers themselves don’t have access to such insights or derive value from them. Therefore, it suggests that beyond compliance “companies can consider how to create awareness of how they use consumer information and the value they provide in return, which can build trust in their brand and services.” However, the authors of the strategy disagree with concerns that companies with large datasets could build an unfair competitive advantage and they see no negative impact on the consumer.<br>In order to deal with privacy issues a number of concrete recommendations are made:<br>[ul]<br><li>Establish a data protection framework with legal backing. The report references the core principles of the proposed Srikishna Committee data protection law: informed consent, technology agnosticism, data controller accountability, data minimisation, holistic application, deterrent penalties and structured enforcement;</li><br><li>Establish sectoral regulatory frameworks;</li><br><li>Benchmark Indian data protection and privacy laws with European standards like the GDPR;</li><br><li>Encourage Indian enterprises to adopt international standards like those of the IEEE;</li><br><li>Encourage self-regulation and the use of Data Privacy Impact Assessment Tools;</li><br><li>Invest in research to find new mathematical models for preserving privacy;</li><br><li>Make citizens aware of their right to privacy, which has been termed a fundamental right by the Supreme Court of India.</li><br>[/ul]<br>The report considers security and accountability to be linked issues and suggests a framework to handle it. The framework would rely on self-regulation of stakeholders to conduct damage impact assessments at every stage of development, and use negligence tests for damages caused by AI. Liability would be limited if appropriate steps to design, test, monitor and improve products had been taken. <br>It is suggested that a consortium of Ethics Councils be set up at each Centre of Excellence to define standards of practice. <br>Finally, inspired by the UK’s Centre for Data Ethics and Innovation, the document advises the Indian Government to set up a Centre for Studies on Technological Sustainability (CSTS) to address issues relating to ethics, privacy, legal aspects, social sustainability and global competitiveness.<br>The document provides no roadmap towards implementation, nor details about the budgetary requirements of the proposed recommendations.",India,National Institution for Transforming India (NITI Aayog)
Pan-Canadian AI Strategy,AI in general,Strategy,,National,3/1/2017 0:00,"<a target=""_blank"" href=""https://www.cifar.ca/ai/pan-canadian-artificial-intelligence-strategy"">Pan-Canadian Artificial Intelligence Strategy</a>","Canada was the first country to announce a national strategy for artificial intelligence, along with a CAN$125m investment over a 5-year period. The effort is led by the Canadian Institute for Advanced Research, which has a long track record of pursuing AI-related research. CIFAR's Learning in Machines and Brains Program launched in 2004 was initially led by Geoff Hinton, who is widely considered one of the fathers of modern deep learning.<br>The strategy is executed in partnership with 3 AI institutes, the Alberta Machine Intelligence Institute (AMII) in Edmonton, the Montreal Institute for Learning Algorithms (MILA) and the <a target=""_blank"" href=""https://vectorinstitute.ai/"">Vector Institute</a> in Toronto.<br>The strategy identified 4 main goals:<br>[ul]<br><li>Increase the number of outstanding artificial intelligence researchers and skilled graduates;</li><br><li>Establish interconnected nodes of scientific excellence in the three partnering AI institutes;</li><br><li>Develop global thought leadership on the economic, ethical, policy and legal implications of advances in AI;</li><br><li>Support a national research community on AI.</li><br>[/ul]<br>Over the 5-year period of the initial funding, CIFAR will collaborate with the Canadian research community to enhance Canada’s international profile in research and training, achieve productivity gains in academic research on AI and an increased capacity to generate leading research and innovation, while increasing collaboration across Canada’s AI research centres. Furthermore, it is expected that the strategy will help to attract and retain outstanding AI talent in Canada, as well as to translate AI research into socio-economic benefit through both private and public sector applications. <br> <br>In addition, the strategy supports policy-relevant working groups to examine the implications of AI and inform policy-makers.<br>The Canadian federal government’s investment in the strategy has led to investment from other levels of government and from the private sector.",Canada,Canadian Institute for Advanced Research
Directive on the Use of Machine Learning for Decision-Making,Automated Decision Systems,Directive,Accountability; Bias; Transparency; Fairness,National,2/1/2019 0:00,"<a target=""_blank"" href=""Draft Directive"">Draft Directive</a><br><a target=""_blank"" href=""https://canada-ca.github.io/digital-playbook-guide-numerique/views-vues/automated-decision-automatise/en/algorithmic-impact-assessment.html"">AIA questionnaire draft 0.2</a><br><a target=""_blank"" href=""https://medium.com/@supergovernance/a-canadian-algorithmic-impact-assessment-128a2b2e7f85"">A Canadian Algorithmic Impact Assessment</a><br><a target=""_blank"" href=""https://medium.com/@supergovernance/the-government-of-canadas-algorithmic-impact-assessment-take-two-8a22a87acf6f"">The Government of Canada’s Algorithmic Impact Assessment: Take Two</a>","The Directive will cover rules related to the automation of administrative decision processes in federal government institutions. It will apply to any Automated Decision System (ADS) developed or procured after 1 April 2020 and will be reviewed every 6 months once in effect on the 4th of February 2019. <br>The Directive is expected to ensure that government departments make decisions in a way that is data-driven, responsible, and in accord with the requirements of procedural fairness and due process. Negative outcomes are to be reduced by assessing the impacts of algorithms on administrative decisions, and where possible, data about the use of ADSs are to be made publicly available. <br>The responsible person at the relevant government program using an ADS is required to undertake an Algorithmic Impact Assessment (AIA). This takes the form of a questionnaire, which is meant to help institutions understand and reduce the risks of ADSs. It uses a 4-level classification to rank the impacts of the decision on individuals’ fundamental rights, the health and well-being of individuals and communities, the economic interests of those affected, as well as on the ongoing sustainability of the ecosystem. Depending on which classification a system falls under, different peer review, notice, human-in-the-loop, explanation, testing, contingency planning and approval requirements must be adhered to. However, irrespective of the classification level, the same training and monitoring requirements apply. These state that before any ADS goes into production, processes must be in place to ensure that the training data is not biased and that the data used by the ADS is routinely tested to guarantee that it remains relevant, accurate and up-to-date. In addition, the systems’ use must be monitored for unintended outcomes and for compliance with legislation and the Directive. <br>Whenever possible, open source solutions should be used. If using a proprietary license the Government of Canada has the right to access and test the system, including the right to have third parties audit the ADS. Unless overriding reasons, such as national security, make it impossible, the ADS’ source code should be made publicly available.",Canada,Government of Canada
International Panel on Artificial Intelligence,AI in general,Partnership ; International agreement,Trust; Privacy; Labour market effects; Justice; Responsibility,International - Bilateral,6/7/2018 0:00,"<a target=""_blank"" href=""https://pm.gc.ca/eng/news/2018/12/06/mandate-international-panel-artificial-intelligence"">Mandate for the International Panel on Artificial Intelligence</a>","The aim of the International Panel is to “support and guide the responsible adoption of AI that is human-centric and grounded in human rights, inclusion, diversity, innovation and economic growth.” The effort builds on the partnership of the French and Canadian governments to collaborate on promoting human-centric AI. It will support international collaboration between researchers, industry and civil society actors, as well as governments and international organizations. The Panel will seek to fulfil a role similar to that of the Intergovernmental Panel on Climate Change and will study the impacts of AI on a global scale. The group would monitor work being done on AI around the world and issue reports to guide policy making.",France; Canada,Government of Canada ; Government of France
Three-Year Action Plan for Promoting Development of a New Generation Artificial Intelligence Industry (2018–2020),AI in general,Action plan,,National,12/1/2017 0:00,"<a target=""_blank"" href=""https://www.newamerica.org/cybersecurity-initiative/digichina/blog/translation-chinese-government-outlines-ai-ambitions-through-2020"">Translation of the action plan at the New America think tank</a>","The plan lays out China's ambitious goals with regard to AI focusing in particular on 4 key initiatives. 
First, it seeks to support and R&D of critical technologies and innovative product and services development, with a special
emphasis on intelligent and connected vehicles (ICV).
Second, it seeks to support R&D in intelligent sensors to advance low-cost, high-precision sensing technologies. 
Third, there is an emphasis on smart manufacturing.
The fourth initiative covers the infrastructure that needs to be in place to support an advanced AI support ecosystem, 
especially emhpasising the role of standards.",China,Ministry of Industry and Information Technology
Toronto Declaration,AI in general,Declaration,Equality; Fairness; Bias; Transparency; Accountability; Non-discrimination;,International - Global,5/1/2018 0:00,"<a target=""_blank"" href=""https://www.accessnow.org/cms/assets/uploads/2018/08/The-Toronto-Declaration_ENG_08-2018.pdf"">Text of the Toronto Declaration</a>","The Declaration was published on 16 May 2018 by Amnesty International and Access Now, and launched at RightsCon 2018 in Toronto, Canada. Since then, Human Rights Watch and the Wikimedia Foundation have also endorsed it.<br>The Declaration underlines the importance of relying on the framework of existing human rights laws and standards to guard individuals and communities against intentional or inadvertent discrimination arising from the use of machine learning systems. It calls on states and private entities to respect human rights at all times, and to have binding measures to uphold and protect these rights. Human rights law is a body of universally binding and actionable measures that is well suited to guide borderless technologies like AI and to ensure accountability. Importantly, a human rights framework includes mechanisms for holding actors accountable and obtaining redress when a person’s rights have been violated. <br>Public and private entities must work to prevent and mitigate the risk of discrimination from the design phase of an application through to its deployment. Inclusion and diversity in terms of race, culture, gender, religion and socio-economic backgrounds is essential to ensure non-discrimination and to eliminate biases. <br>States have a particular obligation to uphold and protect human rights through binding legal instruments. States must have updated measures to guard against discrimination and other rights-harms arising from machine learning and provide meaningful redress of harms. <br>Specifically, state actors must take steps with regard to their own use of machine learning: <br>[ul]<br><li>to identify risks of discrimination and other rights-harms that might arise from machine learning systems. This extends throughout the technology’s entire life cycle. They must conduct regular impact assessments and prepare measures to mitigate the risks identified through such an assessment. Systems must be subjected to regular independent review and testing for bias, and any known limitations of systems must be disclosed. </li><br><li>To ensure and require transparency and accountability, allowing for public scrutiny of the impact of the machine learning systems. They must publicly disclose their use of ML systems, explaining the mechanisms of decision-making and allowing independent analysis of their algorithms</li><br><li>To enforce oversight by including diverse perspective in the design, implementation and review of ML systems, as well as training providing human rights and data analysis training to those involved in their procurement, development and review. ML-supported decisions must meet international norms on due process.</li><br>[/ul]<br>When procuring ML systems from private entities, state authorities must maintain their oversight and ensure third-party audit for human rights due diligence. <br>Finally, states should craft regulations and standards to prevent private entities from using ML in ways that are discriminatory or cause other rights-harms. <br>The Declaration also articulates the responsibilities of private sector actors. First and foremost, they should follow a human rights due diligence framework, making sure that they don’t cause or contribute to any human rights violations. Similar to state authorities, private actors must work to identify any risks associated with their use of an ML system, work to mitigate those risks and be transparent about their efforts. Where the risks of discrimination or other human rights violations are impossible to mitigate, they should refrain from deploying the technology. <br>The provision of effective remedies against violations is a fundamental element of the human rights framework that applies to both state and private sector actors. Particular care should be taken when using ML-based systems in the justice sector, as this might affect individuals’ ability to seek effective remedy. Clear lines of accountability must be defined outlining who is legally responsible for decisions made with the help of ML systems.",Global,Amnesty International ; Access Now
10 principles for public sector use of algorithmic decision making,Automated Decision Systems,Proposal,Bias; Impact assessment; Accountability; Transparency; Redress; Testing/Sandboxes,National,2/1/2018 0:00,"<a target=""_blank"" href=""https://www.nesta.org.uk/blog/10-principles-for-public-sector-use-of-algorithmic-decision-making/"">Article</a><br><a target=""_blank"" href=""https://docs.google.com/document/d/192Kcf-w64pp9n9b46hGCiaTw7tDN6yZgsjXTJYTJiAw/edit"">Text draft for commentary</a>","In response to the growing prominence and critical nature of using automated decision systems in the delivery of government services, this proposal formulates 10 broad principles for a Code of Standards for Public Sector Algorithmic Decision Making.<br><ol><br><li>“Every algorithm used by a public sector organisation should be accompanied with a description of its function, objectives and intended impact, made available to those who use it.”</li><br><li>“Public sector organisations should publish details describing the data on which an algorithm was (or is continuously) trained, and the assumptions used in its creation, together with a risk assessment for mitigating potential biases.”</li><br><li>“Algorithms should be categorised on an Algorithmic Risk Scale of 1-5, with 5 referring to those whose impact on an individual could be very high, and 1 being very minor.”</li><br><li>“A list of all the inputs used by an algorithm to make a decision should be published.”</li><br><li>“Citizens must be informed when their treatment has been informed wholly or in part by an algorithm.”</li><br><li>“Every algorithm should have an identical sandbox version for auditors to test the impact of different input conditions.”</li><br><li>“When using third parties to create or run algorithms on their behalf, public sector organisations should only procure from organisations able to meet Principles 1-6.“</li><br><li>“A named member of senior staff (or their job role) should be held formally responsible for any actions taken as a result of an algorithmic decision.”</li><br><li>“Public sector organisations wishing to adopt algorithmic decision making in high risk areas should sign up to a dedicated insurance scheme that provides compensation to individuals negatively impacted by a mistaken decision made by an algorithm.”</li><br><li>“Public sector organisations should commit to evaluating the impact of the algorithms they use in decision making, and publishing the results.”</li><br></ol>",United Kingdom,Nesta
Sony Group AI Ethics Guidelines,AI in general,Self-regulation,Trust; Privacy; Fairness; Diversity; Transparency;,International - Global,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.sony.net/SonyInfo/csr_report/humanrights/hkrfmg0000007rtj-att/AI_Engagement_within_Sony_Group.pdf"">Sony AI Guidelines</a>","The guidelines formulate 7 principles to which all Sony officers and employees who use AI must adhere to. This includes AI in products or services provided to customers, as well as any internal use of AI-based tools and processes. <br><ol><br><li>Supporting Creative Life Styles and Building a Better Society - Sony’s AI-related work should empower individuals to unfold their potential and to enrich the culture and life of society through creating new types of emotionally moving experiences.</li><br><li>Stakeholder Engagement - Sony will engage with various stakeholders and consider their viewpoints and interest when developing AI-related tools or services.</li><br><li>Provision of Trusted Products and Services</li><br><li>Privacy Protection - Sony will ensure that personal data gathered through AI-based services will be used in ways that respect customers trust and intention and adhere to laws and regulations.</li><br><li>Respect for Fairness - Sony will respect diversity and human rights in its utilisation of AI and will try to work towards the resolution of social problems. </li><br><li>Pursuit of Transparency - Sony will strive to capture the decisions that inform the design of AI products and will seek to provide explanations about the possible impacts on customers.</li><br><li>The Evolution of AI and Ongoing Education - Sony will consider the broad-ranging implications of AI on society and will work for the betterment of society through such new technologies.</li><br></ol>",Global,Sony
Data Ethics Framework,Data governance,Ethics guidelines,Accountability; Transparency; Privacy; Bias; Public sector data;,National,6/1/2018 0:00,"<a target=""_blank"" href=""https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/737137/Data_Ethics_Framework.pdf"">Data Ethics Framework</a><br><a target=""_blank"" href=""https://www.gov.uk/government/publications/data-ethics-workbook"">Data Ethics Workbook</a>","The Data Ethics Framework offers guidance on the use of data in the UK Government and the public sector. It replaces the previous Data Science Ethical Framework. Building on the core values of integrity, honesty, objectivity and impartiality defined by the Civil Service Code, the Data Ethics Framework lays out 7 principles for public servants working with data to act appropriately. The Framework also includes a workbook, which contains a set of questions in relation to each principle in order to help articulate the details of any planned data use and to mitigate potential risks. A separate workbook with additional questions is available for working with suppliers.<br><br>The Data Ethics Framework’s 7 principles are:<br><br><ol><br><li>Start with clear user need and public benefit</li><br><li>Be aware of relevant legislation and codes of practice</li><br><li>Use data that is proportionate to the user need</li><br><li>Understand the limitations of the data</li><br><li>Use robust practices and work within your skillset</li><br><li>Make your work transparent and be accountable</li><br><li>Embed data use responsibly</li><br></ol>",United Kingdom,"Department for Digital, Culture, Media & Sport"
Universal Guidelines for Artificial Intelligence,AI in general,Guidelines,Accountability; Transparency; Bias; Fairness; Data quality; Security; Human control;,International - Global,10/1/2018 0:00,"<a target=""_blank"" href=""https://thepublicvoice.org/ai-universal-guidelines/"">Universal Guidelines for AI</a>","The guidelines were developed by The Public Voice, a coalition of the Electronic Privacy Information Centre, a Washington DC-based research centre. The guidelines are proposed to inform the design and use of AI systems with a focus on protecting human rights. They were presented at the 2018 International Data Protection and Privacy Commissioners Conference in Brussels. <br>The document puts forward 12 principles for governments and private companies, which should be incorporated into ethical standards, legal frameworks, and embodied in AI systems. The principles build on several existing ethical frameworks, laws and conventions, such as the Asilomar Principles, the GDPR, the Toronto Declaration and the framework of fundamental human rights. The guidelines lays down the following rights of individuals and obligations of institutions:<br><ol><br><li>“Right to Transparency.  All individuals have the right to know the basis of an AI decision that concerns them. This includes access to the factors, the logic, and techniques that produced the outcome.</li><br><li>Right to Human Determination. All individuals have the right to a final determination made by a person.</li><br><li>Identification Obligation. The institution responsible for an AI system must be made known to the public.</li><br><li>Fairness Obligation. Institutions must ensure that AI systems do not reflect unfair bias or make impermissible discriminatory decisions.</li><br><li>Assessment and Accountability Obligation. An AI system should be deployed only after an adequate evaluation of its purpose and objectives, its benefits, as well as its risks. Institutions must be responsible for decisions made by an AI system.</li><br><li>Accuracy, Reliability, and Validity Obligations. Institutions must ensure the accuracy, reliability, and validity of decisions.</li><br><li>Data Quality Obligation. Institutions must establish data provenance, and assure quality and relevance for the data input into algorithms.</li><br><li>Public Safety Obligation. Institutions must assess the public safety risks that arise from the deployment of AI systems that direct or control physical devices, and implement safety controls.</li><br><li>Cybersecurity Obligation. Institutions must secure AI systems against cybersecurity threats.</li><br><li>Prohibition on Secret Profiling. No institution shall establish or maintain a secret profiling system.</li><br><li>Prohibition on Unitary Scoring. No national government shall establish or maintain a general-purpose score on its citizens or residents.</li><br><li>Termination Obligation. An institution that has established an AI system has an affirmative obligation to terminate the system if human control of the system is no longer possible.”</li><br></ol>",Global,The Public Voice ; Electronic Privacy Information Centre
Asilomar AI Principles,AI in general,Ethics guidelines,,International - Global,1/1/2017 0:00,"<a target=""_blank"" href=""https://futureoflife.org/ai-principles/"">Asilomar Principles</a>","The principles were developed by the Future of Life Institute, a Boston-based research organisation devoted to the safeguarding human life and developing optimistic visions of the future. In advance of the 2017 Beneficial AI conference, the organisers compiled a list of principles about how to manage AI, distilled from the various reports and initiatives around the world. These principles were circulated during the BAI event and extensive feedback collected about them. A revised version was then discussed at a meeting in Asilomar, which resulted in the final 23 item list organised into 3 broad categories.<br><strong>Research Issues</strong><br>Research Goal: The goal of AI research should be to create not undirected intelligence, but beneficial intelligence.<br>Research Funding: Investments in AI should be accompanied by funding for research on ensuring its beneficial use, including thorny questions in computer science, economics, law, ethics, and social studies, such as:<br>[ul]<br><li>How can we make future AI systems highly robust, so that they do what we want without malfunctioning or getting hacked?</li><br><li>How can we grow our prosperity through automation while maintaining people’s resources and purpose?</li><br><li>How can we update our legal systems to be more fair and efficient, to keep pace with AI, and to manage the risks associated with AI?</li><br><li>What set of values should AI be aligned with, and what legal and ethical status should it have?</li><br>[/ul]<br>Science-Policy Link: There should be constructive and healthy exchange between AI researchers and policy-makers.<br>Research Culture: A culture of cooperation, trust, and transparency should be fostered among researchers and developers of AI.<br>Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.<br><strong>Ethics and Values</strong><br>Safety: AI systems should be safe and secure throughout their operational lifetime, and verifiably so where applicable and feasible.<br>Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.<br>Judicial Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.<br>Responsibility: Designers and builders of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.<br>Value Alignment: Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.<br>Human Values: AI systems should be designed and operated so as to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.<br>Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.<br>Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.<br>Shared Benefit: AI technologies should benefit and empower as many people as possible.<br>Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.<br>Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives.<br>Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather than subvert, the social and civic processes on which the health of society depends.<br>AI Arms Race: An arms race in lethal autonomous weapons should be avoided.<br><strong>Longer-term Issues</strong><br>Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.<br>Importance: Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.<br>Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.<br>Recursive Self-Improvement: AI systems designed to recursively self-improve or self-replicate in a manner that could lead to rapidly increasing quality or quantity must be subject to strict safety and control measures.<br>Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.",Global,Future of Life Institute
ACR-215 23 Asilomar AI Principles,AI in general,Resolution,,Regional,9/1/2018 0:00,"<a target=""_blank"" href=""http://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180ACR215"">California Legislative Information</a>","The California State Senate passed a resolution endorsing the 23 Asilomar AI Principles developed by the Future of Life Institute. The Principles are a result of extensive collaboration among AI experts, legal scholars, ethicists, philosophers, economists and others. They formulate principles in relation to the research, ethics and longer-term management of AI. The California Senate endorsed the principles “as guiding values for the development of artificial intelligence and of related public policy.”",USA,California State Senate
Statement on Algorithmic Transparency and Accountability,Automated Decision Systems,Self-regulation,Bias; Redress; Accountability; Explainability; Data quality; Transparency; Testing,International - Global,1/1/2017 0:00,"<a target=""_blank"" href=""https://www.acm.org/binaries/content/assets/public-policy/2017_usacm_statement_algorithms.pdf"">ACM Statement</a>","The ACM is the world’s largest computing society, bringing together researchers, educators and professionals. It has over 100 000 members worldwide, with Councils in Europe, India and China. The ACM has been issuing a Code of Ethics and Professional Conduct for decades and the most recent version came out in 2018, updating the 1992 edition. <br>The Statement on Algorithmic Transparency and Accountability builds on the Code of Ethics and its purpose is to enable institutions to maximise the benefits of algorithmic decision making while minimising its risks. <br>Seven principles are proposed, which are reproduced below:<br><ol><br><li>Awareness: Owners, designers, builders, users, and other stakeholders of analytic systems should be aware of the possible biases involved in their design, implementation, and use and the potential harm that biases can cause to individuals and society. </li><br><li>Access and redress: Regulators should encourage the adoption of mechanisms that enable questioning and redress for individuals and groups that are adversely affected by algorithmically informed decisions. </li><br><li>Accountability: Institutions should be held responsible for decisions made by the algorithms that they use, even if it is not feasible to explain in detail how the algorithms produce their results.</li><br><li>Explanation: Systems and institutions that use algorithmic decision-making are encouraged to produce explanations regarding both the procedures followed by the algorithm and the specific decisions that are made. This is particularly important in public policy contexts.</li><br><li>Data Provenance: A description of the way in which the training data was collected should be maintained by the builders of the algorithms, accompanied by an exploration of the potential biases induced by the human or algorithmic data-gathering process. Public scrutiny of the data provides maximum opportunity for corrections. However, concerns over privacy, protecting trade secrets, or revelation of analytics that might allow malicious actors to game the system can justify restricting access to qualified and authorized individuals.</li><br><li>Auditability: Models, algorithms, data, and decisions should be recorded so that they can be audited in cases where harm is suspected. </li><br><li>Validation and Testing: Institutions should use rigorous methods to validate their models and document those methods and results. In particular, they should routinely perform tests to assess and determine whether the model generates discriminatory harm. Institutions are encouraged to make the results of such tests public.""</li><br></ol>",Global,Association for Computing Machinery
Artificial Intelligence for Europe,AI in general,Strategy,Accountability; Bias; Labour market effects; Interoperability; Liability;  Investment;,International - EU,4/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/digital-single-market/en/news/communication-artificial-intelligence-europe"">European Commission Communication</a>","This Communication from the European Commission sets out a European initiative on AI, that is meant to boost the European Union’s technological and industrial capacity and uptake of AI, prepare for the socio-economic changes that AI adoption will bring, and provide an appropriate legal and ethical framework.<br>AI is described as a transformational technology that requires a coordinated approach and a solid European framework because the way societies approach AI will define the world people get to live in. Drawing on its strong foundations in values, the EU should lead the way in developing “AI for good and for all.” Unique advantages of the EU are seen in its strong research and startup base, leading industry, the Digital Single Market with common rules, and a large amount of industrial, research and public sector data to build AI applications on. <br>The aim of a European approach to AI is to “maximise the impact of investments at EU and national levels, encourage synergies and cooperation across the EU, exchange best practices and collectively define the way forward to ensure that the EU as a whole can compete globally.”<br><strong>Increasing investment</strong><br>In order to achieve this, the level of public and private investment in AI R&D must reach €20 billion by 2020 in the EU as a whole, up from the 2017 level of €4-5 billion. This level of annual investment should be maintained in the decade from 2020. The Commission will increase its funding by around 70% and it is expected that Member States and the private sector also increase their investments. The Commission will support both basic and industrial research in key areas such as health, connected and automated driving, agriculture, manufacturing, energy, next generation internet technologies, security and public administrations. These efforts will be underpinned by the Commission’s commitment to responsible research and innovation. <br>The Commission will also support AI excellence centres to facilitate networking and collaboration and will launch an “AI-on-demand” platform to ease access of all potential users to AI solutions. The platform will host a knowledge base and provide access to datasets, algorithms, and cloud computing facilities. Access to the platform will be rolled out through the existing network of Digital Innovation Hubs and dedicated AI hubs will be established. <br>The Digital Innovation Hubs will also serve as the basis for setting up a series of testing and experimentation infrastructures for AI products and services, which can help to make products market-ready, ensure compliance with standards and regulations and improve security. This approach also allows policymakers to learn about the technologies and co-develop suitable legal frameworks.<br>Beyond 2020 it will be possible to upgrade the network of AI excellence centres, pursue R&D in explainable AI, unsupervised ML and energy efficiency, as well as launch additional testing and experimentation facilities and regulatory sandboxes, co-invest in AI with Member States, explore join innovation procurement for AI use and development, and for a support centre for data sharing linked to the AI-on-demand platform.<br>With regard to making more data available, the EU already has several initiatives, but further policies should encourage the opening up of privately held data while ensuring the protection of personal data. To advance this, a support centre for data sharing will offer legal and technical support. <br><strong>Preparing for socio-economic changes</strong><br>The strategy discusses the likely impacts of AI on the labour market and highlights three main challenges for Europe in this regard. First, to prepare society as a whole by developing basic digital skills and those uniquely human abilities which are unlikely to be automated, such as creativity, management and critical thinking. Second, to help workers currently in jobs that are likely to vanish or be fundamentally transformed due to AI and automation. Thirdly, the EU needs to train more AI specialists.<br>The EU seeks to ‘leave no one behind’ through adopting a human-centric, inclusive and anticipatory approach that focuses on identifying those roles that are at the highest risk of being automated and supporting people in those roles to acquire new skills. These dedicated retraining schemes will be supported by the European Social Fund and by the Member States. The Commission will also make efforts to anticipate the changes to the labour market and launch a pilot to predict training requirements for future competence profiles, and publish expert recommendations. The Commission will also support Digital Opportunity Traineeships and encourage business-education partnerships to attract AI talent. <br>In the next EU multiannual financial framework (2021-2027) the European Globalisation Adjustment Fund will address job loss resulting from automation and AI.<br><strong>Ensuring an appropriate ethical and legal framework</strong><br>With regard to the ethical and legal framework, the Treaty of the European Union, as well as the EU Charter of Fundamental Rights, provide the foundations of the rights that need to be upheld and protected. The Commission will convene a group of experts and stakeholders to issue draft AI ethics guidelines, which build on these foundations. It will also issue guidance on the interpretation of the Product Liability Directive and publish a report by mid-2019 on broader issues around liability and safety in relation to AI, robotics and IoT. The Commission is also committed to supporting research on explainable AI to ensure that new technologies operate in a transparent and accountable fashion. It will implement a pilot on Algorithmic Awareness Building to support the design of policy measures related to automated decision-making. The Commission will also support consumer organisations and data protection supervising authorities.<br><br><strong>Joining forces</strong><br>Finally, on a joint European effort, the strategy advises all Member States to develop their own national strategies on AI. Cooperation on interoperability, legal harmonisation and the sharing of data sets and best practices is seen as the road to ensuring European competitiveness. The Commission will seek to facilitate dialogue among the Member States to develop a coordinated plan and it will monitor AI-related developments across the Member States. <br>A European AI Alliance is proposed as a broad, multi-stakeholder platform, which will work on all aspects of AI.<br>The Commission will continue to advance international discussions about AI in various fora like the G7/G20, UN and OECD and will promote the use of AI towards the solution of global challenges, in support of the Paris Climate Agreement and for the realisation of the UN’s Sustainable Development Goals.",European Union,European Commission
Coordinated Plan on Artificial Intelligence,AI in general,Strategy,Investment; Labour market effects; Security; Trust; Data quality,International - EU,12/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/digital-single-market/en/news/coordinated-plan-artificial-intelligence"">Coordinated Plan on AI </a>","The document describes AI as a transformational technology that is fundamentally reshaping the world. Building on the principles of the European Strategy published in April 2018, as well as the declaration of cooperation on AI among the Member States, the Commission puts forward a coordinated plan on AI. This coordination extends to “investment, excellence in and diffusion of AI, data availability, societal challenges, ethics and the regulatory framework.” <br>The Commission and Member States will both increase investment in AI to reach €20 billion/year over the next decade. The Commission is increasing the H2020 AI allocation by 70% and will dedicate €1 billion / year to AI R&D in the next multiannual financial framework.<br>Member States are encouraged to develop their own national AI strategies based on national characteristics. Such strategies should describe the level of investment and planned measures of implementation. <br>To maximise investment, the Commission will develop a common strategic research and innovation agenda for AI, with support starting in 2020. This large-scale public-private partnership is expected to foster collaboration between academia and industry across Europe. The Commission will also increase investment in AI and blockchain startups. Disruptive innovation will be supported through a €100 million fund by a European Innovation Council pilot (2019-2020) focusing on areas like human-centric AI. Member States are encouraged to explore various mechanisms to support SMEs in their adoption of AI, such as loans, grants and innovation vouchers.<br>The European research base will also be strengthened and extended through the funding of new AI excellence centers. World-reference testing corridors and large-scale pilots for the integration of AI in energy, healthcare, manufacturing, agriculture and geo-information will also be developed. In addition, the Commission will invest €200 million under the ECSEL Joint Undertaking to integrate AI in its manufacturing, mobility and personalised medicine lighthouse projects. Beyond 2020 €1.5 billion will be made available to establish testing and experimentation sites for AI products and services across Europe, and it is expected that Member States will match this investment.<br>AI take-up by the public and private sector will be supported by the network of Digital Innovation Hubs and the European Institute of Technology. <br>In order to ensure the availability of sufficient AI talent in Europe, the Commission puts forward recommendations for Member States and will engage in a series of activities itself. Member States are encouraged to exchange best practices on retaining talent (e.g. through the Blue Card system) and on re- and upskilling the workforce. They should also prominently include the skills dimension in their national strategies, map the specificities of their labour markets and devise measures to be more inclusive in attracting people to AI fields, explore ways of integrating AI in secondary and tertiary education curricula, and focus on life-long learning as well.<br>Using its existing instruments, like the AI excellence centres and fellowship, the Commission will work towards establishing a unique European brand in industrially-oriented PhDs in AI. It will also support the inclusion of AI modules in other disciplines and work with the Member States on awareness campaigns on the benefits of AI. Beyond 2020, it is proposed that €700 million be made available to support advanced AI and related skills at various levels, from short-term training to Master degrees. This will also provide an opportunity to mainstream the ethical principles in these training programmes.<br>Data is seen as a cornerstone of AI and the Commission proposes the creation of a Common European Data Space. Such a platform must contain data in formats that ensure interoperability and are open, based on FAIR principles, machine readable, standardised and documented. Member States are encouraged to identify public data sets and make them reusable across the Union, in line with the Public Sector Information Directive. Invest in tools for the aggregation, access and interoperability of datasets, including the development of APIs. This work will include the creation of data and metadata standards. The creation of a data infrastructure will be supported, which enables sandbox experimentation with data-driven services. Blockchain-based solutions are also to supported to ensure secure solutions for accessing data. <br>Health is treated as a primary field of application that can benefit from applying AI. The Commission will link genomics repositories and support the development of a common database of health images to provide a larger data set for training AI systems. This will form the basis of a larger health data space to be launched in 2021. Other datasets to be made expanded are the EU’s geo-information, Earth Observation and linguistic datasets. Building on the EC’s ""Towards a common European data space"" initiative, which contains guidelines for the sharing of industrial and personal data, the Commission will further support next-generation digital industrial platforms and support the connection of national initiatives with EU-level activities. <br>The Commission will launch a Support Centre for data sharing to help the private sector with advice and best practices on data sharing and analytics.<br>The Commission seeks to spearhead the ethics agenda to attain a competitive edge while protecting the fundamental rights and freedoms of citizens. A final version of the High-Level Expert Group guidelines on AI will be ready by March 2019, following broad consultation through the European AI Alliance network. <br>A key principle is ‘ethics by design’, which entails that key ethical and legal standards are ‘baked into’ product development from the beginning of the design process. This principle will be a part of future calls for proposals on AI by the Commission. The Commission is also assessing the suitability of existing legislation and will publish a report on the safety and liability framework for AI. Moreover, starting in 2019 the Commission will work with the Member States to conceptualise regulatory sandboxes and testing environments, which are to be established by the end of 2020. <br>Another key area is AI in the public sector. The Commission will scale-up current investments to expedite the adoption of AI in areas such as healthcare, transport, security and education. Member States are encouraged to explore areas for joint procurement of AI solutions and to work with the Commission on implementing AI-enabled experiments to understand the value of AI in policy-making and public services. Finally, the Member States and the Commission are planning to use AI solutions to support evidence-based policymaking in areas like climate change, environmental protection, migration, agriculture and urban development.",European Union,European Commission
Declaration of Cooperation on ‘AI for Europe’,AI in general,Declaration ; International agreement,Labour market effects; Privacy; Transparency; Accountability,International - EU,4/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/jrc/communities/sites/jrccties/files/2018aideclarationatdigitaldaydocxpdf.pdf"">Declaration text</a>","The Declaration builds past European efforts around artificial intelligence, as well as on the Digital Single Market initiative. <br>Participating Member States agree to cooperate on:<br>[ul]<br><li>“Boosting Europe's technology and industrial capacity in AI and its uptake, including better access to public sector data;</li><br><li>Addressing socio-economic challenges, such as the transformation of the labour markets and modernising Europe's education and training systems, including upskilling & reskilling EU citizens;</li><br><li>Ensuring an adequate legal and ethical framework, building on EU fundamental rights and values, including privacy and protection of personal data, as well as principles such as transparency and accountability.”</li><br>[/ul]",European Union,EU Member States
Analysis of the Development Potential of Artificial Intelligence in the Czech Republic,AI in general,Report,Labour market effects; Retraining; Education; Privacy; Transparency;,National,12/20/2018 0:00,"<a target=""_blank"" href=""https://www.vlada.cz/assets/evropske-zalezitosti/aktualne/AI-Summary-Report.pdf"">AI report for the Office of the Government of the Czech Republic</a>","The Czech Republic’s Office of the Government commissioned a group of 15 experts from the Technology Centre CAS, the Czech Technical University in Prague and the Institute of State and Law of the Czech Academy of Sciences to produce a report about the development potential of AI. <br>The report surmises that the expected economic benefit of automation amounts to a 3.9% annual growth rate over the next 16 years, which is twice the rate of the comparator scenario where no additional automation takes place. It also cites the transformational effects AI will have on the labour market of the country. <br>The report advises the creation of a national strategy, which should cover 4 key domains: <br>[ul]<br><li>“How can the public and private sectors ensure that businesses and research institutions receive the necessary support for the development and deployment of AI-based innovations so that the AI potential is fully exploited in terms of competitiveness and economic growth?”</li><br><li>“How can the public sector exploit the potential offered by AI in its own activities to provide high quality public services effectively? How can data-oriented businesses benefit from the secondary use of public sector information sources?”</li><br><li>“How will AI influence us as individuals and what impact will it have on the labour market? What will be its wider impact on society and how to prepare for it? How can we ensure that our social structures adapt to the changes brought by AI and that we continue to be a well-functioning, prosperous society?”</li><br><li>“What new ethical and legal issues does AI cause and how should society and the legal system be prepared for their implementation? What regulatory measures should be addressed by the public sector at the time of the rise of AI?”</li><br>[/ul]<br>The Government had funded 3 separate studies to address these questions and a set of recommendations on supporting R&D for AI, on issues related to the labour market, retraining and education, and on the topic of regulation has been put forward.<br>On R&D, the report recommends that the Czech Republic invest in the startup ecosystem to support SMEs working on AI-related technologies. Support might take the form of simplifying legislation for new businesses, helping companies into foreign markets, strengthening local venture capital and using accelerators and incubators. In addition, grants should support young researchers to translate their work into businesses and applications. Innovations hubs should also be supported because they act like bridges among different actors in the AI ecosystem. Data to train AI systems should be made easily available to companies as part of a cross-sectoral cooperation among businesses and the university sector.<br>Measures should be put in place to help Czech research get translated into practice, including a revision of existing intellectual property laws that could incentivize research organisation to try more experimental applications. <br>The document also suggests that more experimentation with AI technologies should be encouraged via incubators, hubs and accelerators. In addition to focusing on products brought to market, it is suggested that platforms for the creation and enrichment of AI training data should be supported.<br>The country should invest in attracting top foreign AI researchers, develop intersectoral mobility schemes and introduce AI-related modules into various educational curricula, even in non-computer science degrees.<br>The country must use its limited resources in a very efficient and impact-driven manner and AI should be incorporated into the key digitalization strategies. Furthermore, a national AI strategy should be developed.<br>With regard to the labour market, policymakers must devise measures to support individuals whose job market prospects become insecure, or who find employment in roles that provide low social security protections. The impact of automation on working hours must also be assesses, and work opportunities supported especially in regions the unfavourable impact of automation will be highest. The state should develop a supported lifelong learning and vocational education system, focused on technology and soft skills, as well as support the acquisition of digital skills and retraining. For vulnerable workers, a complex system of retraining should be developed. <br>Sweeping reforms of the whole educational system are suggested to support the acquisition of new technical skills, including measures to increase the social status of teachers and adopting AI tools to increase the quality of education by monitoring learners’ progress and freeing up teachers from routine assignments. <br>Steps are also suggested towards effectively supporting entrepreneurship, developing fair competition, regulatory and tax policies (including international cooperations), and reacting to the reliance on international technology companies. Local public-private partnerships mechanisms should be created. The report urges the Government to take part in international efforts to accurately monitor and measure the impact of automation and digitisation on the labour market.<br>With regard to regulation, the report advises that stakeholder-informed, flexible regulations should support legislative activities, and that the country should participate in the creation of international legal framework and ethical and technical standards. <br>Recognising that different industries have specific needs, the report recommends supporting industry self-regulation through ethical codes of conduct, ‘best practices’ for areas like cybersecurity and data processing, and certification to increase certainty regarding compliance with legal norms.<br>The report advises that regtech efforts, which can help achieve legal compliance or ensure the effective functioning of the law should be supported. As part of this, the development of technical solutions, similar to the electronic IDentification, Authentication and trust Services, to AI transparency is mentioned. Further, technical solutions for ensuring compliance with data processing requirements should be developed. An informational self-determination tool for managing a person’s data and privacy rights should also be developed. <br>The report suggests that interpretation guidelines on how certain - usually vague - pieces of legislation are to be understood can reduce uncertainty without the need for changing legislation. This may include issues like contractual liability through model contracts, tort liability through interpretation guidelines, and administrative and criminal liability. In addition, interpretation guidelines for the GDPR, especially in relation to the requirement to provide meaningful information should, and information materials about the risks of AI should also be created. <br>The report also suggest a few specific amendments to existing codes, for example to cover the use of automated decision-making in the justice system, or to permit autonomous vehicle testing. <br>It is advised that a dedicated centre be set up to continuously monitor the impacts of AI developments on society, to regularly assess the impact of regulation on various key areas, such as autonomous mobility, fintech, etc, and to cooperate with all relevant stakeholders. The aim is to be able to adapt regulation as and when necessary.<br>Finally, the report suggests that “in the future” regulatory sandboxes and data trusts should be established.",Czechia,Office of the Government of the Czech Republic
Draft Ethics Guidelines for Trustworthy AI,AI in general,Ethics guidelines,Accountability; Bias; Transparency; Human control; Explainability; Data quality; Fairness; Safety; Diversity; Privacy; Inclusion; Testing; Validation,International - EU,12/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=56433"">HLEG Draft AI Guidelines</a>","The Draft Ethics Guidelines for Trustworthy AI were produced by the European Commission’s High-Level Expert Group on Artificial Intelligence. The group is comprised of 52 representatives from academia, civil society and industry, and it was put together through an open selection process. The Group had been tasked with creating ethics guidelines  as well as policy and investment recommendations. The present document is a draft of the first deliverable, a final version of which is scheduled for March 2019. The second deliverable is due in May 2019.<br>The report describes AI as “one of the most transformative forces of our time” that has the potential to create enormous societal benefit while harbouring significant risks. In order to minimise the risks and maximise the benefits, the Group proposes the notion of human-centric, Trustworthy AI, which is built on two fundamental components: a strong “ethical purpose”, and robust technical implementation. According to the report, trust is an absolute prerequisite for developing AI for the benefit of individuals and societies. Trust is required towards 3 interdependent layers, the technology, the rules, laws and norms governing the technology, as well as the business and public governance models of various AI providers. <br>The Guidelines offer a complete framework for Trustworthy AI, unfolded in 3 increasingly concrete steps. First, the basic ethical principles are outlined, followed by guidance on their realisation, covering both technical and non-technical aspects, and finally, an assessment list is provided to ensure operationalisation. The document’s intended audience includes all relevant stakeholders, both private and public. The guidelines are not intended to stand in place of regulation or policy-making but are intended to inform such efforts. While the guidelines offer general principles, the report stresses that it is necessary to tailor them to the specific context of application.<br>Starting with “ethical purpose”, the guidelines emphasise that the EU’s rights’ based approach should be followed. According to this, the EU Treaties and the Charter of Fundamental Rights provide the basis for defining the ethical principles, which are then operationalised. The rights to be respected are dignity, freedoms, equality and solidarity, citizens’ rights and justice. These rights together constitute the EU’s human-centric approach, which must be upheld in all law-making. This approach also ensures that an ethical lens is applied when evaluating how technology <em>should</em> be used, rather than just considering how it <em>could</em> be used. A further advantage of this approach is that it reduces regulatory uncertainty because clear norms exist. In its adoption of a fundamental rights’ framework, the HLEG follows in the footsteps of the Oviedo Convention, which took a similar approach in relation to medical technologies, upholding the “primacy of the human being.” <br>It is this respect for fundamental rights, which constitutes the “ethical purpose” that is one of the two key elements of Trustworthy AI.<br>Drawing on a review of other ethics framework that took a fundamental rights’ approach conducted by AI4People, the HLEG lists 5 overarching principles that must be observed to ensure human-centric AI. <br>[ul]<br><li>The Principle of Beneficence / “Do Good” - AI systems should be deployed towards the collective good and the resolution of the world’s challenges</li><br>[/ul]<br>[ul]<br><li>The Principle of Non-maleficence/ “Do No Harm” - The report takes a very comprehensive view of harms when stating that AI systems should not harm humans. Included are physical, psychological, financial and social harms. This extends to the protection from “ideological polarization and algorithmic determinism.” Vulnerable groups should receive increased protections and there is also a requirement to pursue AI in an environmentally friendly way.</li><br>[/ul]<br>[ul]<br><li>The Principle of Autonomy / “Preserve Human Agency” - “Human beings interacting with AI systems must keep full and effective self-determination over themselves.” This includes the right to decide whether to be subject to AI-based decision-making. Vulnerable groups might require government or non-government support to ensure self-determination, and adequate measures must be in place to guarantee the accountability of AI systems.</li><br>[/ul]<br>[ul]<br><li>The Principle of Justice / “Be Fair” - This includes ensuring that AI is bias-free and that its benefits and harms are distributed evenly across society. Redress must be provided to those who suffer harms as a result of AI, and developers must be held to high standards of accountability.</li><br>[/ul]<br>[ul]<br><li>The Principle of Explicability / “Operate transparently” - Technological and business models must both be sufficiently transparent to enable citizen’s trust. Technologies must be auditable and intelligible to humans of various levels of expertise, while business model transparency implies that users are informed of the intentions of platform implementers. The report also stresses the importance of informed consent, which is predicated on explicability and also calls for accountability measures to be put in place.</li><br>[/ul]<br>There is no stated hierarchy among these principles and they may sometimes be in conflict with each other when viewed from different perspectives. No fixed mechanism exists for the resolution of these conflicts or for the ordering of the principles. Therefore, the guidelines suggest that developers should rely on ethical expertise when designing, developing and deploying AI systems.<br>The report goes on to briefly discuss a few specific applications of AI that might raise special concerns, such as AI-based identification without consent, covert AI systems, mass citizen scoring, lethal autonomous weapon systems, and Artificial General Intelligence. The public’s input is solicited on these issues as the HLEG could not reach consensus, however, the report expresses support for the EU Parliament’s resolution calling for a legally binding instrument prohibiting lethal autonomous weapon systems.<br>Moving on from the abstract ethical principles to the realisation of Trustworthy AI. The guidelines list 10 equally important requirements derived from the previously discussed rights and principles:<br><ol><br><li>Accountability </li><br><li>Data Governance </li><br><li>Design for all </li><br><li>Governance of AI Autonomy (Human oversight) </li><br><li>Non-Discrimination </li><br><li>Respect for (& Enhancement of) Human Autonomy</li><br><li>Respect for Privacy</li><br><li>Robustness</li><br><li>Safety</li><br><li>Transparency </li><br></ol><br>The guidelines propose both technical and non-technical measures to implement these requirements. There should be an ongoing assessment of the degree to which the requirements are fulfilled. Given that AI systems themselves continuously change, achieving Trustworthy AI is also a continuous process. <br>Technical methods include:<br>[ul]<br><li>Ethics and rule of law by design - this entails incorporating compliance with legal and ethical norms into the design process, such as Privacy-by-design and Security-by-design. This requires developers to identify the likely impacts of their systems from early on.</li><br>[/ul]<br>[ul]<br><li>Architectures for Trustworthy AI - entails formulating rules or behaviour boundaries that ensure that system acts in line with ethical principles.</li><br>[/ul]<br>[ul]<br><li>Testing & validating - should begin as early as possible and be iterative to ensure the systems behaves as intended. Testing should include all inputs to the system, including pre-trained models, and it should be undertaken by a diverse group of people using multiple metrics.</li><br>[/ul]<br>[ul]<br><li>Traceability and auditability - decisions at every step of the design process should be documented to ensure transparency and explainability. Human-machine interfaces that assist in understanding the causality of algorithmic decision-making, as well as internal and external auditors can help ensure explainability and further trust. </li><br>[/ul]<br>[ul]<br><li>Explanation (XAI research) - can help address the opacity of neural nets and make their operation more semantically transparent</li><br>[/ul]<br>Non-technical methods include should also be evaluated on an ongoing basis and include:<br>[ul]<br><li>Regulation to ensure trust and guarantee redress when harms occur;</li><br><li>Standardization can act as instruments of quality management;</li><br><li>Accountability governance through internal or external methods, such as appointing an ethics panel to provide oversight and advice;</li><br><li>Codes of conduct and the adaptation of internal KPIs to reflect a commitment to Trustworthy AI </li><br><li>Education and awareness to foster an ethical mind-set, which requires properly trained ethicists in this space;</li><br><li>Stakeholder and social dialogue on the use and impact of AI to help review results and approaches and spread awareness of AIs benefits and risks;</li><br><li>Diversity and inclusive design teams to ensure the consideration of different perspectives.</li><br>[/ul]<br>Finally, the guidelines offer a preliminary assessment list to help operationalist the implementation of the requirements outlined earlier. The list proposes questions that the development team should consult at every stage of the design process. In the draft version of the guidelines, public input is sought on the questions and it is expected that the final guidelines will consider several use-cases to illustrate how the assessment list can be applied. It is emphasised that the assessment is an ongoing process and that it needs to be tailored to the particular application and context at hand. <br>Assessment is envisaged as a circular process where assessment is never conclusive. The model will include metrics associated with each question, and specific measures to ensure Trustworthy AI.",European Union,High-Level Expert Group on Artificial Intelligence
Resolution on autonomous weapon systems,Lethal autonomous weapon systems,Resolution,Human control; Safety;,International - EU,9/12/2018 0:00,"<a target=""_blank"" href=""http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//TEXT+TA+P8-TA-2018-0341+0+DOC+XML+V0//EN&language=EN"">Text of the Resolution</a>","The Resolution was adopted with over 80% of MEP’s voting in favour of it. <br>The document cites several earlier positions, recommendations and resolutions that have called for a complete ban on the development, production and use of fully autonomous weapons. <br>It cites several reasons, stating that Lethal Autonomous Weapon Systems (LAWS) lack meaningful human control over the selection of targets, they have the potential to trigger an arms race at a previously unprecedented rate, they raise fundamental ethical and legal questions of human control and the implementation of international human rights law and other values with regard to the military, they pose the risk of malfunction on hacking, and that humans should remain in control and accountable for lethal decision. <br>The Resolution urges the adoption of a common position on LAWS and to work on a legally binding instrument prohibiting lethal autonomous weapon systems and preventing their development and production. This is further justified by the EU’s commitment to act as a force for global peace and disarmament. <br>The resolution exempts teleoperated systems and existing weapons like air-defence systems from the category of LAWS, and states that engagement decisions against human-inhabited aircraft should be taken by human operators.",European Union,European Parliament
AI in the Nordic-Baltic region,AI in general,International agreement,Data; Standards; interoperability; Privacy; Trust;,International - Multilateral,5/1/2018 0:00,"<a target=""_blank"" href=""https://www.regeringen.se/49a602/globalassets/regeringen/dokument/naringsdepartementet/20180514_nmr_deklaration-slutlig-webb.pdf"">Declaration</a>","The ministers responsible for digital development in Finland, Denmark, Estonia, the Faroe Islands, Iceland, Latvia, Lithuania, the Åland Islands, Norway and Sweden have signed an agreement, which welcomes the Artificial Intelligence for Europe strategy and the Declaration of Cooperation on AI. Recognising the significant economic benefits that AI might bring to the Nordic-Baltic countries as well as its serious risks, the ministers agreed to “develop and promote the use of artificial intelligence to serve humans better.” The cooperation will be led by the Swedish Government. <br>The countries agreed to cooperate on:<br>[ul]<br><li>skills development to support AI adoption;</li><br><li>enhancing  access to data;</li><br><li>developing ethical and transparent guidelines, standards, principles and values; </li><br><li>ensuring that all infrastructure, including hardware, software and data are based on standards, “enabling interoperability, privacy, security, trust, good usability, and portability”;</li><br><li>supporting the implementation of AI initiatives in the EU’s Digital Single Market;</li><br><li>avoiding unnecessary regulation; </li><br><li>Utilising the Nordic Council of Ministers for collaboration in relevant policy areas.</li><br>[/ul]",Denmark; Estonia; Finland; Faroe Islands; Iceland; Latvia; Lithuania; Norway; Sweden; Aland Islands,Nordic Council of Ministers
Taiwan AI Action Plan,AI in general,Strategy,,National,1/1/2018 0:00,"<a target=""_blank"" href=""Taiwan AI Action Plan"">Taiwan AI Action Plan</a>","Taiwan’s Premier announced that over a 4-year period an investment on the order of $300m will be made to boost the nation’s AI industry. The proposed action plan builds on Taiwan’s existing strengths in hardware manufacturing, its thriving SME ecosystem, strong ICT innovation in several verticals, and its #1 position on the Global Open Data Index.<br>The Action Plan describes 5 initiatives:<br>The strand “AI for Industrial Innovation” will assist SMEs to develop AI applications through pilots, data platforms, test fields and regulatory co-creation processes. It will also seek to attract international companies to establish up AI research centers in Taiwan. Open research open research platforms will be created and the government will promote industry standards with IoT Integration Service Center (IISC) in order to support SMEs with a “one-stop supporting service for deploying AI applications.” In addition, efforts will be made speed up AI adoption by SMEs. Sever pressing topics are identified, which should be matched to AI talent to develop 100+ solutions. The pressing topics are smart machinery, Asia-Silicon Valley, biomedical industry, renewable energy, defense industry, new agriculture, circular economy.<br> <br>Under the “AI International Innovation Hub” 100 AI-related startups will be supported, the country’s connections to global venture capital expanded, and international cooperation among academia and businesses strengthened, with a view to driving IP in AI.<br>Under “AI Pilot Project”, the Action Plan suggests the adoption of models similar to DARPA in the US and SIP in Japan in order to “focus research and discover niche advantages for development.” This entails hosting competitions on topics selected by an expert committee, and also welcoming international R&D teams. The National AI Forward-Looking Network is also to be established, which would incorporate the relevant university training programs to train a diverse pool of talents and integrate with the international community to attract researcher “elites” from abroad.<br>As part of the “AI Talent Program,” 1000 high-calibre “elite” experts in intelligent technologies should be trained by 2021, along with 10 000 “pioneers” in intelligent applications. This work package would also include measures to recruit and retain global AI talent. A complete training pipeline is proposed, spanning demand investigation and curriculum planning, training implementation in collaboration with major international companies, and talent certification at multiple levels.<br>Finally, the “Test Fields and Regulatory Co-Creation” stream sketches that test fields for intelligent application should be established in several domains, including unmanned vehicles, IoT for public welfare, AI cyberservices, and government services. <br>Several pieces of legislation are listed, which fall into one of 4 categories:<br>[ul]<br><li>Legislation passed already to enable “open fields and data for testing”, such as Financial Technology Development and Innovation Experimental Regulations, Recruitment and employment of foreign experts</li><br><li>Planning completed or under deliberation by the Legislature, such as Unmanned Vehicle technology innovation experimental regulations, Information security management legal system</li><br><li>Under discussion are pieces of legislation on regulatory sandboxes, government procurement, coping and adjustment in industrial management regulations, and applications of telecommunication spectrum resources</li><br><li>To be analyzed are the topics of open data, employment market cushion mechanisms, rights and obligations derived from AI applications, regime law on AI in administrative functions, consumer protection for AI applications, and regulations restriction for AI applications.</li><br>[/ul]",Taiwan,Government of Taiwan (Executive Yuan)
AI for Humanity - French Strategy for Artificial Intelligence,AI in general,Strategy,Open data; Sandboxes; Transparency; Explainability; Labour market effects; Sustainability; Audit; Impact assessment;,National,3/1/2018 0:00,"<a target=""_blank"" href=""https://www.aiforhumanity.fr/en/"">French AI Strategy</a><br><a target=""_blank"" href=""https://www.aiforhumanity.fr/pdfs/MissionVillani_Report_ENG-VF.pdf"">Villani report</a>","The strategy was presented by French President, Emmanuel Macron on 29 March 2018 at the Collège de France, in Paris. The strategy is derived from the so-called Villani-report, produced by french mathematician and Member of Parliament, Cedric Villani, who was commissioned by the French Prime Minister in September 2017 to lay the foundations of an AI strategy. With this, France was among the first countries to start working on a The report’s full title is “For a Meaningful Artificial Intelligence - Towards a French and European Strategy.” <br>The French strategy - AI for Humanity - contains three central commitments and a number of specific measures to implement them.<br>First, the government will make a €1.5 billion investment over the next 5-year period in order to strengthen the country’s research base and support the AI ecosystem. Second, the government will take steps to make the country’s massive centralised datasets available for the purposes of innovation. Third, an ethical framework will be erected to deal with the challenges of AI.<br>There are 7 main recommendations adapted from Villani report.<br><ol><br><li>Developing an aggressive data policy is proposed as a means of attaining sovereignty and strategic autonomy from the major US, Chinese and Russian data giants. As part of this policy, the government must encourage companies to pool their data into sectoral data commons based on the principle of reciprocity, cooperation and sharing. The right to data portability should also be supported, whereby citizens could grant government authorities or researchers access to their data, following GDPR guidelines. </li><br><li>Targeting four strategic sectors, where France (and Europe) already excel: health, transport, the environment, defence and security. In these areas, sector specific policies should be implemented that focus on the major issues. Furthermore, platforms should be established to “facilitate innovation by creating controlled environments for experiments.” Finally, sandboxes should be implemented, which temporary ease the regulatory burden to help innovators conduct mini tests in ‘real-life’ conditions.</li><br><li>Boosting the potential of French research in order to meet the challenges of ‘brain drain’ and the low transfer of research into applications. As a remedy, interdisciplinary AI institutes should be established across France, and appropriate resources, like a dedicated supercomputer, should be made available. Furthermore, pursuing a career in research should be made more attractive to attract and retain talent.</li><br><li>Planning for the impact of AI on labour. Three concrete measures are proposed. The creation of a public laboratory on the transformation of work could study labour market changes as well as support those affected by transitions. In particular, complementarity between humans and machines should be prioritised and new methods of funding vocational training explored.</li><br><li>Making AI more environmentally friendly. The strategy clearly references climate change as an indisputable reality that may both exacerbated and mitigated through increased digitisation. To this end, the government must be committed to contributing to a ‘smart ecological transition’ by launching a research centre dedicated to this topic and implementing a platform to measure and monitor the impact of smart digital tools on the environment. Moreover, the government must support initiatives, like the greening of the European cloud industry. Finally, ecological data up to 2019 must be made open and widely available to support the development of AI-based solutions.</li><br><li>Opening up the black box of AI. Algorithm transparency and mechanisms to audit them must be developed to ensure that AI is socially acceptable. More explainable models, intuitive user interfaces and understanding the conditions for satisfactory explanations form aspects of this work. In order to create a sense of responsibility, ethics training should be mandatory for AI engineers and researchers, and discrimination impact assessment should form part of algorithm development. A consultative ethics committee on AI and digital technologies should be established, as well as broad and regular public dialogue initiatives undertaken. Finally, human responsibility for the use of AI tools must be maintained.</li><br><li>Ensuring that AI supports inclusivity and diversity. It is proposed that by 2020 the proportion of women enrolled in digital engineering courses should be raised to 40%. A government system to automatically manage administrative procedures could be launched in order to improve citizens’ access to rights in a personalised manner and to increase public knowledge of administrative rules. Simultaneously, human mediation tools should be developed. Lastly, AI-based social innovations should be supported.</li><br></ol>",France,French Government
UAE Strategy for Artificial Intelligence,AI in general,Strategy,,National,10/1/2017 0:00,"<a target=""_blank"" href=""https://government.ae/en/about-the-uae/strategies-initiatives-and-awards/federal-governments-strategies-and-plans/uae-strategy-for-artificial-intelligence"">UAE Strategy</a> ; <a href=""http://www.uaeai.ae/en/"" target=_blank>UAE AI</a>","In October 2017 the UAE Government released an AI strategy. It is meant to support the achievement of the goals laid out in the UAE Centennial 2017, which aspires to make the UAE “the best country in the world” by 2017. This is to be achieved through creating a future-focused government, excellent education, a diversified knowledge economy and a happy and cohesive society underpinned by an Emirati moral system. The AI strategy is meant to boost government performance, make the UAE a leader in AI investment in certain areas, create new markets and use “an integrated smart digital system that can overcome challenges and provide quick efficient solutions.”<br>Key sectors are specified: transport, health, space, renewable energy, water, technology, education, environment, and traffic.<br>The strategy also calls for the creation of an AI Council - which was launched in March 2018, headed by Omar bin Sultan Al Olama, Minister of State for Artificial Intelligence, as well as plans to issue a law on the safe use of AI.",United Arab Emirates,UAE Government
Ethics Commission: Automated and Connected Driving,Autonomous mobility,Ethics guidelines,Safety; Responsibility; Precaution; Liability; Data ownership; Accountability,National,6/1/2017 0:00,"<a target=""_blank"" href=""https://www.bmvi.de/SharedDocs/EN/publications/report-ethics-commission.pdf?__blob=publicationFile"">Ethics Guidelines</a>","The Ethics Commission is a body of experts from the fields of philosophy, jurisprudence, social sciences, technology impact assessment, the automotive industry and software development. They were commissioned in 2016 by the Federal Minister of Transport and Digital Infrastructure to develop guidelines for the application of automated vehicles. <br>They proposed the following 20 principles:<br><ol><br><li>Automation must ultimately serve the “safety of all road users.” This guideline might never breach the legal principle of personal autonomy. The individual must always enjoy their full freedom of action, for which they are responsible.<br></li><br><li>No “utilitarian consideration” shall overwrite the protection of individuals. This entails that the only goal of automation is to decrease harm in human driving until it is completely eradicated. The method for this should be the prohibition of issuing of licenses as long as the particular technology does not justifiably reduce harm.<br></li><br><li>The public sector should be responsible for guaranteeing safety by deciding over licenses and continuous monitoring.<br></li><br><li>In order to uphold personal responsibility and the possibility for personal development, regulatory policies should promote the “free development and the protection of individuals”, which must be balanced against the freedom and safety of others.<br></li><br><li>Automated and connected technology should prevent accidents with the aim of creating technology that could avoid all-in-all the emergence of such situations. To solve possible “dilemma situations, the entire spectrum of technological options” is allowed to be applied.<br></li><br><li>It can be “socially and ethically mandated” to introduce more highly automated driving systems to mitigate the potential for damage. However, it is “ethically questionable” to legally prescribe the use of fully automated transport systems, “if it entails submission to technological imperatives.”<br></li><br><li>In hazardous situations, human lives may always enjoy utter priority. Damages to animals and property are accepted.<br></li><br><li>“Genuinely dilemmatic decisions” cannot be standardized, complex, intuitive assessment must lie in the driver and in his/her moral capacity. The establishment of an independent advisory agency might be useful to assess general patterns of culpability stemming from the experiences of automated driving.<br></li><br><li>There are no acceptable ways of discrimination in an accident and “it is also prohibited to offset victims against one another.”<br></li><br><li>When it comes to automated and connected driving systems, responsibility and culpability shift completely to the manufacturers and operators.<br></li><br><li>“Liability for damage caused by activated automated driving systems is governed by the same principles as in other product liability”<br></li><br><li>The general public has a right to be informed about new technologies and their deployment.<br></li><br><li>The complete connectivity and central control of motor vehicles of digital transport infrastructure are ethically questionable and should be avoided. However, only if it can only lead to “total surveillance of road users and manipulation of vehicle control.”<br></li><br><li>Automated driving should not harm people’s confidence in road transport, otherwise, it is not justifiable.<br></li><br><li>The vehicle keepers and users may alone, voluntarily decide about the usage and handing over of their data.<br></li><br><li>To ensure accountability, it must always be clear, who drives: the machine or the human. In the case of non-driverless systems, the human-machine interface must be designed in a way that it is always obvious, who has the responsibility for control.<br></li><br><li>An “abrupt handover of control” must always be possible and this should serve as a basic principle for design.<br></li><br><li>“Self-learning systems must not be deployed unless they meet the safety requirements regarding functions relevant to vehicle control and do not undermine the rules established here”<br></li><br><li>In emergency situations, the vehicle must autonomously, i.e. without human assistance, enter into a “safe condition”.<br></li><br><li>The proper use of automated systems should form part of people’s general digital education.<br></li><br></ol><br>The Commission also provided a detailed analysis of a series of unresolved issues with regard to automated driving.<br>",Germany,Federal Ministry of Transport and Digital Infrastructure
"Statement on Artificial Intelligence, Robotics and ‘Autonomous’ Systems",AI in general,Ethics guidelines,Accountability; Bias; Sustainability; Responsibility; Autonomy; Labour market effects; Privacy;,International - EU,3/1/2018 0:00,"<a target=""_blank"" href=""http://ec.europa.eu/research/ege/pdf/ege_ai_statement_2018.pdf"">EGE Statement</a>","The manuscript is issued by the European Group on Ethics in Science and New Technologies, which is an independent advisory body of the President of the European Commission. The paper consistently refers to itself as being a “statement” and has the aim of laying down the basic moral principles for future international law on the use and governance of artificial intelligence, robotics, and autonomous systems. It also believes that the EU must play a defining and leading role in the crafting of this more comprehensive international law.<br>The issuing of the statement was motivated by the ever-growing “opaque” mode of operation of the various autonomous technologies, and by the fear of a fragmented or unharmonized way of AI regulation (“regulatory patchwork”) within the European Union. This latter was the more important consideration behind the globally focused statement, since the basic principles and democratic prerequisites that the manuscript sketches are “based on the fundamental values laid down in the EU Treaties and in the EU Charter of Fundamental Rights.”<br>These ethical principles and democratic prerequisites are: 1) human dignity; 2) autonomy; 3) responsibility; 4) justice, equality, and solidarity; 5) democracy; 6) rule of law and accountability; 7) security, safety, bodily, and mental integrity; 8) data protection and privacy; 9) sustainability.<br>1) The principle of human dignity should limit the use of AI in respect to making classifications and determinations about human beings based on algorithms and autonomous technologies. Human beings should be informed about the use of autonomous technologies when they could be affected by their application. Persons should also know, whether they are interacting with an actual human being or with a machine.<br>2) The principle of autonomy prescribes that human beings should have control over and knowledge about autonomous systems. Human beings should be able to set their own norms and standards and to live a life based on the principles they established for themselves. Persons should be able to make their own decisions and take actions alone. However, if these actions and decisions were delegated to autonomous technologies, humans should be in absolute control over their “when” and “how.” This entails that autonomous systems should be transparent and predictable.<br>3) The principle of responsibility should be the guiding principle for AI research and application. This means that future development should align with the global social and environmental preferences of the nations of the world, which should be defined through a democratic process. Fundamental human values and rights should never be endangered, and the application of AI and robotics should never “pose unacceptable risk of harm” and should not “compromise human freedom and autonomy,” especially by limiting options for, and awareness of citizens.<br>4) The principles of justice, equality, and solidarity entail that AI should contribute to global justice with benefits accessible for all. To achieve this, first, the creation of biased data sets for AI systems should be prevented. Second, the global accessibility to core AI technologies should be ensured in order to provide fair distribution and benefit sharing coming with the hardships of the economic transformations that automation, digitalization, and AI bring.<br>5) The future regulation of AI development and application should be the outcome of deliberative democratic debates because only this can guarantee an “inclusive, informed, and farsighted manner.” The pluralism and diversity of democratic societies “must not be jeopardized, subverted, or equalized by new technologies,” therefore, the freedom of expression and the right to receive information should always be guaranteed.<br>6) To implement in practice the concept of and to protect the different human rights, the rule of law and accountability must always prevail. Within the developing new field of AI regulation, governments must invest in the creation of “robust solutions” that ensure a “fair and clear” distribution of responsibilities.<br>7) When it comes to the principles of security, safety, bodily and mental integrity in relation to autonomous systems, the following three forms are given extra care by the statement: first, the external safety; second, reliability and internal robustness; and three, emotional safety with respect to human-machine interaction. These areas should be taken into account by AI developers before release. Special attention should also be paid to people in a vulnerable position and to the weaponization of AI.<br>8) Physical AI robots as part of the Internet of Things and AI softbots that operate via the World Wide Web must comply with data protection regulations and not spread and collect data without informed consent in order to protect personal information and the right to privacy. The manuscript enlists three rights that belong to the right of private life and should be respected by the operation of autonomous systems: first, the right to be free from technologies that influence personal development and opinions; second, the right to establish and develop relationships with other human beings; and third, the right to be free from surveillance. It also opens the debate, whether the right to private life should be enriched by the following two new rights: the right to meaningful human contact and the right not to be profiled, measured, analyzed, coached or nudged.<br>9) Priority must also be given to policies of environmental protection and sustainability when designing future AI regulation, since humans have a responsibility to ensure basic the preconditions for life on the planet.",European Union,European Group on Ethics in Science and New Technologies
Principles for Accountable Algorithms and a Social Impact Statement for Algorithms,Automated Decision Systems,Proposal,Accountability; Impact assessment; Fairness; Explainability; Auditing;,International - Global,7/1/2016 0:00,"<a target=""_blank"" href=""http://www.fatml.org/resources/principles-for-accountable-algorithms"">FAT/ML Principles </a>","FAT/ML is an annual conference launched in 2014 to address issues of fairness, accountability and transparency in machine learning. The principles were developed as part of the Dagstuhl seminar, “Data, Responsibly”.<br>The document has a clear and direct premise that the editors believe should serve as the foundational ethical ideal for designing and implementing algorithmic systems in “publicly accountable ways.” This premise is the following:<br>“Algorithms and the data that drive them are designed and created by people -- There is always a human ultimately responsible for decisions made or informed by an algorithm. ""The algorithm did it"" is not an acceptable excuse if algorithmic systems make mistakes or have undesired consequences, including from machine-learning processes.”<br>From the declaration of ultimate human responsibility, equally important other principles are derived, the implementation of which could help create accountability in the development of algorithmic systems: 1) responsibility; 2) explainability; 3) accuracy; 4) auditability; 5) fairness.<br>Adhering to these principles should contribute to the mitigation of negative social impacts and to the establishment of an “obligation to report, explain, or justify” algorithmic decision-making, both being declared to be constitutive parts of accountability within the field of designing and implementing algorithmic systems.<br>The definition of these five principles are internationally very concise, all of them being no longer than just one sentence. The idea behind this was “to allow these principles to be broadly applicable.” Their implementation, however, should always be case and context specific.<br>The document includes a call to action targeting algorithm creators, inviting them to lay down a “Social Impact Statement” based on these five principles. The Statement should be “revisited and reassessed” at least three times: during the design stage, during the pre-launch stage, and during the post-launch phase. The Statement should answer 27 questions stemming from the five principles.",Global,FAT/ML
AI Policy Principles,AI in general,Self-regulation ; Policy principles,Safety; Human control; Liability; Accountability; Bias; Transparency; Labour market effects; Security,International - Global,"Oct 1, 2017 00:00","<a target=""_blank"" href=""https://www.itic.org/dotAsset/50ed66d5-404d-40bb-a8ae-9eeeef55aa76.pdf"">ITI AI Policy Principles </a>","The ITI is a Washington, DC-based trade association representing the ICT industry. It has been described as a ‘lobbying group’ and its membership includes the largest technology companies, like Apple, Amazon, Google, Intel, IBM, and others.<br>The paper offers a general outline of possible future cooperation between the private and the public sector, globally. ITI highlights industry’s responsibility in promoting responsible development and use of AI, the opportunity for governments to invest in and enable the AI ecosystem, and the opportunity for public-private partnerships, and groups its policy principles under these 3 headings.<br>Industry’s responsibility includes:<br>[ul]<br><li>Responsible Design and Deployment, meaning the “responsibility to integrate principles into the design of AI technologies, beyond compliance with existing laws”, in short, a commitment to ‘ethics-by-design’;</li><br><li>Safety and Controllability, meaning that AI systems must be safe, minimise risk to humans and remain controllable by them;</li><br><li>Robust and Representative Data, meaning that “ industry has a responsibility to understand the parameters and characteristics of the data, to demonstrate the recognition of potentially harmful bias, and to test for potential bias before and throughout the deployment of AI systems.”</li><br><li>Interpretability entails a commitment to working with partners to mitigate bias, inequity and other harms;</li><br><li>Liability of AI Systems Due to Autonomy, expresses the commitment to work with relevant stakeholders to create an accountability framework for autonomous systems.</li><br>[/ul]<br>With regard to governments’ role, ITI has several proposals:<br>[ul]<br><li>Investment in AI R&D, especially cyber-defence, data analytics, detection of fraudulent transactions, robotics, human augmentation, natural language processing, interfaces, visualizations;</li><br><li>Flexible regulatory approach, including especially the avoidance of overregulation. The application of sector-specific approaches is encouraged instead of making general policies. It also urges governments to evaluate existing policy tools before implementing changes in order to not “impede the responsible development and use of AI”;</li><br><li>Promoting innovation and the security of the Internet, with special care to government absence: companies should not be obliged to “transfer or provide access to technology, source code, algorithms, or encryption keys” as a condition of doing business;</li><br><li>Cybersecurity and privacy, encouraging the governments to use strong, globally accepted and deployed cryptography to ensure trust and interoperability; voluntary information sharing on hacks is proposed as a way of enabling consumer protection;</li><br><li>Voluntary, industry-led, consensus-based standards and best practices should be developed in order to promote competition and international collaboration.</li><br>[/ul]<br>ITI also embraces public-private partnerships to democratise access to AI resources, strengthening STEM education, and efforts aimed at managing the labour market transformations brought about by AI.",Global,The Information Technology Industry Council (ITI)
AI & Machine Learning Policy Paper,AI in general,Policy paper,Accountability; Transparency; Bias; Data quality; Human control; Interoperability; Explainability; Safety; Liability;,International - Global,4/1/2017 0:00,"<a target=""_blank"" href=""https://www.internetsociety.org/wp-content/uploads/2017/08/ISOC-AI-Policy-Paper_2017-04-27_0.pdf"">Internet Society AI / ML Policy Paper</a>","The Internet Society is a US-based non-profit founded in 1992, with offices around the world. Its founders are Vint Cerf and Bob Kahn, and the organisation’s mission is to support and promote the “development of the Internet as a global technical infrastructure, a resource to enrich people’s lives, and a force for good in society.”<br>This policy paper offers a brief introduction to AI for policymakers in order to help the decision-making process about AI and Internet regulation. It describes key factors for consideration to ensure people’s trust in the new technology. These are socio-economic impacts; transparency, bias and accountability; new uses for data that might threaten user privacy; security and safety, including harmful AI behaviours or malicious exploitation of systems; ethics; and the emergence of new ecosystems (applications, services, etc.) created by AI. <br>These factors contribute to a set of challenges that must be overcome. These include<br><br><li>Transparency and interpretability in decision making: corporate and governmental secrecy limits thorough understanding when it comes to AI, while the unknown internal decision logic based on advanced ML creates hardships and complications for programmers<br></li><br><li>Data quality and bias: one possible harm is making “bad” decisions based on the low or biased provided data, while the other is due to AI’s ability to identify new patterns or “re-identify anonymized information,” which could lead to a breach of the user’s fundamental rights, leading to profiling and discriminating<br></li><br><li>Safety and security: AI agents may cause harm based on their indifference to their acts, how they learn from their environment, and because their algorithms can be manipulated.<br></li><br><li>Accountability: when it comes to ML, algorithms and their reasonings may stay unknown for programmers, perpetuating biases with non-intentional impacts. It raises the question: who should be responsible for the unintentional consequences of the actions done by advanced ML? The current solution is not making programmers responsible for the consequences of machine learning in order to not impede and discourage future innovation. However, the question of responsibility should be clarified in the near future between programmers, operators, and manufacturers.<br></li><br><li>Social and economic impact: automatization will bring new jobs and a higher level of convenience for consumers, while it will also impact unskilled, low-paying labor just as much as it will hit high skilled jobs. A higher degree of structural unemployment should be expected together with a global impact on the division of labor.<br></li><br><li>Governance is still in its infancy.<br></li><br><br>The policy paper enlists 6 guiding principles for the deployment of AI in Internet services, which are meant to meet the challenges introduced above:<br><ol><br><li>AI system designers should adopt a user-centric approach and consider their collective responsibility. Industry and researchers should adopt ethical standards, and innovation policies should require adherence to ethical standards as a prerequisite for funding;<br></li><br><li>Human interpretability of algorithmic decisions must be ensured, especially for applications that might have harmful or discriminatory consequences. Users must be empowered to request explanations about AI-based decisions.<br></li><br><li>Public and consumer empowerment must be supported and algorithmic literacy must be a basic skill.<br></li><br><li>To ensure responsible deployment humans must be in control of autonomous AI systems, safety and privacy must be priorities and a policy of data minimisation should be followed. AI systems should not be trained with biased data. Vulnerabilities must be disclosed. Internet-connected AIs must be especially secure, and vulnerabilities should be disclosed.<br></li><br><li>There must be legal certainty on how existing laws and policies apply to algorithmic decision-making and legal accountability must be ensured when automated decision systems take over from humans. Governments need to create clarity on liability for when AI “goes wrong” and any applicable laws must take a user-centred approach, ensuring the ability to challenge AI-based decisions.<br></li><br><li>All stakeholders should engage in dialogue to “shape an environment where AI provides socio-economic opportunities for all.”<br></li><br><li>An open, multi-stakeholder approach to governance should be adopted, informed by the Internet Society’s relevant work on the <a target=""_blank"" href=""https://www.internetsociety.org/resources/doc/2016/internet-governance-why-the-multistakeholder-approach-works/"">topic</a>, and underpinned by the principles of <br><ol><br><li>Inclusiveness and transparency; <br></li><br><li>Collective responsibility; <br></li><br><li>Effective decision making and implementation and <br></li><br><li>Collaboration through distributed and interoperable governance<br></li><br></ol><br></li><br></ol>",Global,The Internet Society
"Finland's Age of Artificial Intelligence",AI in general,Strategy,,National,12/1/2017 0:00,"<a target=""_blank"" href=""http://julkaisut.valtioneuvosto.fi/bitstream/handle/10024/160391/TEMrap_47_2017_verkkojulkaisu.pdf?sequence=1&isAllowed=y"">Finland’s Age of AI document</a><br><a target=""_blank"" href=""https://www.tekoalyaika.fi/en/"">AI Finland</a>","The working group on artificial intelligence was appointed by the Mika Lintila, the Minister of Economic Affairs and Employment in Finland in May 2017, to answer the question: “How can it be ensured that Finland becomes one of the frontrunners among the countries that apply AI?”<br>There are two main concerns: first, the working group was appointed in order to exploit the advantages that Finland has in automation and AI application compared to nine other nations, based on a previous McKinsey report. Second, to find the ways that could turn AI and automatization an engine of future economic growth for Finland. Hence, the paper foresees that within five years, AI application will be an everyday part of every Finnish citizens’ life and by 2030, the country can produce a 3% annual growth and an unemployment-level of 5% by the utilization of AI and automatization.<br>To make all this come true, 1) Finland should build research networks, since the vast majority of research is done outside its borders; 2) Finland should invest in the cooperation between companies and research institutes; 3) the Finnish corporate taxation should be attractive to investment; 4) Finland should find ways, how the currently available AI education and training applied at a high level at the sciences could be utilized at other fields of education; 5) in energy, healthcare, transport, and industry a “shar and ambitious innovation ecosystem” should be created, since Finland will utilize AI greatly within these fields; 6) ensuring an easy access to AI, robotics, and data platforms for companies of all sizes; 7) Finland should create a legal framework ensuring the availability of good quality of data for companies; 8) regulating the extensive collection and application of MyData; 9) setting up a data provider pilot based on the infrastructure provided by the national architecture for digital services; 10) Finland should spread for the business sector the expertise using the tools and the knowhow to access the computational capacity needed to use AI; 11) Finland should create open piloting and testing environments; 12) Finland must establish an international hub for artificial intelligence, together with a “virtual university” to attract top experts; 13) working age population must be given access to high quality education and AI literacy must be guaranteed for every citizen; 14) Finland should acquire top expertise in AI and in creating piloting environments in order to be made appealing for international experts; 15) Finland should create a “Master of AI” degree; 16) adequate investments and incentives should be made available in AI development; 17) applying AI in public administration by the set up of “Aurora,” providing digital service 24/7; 18) Finland should enhance the cooperation between the private and the public sectors. A public sector reform is needed; 19) Finland should actively influence the work of the EU Commission on its AI agenda setting",Finland,Department of Enterprise and Innovation at the Finnish Ministry of Economic Affairs and Employment
The National AI Strategy of the Federal Government of Germany,AI in general,Strategy,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.ki-strategie-deutschland.de/home.html"">German AI Strategy</a>","The Federal Government of Germany decided to turn the country into a world-leading nation regarding the application of AI and following the earlier publication of a set of key principles in July 2018, it launched a national AI strategy on the 15 of November. The strategy’s development was led by 3 ministries, Education and Research, Economic Affairs and Energy, and Labor and Social Affairs. It draws on expert meetings and public consultations, including a national online survey. <br>The strategy is also strongly influenced by the idea that AI will bring changes for the whole of mankind, therefore, solutions and policies should not be only national in scope. The overarching goal of making Germany a world leader is connected to strengthening the position of the European Union and cooperating internationally.<br>The strategy defines 3 overarching aims:<br><ol><br><li>To make Germany and Europe global leaders on the development and use of AI technologies and secure Germany's competitiveness in the future, <br></li><br><li>To safeguard the responsible development and use of AI which serves the good of society, and <br></li><br><li>To integrate AI in society in ethical, legal, cultural and institutional terms in the context of a broad societal dialogue and active political measures.<br></li><br></ol><br>The strategy goes on to identify 12 fields of action where the Federal Government will undertake measures: <br><ol><br><li>Strengthening research in Germany and in Europe<br></li><br><li>Innovation competitions and European innovation clusters<br></li><br><li>Supporting AI adoption by SMEs<br></li><br><li>Boosting startups<br></li><br><li>Restructuring the world of labour<br></li><br><li>Strengthening AI-related education<br></li><br><li>Use AI to improve government services<br></li><br><li>Making data available and facilitating its use<br></li><br><li>Adjusting the regulatory framework<br></li><br><li>Set technical and ethical standards<br></li><br><li>Amplify international cooperation<br></li><br><li>Conduct broad public engagement<br></li><br></ol><br>To make these goals come true, the Federal Government aims to spend €3 billion on its program by 2025 and €500 million in 2019.",Germany,Federal Government of Germany
Towards an AI Strategy in Mexico,AI in general,Strategy,,National,6/1/2018 0:00,"<a target=""_blank"" href=""https://docs.wixstatic.com/ugd/7be025_9c99aef6567442b09dbf38a1387b7d4a.pdf"">Towards an AI Strategy in Mexico: Harnessing the AI Revolution</a>","The white paper is a collection of proposals about the ways in which Mexico could exploit the advantages of AI development. The work was led by Oxford Insights & C Minds in partnership. Oxford Insights advises organisations on strategic, cultural and leadership opportunities from digital transformation. It specialises in artificial intelligence (AI), helping governments to craft AI strategies and publishing the annual Government AI Readiness Index. C Minds is an “impact innovation agency that designs and deploys strategies for economic and social development for developing countries.” The organization works with governments and international organizations in order to bring new technological advancements into developing countries. It has offices in San Francisco (HQ) and in Mexico City. <br><br>The Mexican Government was one of the collaborators in the work along with the British Embassy in Mexico, and the Prosperity Fund. The piece “makes the case for Mexico to invest in AI now,” and it delivers recommendations in five fields: <br><ol><br><li>governance, government, and public services,<br></li><br><li>research and development,<br></li><br><li>capacity, skills, and education, <br></li><br><li>data infrastructure, <br></li><br><li>ethics and regulation.<br></li><br></ol><br>A novelty of this document that it (briefly and concisely) goes through all the national AI strategies that have already been published, which is in line with the direct “call for action” of the authors: motivating the Mexican government to be among the first 10 nations to have prepared such a strategy. It also explains the need and the use of having such a strategy, while summarizing the current state of Mexico in the “AI revolution” through the description of outcomes of previous developments. The actual recommendations occupy 8 pages out of the 52 (pgs. 30-37)<br><ol><br><li>Governance, government, and public services<br>[ul]<br><li>“The government should appoint a national official” to lead on AI-related innovations and to guarantee a clear strategic direction</li><br><li>Ministries should attract experts in data science, algorithmic thinking, and machine learning</li><br><li>Creating a “formal and permanent AI Commission” that brings together the main actors of the private sphere to continuously work together with the public to secure the constitution and high quality of the national AI strategy. The should not only develop it but promote it as well.</li><br><li>The houses of legislation (Senate and Chamber of Deputies in the Congress) should create “working groups” on AI to guarantee the cooperation between the Executive and the Legislation.</li><br><li>The Mexican government should be a global leader in finding solution for universal challenges posed by the spread of AI technology, what it could ensure through its good positions in the various international organizations</li><br><li>Creating a “coalition of AI practitioners from all sectors and disciplines.” The group should develop an “AI Road Map,” based on “mutual sector responsibility.”</li><br>[/ul]<br></li><br><li>Research and development<br>[ul]<br><li>Creating a “National Center for AI Research.” The model should be the Turing Center in the UK. It should provide a space for “cross-disciplinary work.” It could also help Mexico to be better positioned on the global stage<br></li><br><li>Strengthening connections between academia and industry. Using the “Tec de Monterrey” model, bringing representatives from industries to the planning table of future educational programs. Funding startups and university attempts. University professors should be allowed to be employed in the private sphere as well.<br></li><br><li>Ensuring a business-friendly environment through certainty and confidence. Updating the Intellectual Property Rights framework. Securing a safe space for data to be exchanged, to guarantee collaboration between research and industry.<br></li><br><li>Create an AI government fund<br></li><br>[/ul]<br></li><br><li>Capacity, skill, and education<br>[ul]<br><li>Continued education should be applied instead of beginning to educate the population from a very early age. Civil servants should be trained. Creating and maintaining vocational courses<br></li><br><li>Non-technology and non-science related students should also learn about and understand AI.<br></li><br><li>Computational skills and coding should be part of primary education<br></li><br><li>Masters and PhDs in data science<br></li><br>[/ul]<br></li><br><li>Data infrastructure<br>[ul]<br><li>“The government should maintain and share core data services”<br></li><br><li>The future national AI centre should produce training data sets for Mexico<br></li><br><li>Protect personal privacy<br></li><br>[/ul]<br></li><br><li>Ethics and regulation<br>[ul]<br><li>Data should not fall outside the scope anti-competitive legislation.<br></li><br><li>Create a Mexican AI Ethics Council<br></li><br>[/ul]<br></li><br></ol>",Mexico,Mexican Government
New Generation of Artificial Intelligence Development Plan,AI in general,Strategy,,National,7/1/2017 0:00,"<a target=""_blank"" href=""https://www.newamerica.org/cybersecurity-initiative/blog/chinas-plan-lead-ai-purpose-prospects-and-problems/"">Translation of strategy</a>","The Chinese Government’s development plan has been translated into English by the experts at the New America think tank. The summary below is based on this translation.<br>The document describes artificial intelligence as a new focus of international competition and an engine of economic development that brings great opportunities for creating societal benefits. However, challenges are also acknowledged, such as economic security, social stability, personal privacy and even global governance. Therefore, a forward looking approach is required to minimise the risks and guarantee the controllable development of AI.<br>While some advances have been made in areas like intelligent manufacturing, the general state of AI development in China is judged to be lacking. However, the document affirms the ambition to seize this historical opportunity to lead the world in AI development. <br>Four basic principles are outlined.<br>Technology-led - achieve transformational breakthroughs in AI theory, methods, tools and systems;<br>Systematic layouts - use a systematic development strategy encompassing basic research, technology development, industrial development and application, building on the socialist system’s ability to undertake major efforts. <br>Market-dominant - follow the rules of the market and accelerate commercialisation. Leverage the government for planning, policy support, security, ethical guidelines and market regulation.<br>Open-source and open - promote open-source sharing in academia and industry. “promote two-way conversion and application for military and civilian scientific and technological achievements and co-construction and sharing of military and civilian innovation resources”<br>The strategic objectives are to be achieved in three steps. <br>[ul]<br><li>By 2020 China should have caught up with the other global players in overall AI theory, technology and application. First technology standards should also be established by that point, along with ethical norms, policies and regulations in some areas.</li><br><li>By 2025 China should achieve major breakthroughs in AI theory, resulting in world-leading innovations, making AI the main driving force of China’s economic transformation. AI laws and regulations will have been established, along with ethical norms and policy systems, AI security assessment and control systems.</li><br><li>By 2030 China should lead the world in AI theories, technologies and applications, and become the globe’s primary AI innovation centre. </li><br>[/ul]<br>Key elements of the deployment of this strategy are <br><ol><br><li>Creation of an open and cooperative AI tech innovation system, that strengthens China’s basic research capacity and allows for original theoretical contributions to AI;</li><br><li>Recognising the integration of technological and social systems, pursue parallel innovations in industrial and social policies;</li><br><li>Promote breakthrough in all 3 areas of theoretical research, technology development and industrial application, ensuring security and controllability;</li><br><li>“Fully support science and technology, the economy, social development, and national security” Leverage AI to become a global R&D power, create economic prosperity and implement people-centric development thinking.</li><br></ol><br>In addition to a strong focus on the science and technology base, the elaboration of which takes up the overwhelming majority of the document, legal, ethical and social issues also play an important role. <br>Research on legal, ethical, and social issues related to AI should be strengthened and laws, regulations and ethical frameworks established. Civil and criminal responsibility issues and the protection of privacy and property should be extensively researched, along with information security in AI. Traceability and accountability systems should be devised and in key areas safety management laws and regulations should be quickly formulated, to “lay a legal foundation for the rapid application of new technology.” <br>Research should also look at human-machine collaboration and an ethical framework for such should be devised.<br>An AI R&D and design code of ethical conduct should be developed and the assessment of the potential hazards and benefits of AI strengthened. China will also actively take part in global efforts aimed at AI governance and contribute to the resolution of common problems and global challenges.<br>Open data policies should be improved and related pilots undertaken to create value from public data. In addition, the Government will review several policy domains to effectively cope with social problems generated by AI.<br>The AI standards framework should be strengthened, building on the key principles of security, availability, interoperability, and traceability. Chinese enterprises should be encouraged to participate in such standard-setting activities internationally. At the same time IP protections in AI should be strengthened and a public pool of AI patents established to promote AI uptake.",China,Chinese State Council
Ethics in Autonomous and Artificial Intelligence Applications,AI in general,Standardisation,Standardisation;,International - Global,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.iec.ch/dyn/www/f?p=103:186:5696200230312::::FSP_ORG_ID,FSP_LANG_ID:22827,"">SEG 10 -  Ethics in Autonomous and Artificial Intelligence Applications</a>","The International Electrotechnical Commission is the world’s leading organization that prepares and publishes International Standards for all electrical, electronic and related technologies.<br>At the October 2018 meeting of the Standardization Management Board set up Standardization Evaluation Group 10, ‘Ethics in Autonomous and Artificial Intelligence Applications’. SEG 10 will identify ethical issues and societal concerns related to IEC technical activities and develop guidelines on ethical aspects related to autonomous and/or AI applications. <br>The SEG was encouraged to ensure participation by JTC 1/SC 42 and to coordinate with the OCEANIS forum. It will be co-convened by China and Germany.",Global,International Electrotechnical Commission
Explainable Artificial Intelligence (XAI),AI in general,Research,Explainability,National,5/1/2017 0:00,"<a target=""_blank"" href=""https://www.darpa.mil/program/explainable-artificial-intelligence"">XAI Project</a>","[font=Arial, Verdana, sans-serif]DARPA is funding several programs aimed at developing XAI - a new machine learning process that is more understandable to humans. The effort is motivated by national security objectives. The aim is to “Produce more explainable models, while maintaining a high level of learning performance (prediction accuracy); and enable human users to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners.” Working on “a portfolio of methods that will provide future developers with a range of design options covering the performance-versus-explainability trade space.” “The XAI program is focused on the development of multiple systems by addressing challenge problems in two areas: (1) machine learning problems to classify events of interest in heterogeneous, multimedia data; and (2) machine learning problems to construct decision policies for an autonomous system to perform a variety of simulated missions. These two challenge problem areas were chosen to represent the intersection of two important machine learning approaches (classification and reinforcement learning) and two important operational problem areas for the DoD (intelligence analysis and autonomous systems).” At the end of the program, the final delivery will be a toolkit library consisting of machine learning and human-computer interface software modules that could be used to develop future explainable AI systems. After the program is complete, these toolkits would be available for further refinement and transition into defense or commercial applications.",USA,DARPA
Guidelines for Trials of Automated Vehicles,Autonomous mobility,Regulation,,National,5/1/2017 0:00,"<a href=""https://www.ntc.gov.au/codes-and-guidelines/automated-vehicle-trial-guidelines"" target=_blank>Guidelines for trials of automated vehicles in Australia</a>",,Australia,National Transport Commission
Austrian Action Programme on Automated Mobility 2019-2022,Autonomous mobility,Action programme,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.bmvit.gv.at/en/service/publications/downloads/action_automated_mobility_2019-2022_ua.pdf"">Austrian Action Programme on Automated Mobility 2019-2022</a><br><a target=""_blank"" href=""https://www.bmvit.gv.at/en/service/publications/downloads/action_automated_mobility_2019-2022_ua.pdf""><br></a>",,Austria,"Ministry for Transport, Innovation and Technology"
Driving Change - Technology and the Future of the automated vehicle,Autonomous mobility,Report,,National,1/1/2018 0:00,"<a target=""_blank"" href=""https://sencanada.ca/content/sen/committee/421/TRCM/Reports/COM_RPT_TRCM_AutomatedVehicles_e.pdf"">Driving Change - Technology and the Future of the automated vehicle</a>",,Canada,"Standing Senate Committee on Social Affairs, Science and Technology"
"Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems",Health,Report,,National,10/1/2017 0:00,"<a target=""_blank"" href=""https://sencanada.ca/content/sen/committee/421/SOCI/reports/RoboticsAI3DFinal_Web_e.pdf"">Integrating Robotics, Artificial Intelligence and 3D Printing Technologies into Canada’s Healthcare Systems</a>",,Canada,"Standing Senate Committee on Social Affairs, Science and Technology"
Bots at the Gate - Human Rights and ADS,Automated Decision Systems,Report,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://citizenlab.ca/wp-content/uploads/2018/09/IHRP-Automated-Systems-Report-Web-V2.pdf"">Bots at the Gate - Human Rights and ADS</a>",,Canada,University of Toronto
Digital Growth Strategy,AI in general,Strategy,,National,1/1/2018 0:00,"<a target=""_blank"" href=""https://eng.em.dk/media/10566/digital-growth-strategy-report_uk_web-2.pdf"">Digital Growth Strategy</a>",,Denmark,"Ministry of Industry, Business and Financial Aff airs"
Action Plan Against Disinformation,Disinformation,Action plan,,International - EU,12/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/commission/sites/beta-political/files/eu-communication-disinformation-euco-05122018_en.pdf"">Action Plan Against Disinformation</a>",,European Union,European Commission
Committee of experts on Human Rights Dimensions of automated data processing and different forms of AI (MSI-AUT),Automated Decision Systems,Advisory body,,International - EU,3/1/2018 0:00,"<a href=""https://www.coe.int/en/web/freedom-expression/msi-aut#{%2232639232%22:[1]}"" target=_blank>MSI-AUT Committee report on Human Right dimensions of AI</a>",,European Union,Council of Europe
High-Level Expert Group on AI,AI in general,Advisory body,,International - EU,6/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/digital-single-market/en/high-level-expert-group-artificial-intelligence"">High-Level Expert Group on AI</a>",,European Union,European Commission
AI4People Ethical Framework for a Good AI Society,AI in general,Ethics guidelines,,International - EU,10/1/2018 0:00,"<a target=""_blank"" href=""http://www.eismd.eu/wp-content/uploads/2018/11/Ethical-Framework-for-a-good-AI-Society.pdf"">AI4People Ethical Framework for a Good AI Society</a>",,European Union,Atomium
European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment,Justice system,Ethics guidelines,,International - EU,12/1/2018 0:00,"<a target=""_blank"" href=""https://rm.coe.int/ethical-charter-en-for-publication-4-december-2018/16808f699c"">European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment</a>",,European Union,Council of Europe - CEPEJ
Guidelines on Automated individual decision-making and Profiling for the purposes of Regulation 2016/679 (GDPR),Automated Decision Systems,Guidelines,,International - EU,2/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/newsroom/article29/item-detail.cfm?item_id=612053"">Guidelines on Automated individual decision-making and Profiling for the purposes of Regulation 2016/679</a>",,European Union,Article 29 Data Protection Working Party
Guidelines on AI and Machine Learning,AI in general,Guidelines,,International - EU,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.epo.org/law-practice/legal-texts/html/guidelines2018/e/g_ii_3_3_1.htm"">Guidelines on AI and Machine Learning</a>",,European Union,European Patent Office
European AI Alliance,AI in general,Network,,International - EU,6/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/digital-single-market/en/european-ai-alliance"">European AI Alliance</a>",,European Union,European Commission
European Economic and Social Committee Opinion on AI,AI in general,Opinion ; Ethics guidelines,,International - EU,5/1/2017 0:00,"<a target=""_blank"" href=""https://www.eesc.europa.eu/en/our-work/opinions-information-reports/opinions/artificial-intelligence"">European Economic and Social Committee Opinion on AI</a>",,European Union,European Economic and Social Committee
Legal and ethical reflections concerning robotics,Robotics,Policy briefing,,International - EU,6/1/2016 0:00,"[url=http://www.europarl.europa.eu/RegData/etudes/STUD/2016/563501/EPRS_STU(2016)563501(ANN)_EN.pdf]Legal and ethical reflections concerning robotics<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span>",,European Union,Science and Technology Options Assessment Agency
EU regulation on automated vehicles,Autonomous mobility,Proposed regulation,,International - EU,5/1/2018 0:00,"<a target=""_blank"" href=""https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52018PC0286"">EU regulation on automated vehicles</a><br><a target=""_blank"" href=""https://ec.europa.eu/jrc/sites/jrcsh/files/23112018-artificial_intelligence-lagrange_en.pdf"">European Commission presentation on the 3rd EU mobility package on autonomous vehicles</a>",,European Union,European Commission
General Data Protection Regulation (GDPR),Data protection,Regulation,,International - EU,5/1/2018 0:00,"<a target=""_blank"" href=""https://eur-lex.europa.eu/eli/reg/2016/679/oj"">General Data Protection Regulation (GDPR)</a><br><a target=""_blank"" href=""http://www2.datainnovation.org/2018-impact-gdpr-ai.pdf"">Center for Data Innovation - The Impact of the EU’s New Data Protection Regulation on AI</a>",,European Union,European Parliament; Council of Europe
Commission Evaluation Report on Machinery Directive,AI in general,Report,,International - EU,5/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/docsroom/documents/29222"">Commission Evaluation Report on Machinery Directive</a>",,European Union,European Commission
Commission Evaluation Report on Product Liability Directive,AI in general,Report,,International - EU,5/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/docsroom/documents/29221"">Commission Evaluation Report on Product Liability Directive</a>",,European Union,European Commission
European Commission Staff Working Document - Liability for emerging digital technologies (AI),AI in general,Report,,International - EU,4/1/2018 0:00,"<a target=""_blank"" href=""https://eur-lex.europa.eu/legal-content/en/ALL/?uri=CELEX%3A52018SC0137"">European Commission Staff Working Document - Liability for emerging digital technologies (AI)</a>",,European Union,European Commission
The European AI Landscape,AI in general,Report,,International - EU,4/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/digital-single-market/en/news/european-artificial-intelligence-landscape"">The European AI Landscape</a>",,European Union,European Commission
Civil Law Rules on Robotics,Robotics,Report,,International - EU,10/1/2016 0:00,"[url=http://www.europarl.europa.eu/RegData/etudes/STUD/2016/571379/IPOL_STU(2016)571379_EN.pdf]Civil Law Rules on Robotics<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span>",,European Union,European Parliament
Ethical Aspects of Cyber-Physical Systems,Robotics,Report,,International - EU,6/1/2016 0:00,"[url=http://www.europarl.europa.eu/RegData/etudes/STUD/2016/563501/EPRS_STU(2016)563501_EN.pdf]Ethical Aspects of Cyber-Physical Systems<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span>",,European Union,Science and Technology Options Assessment Agency
Artificial Intelligence - A European Perspective,AI in general,Research,,International - EU,12/1/2018 0:00,"<a target=""_blank"" href=""https://ec.europa.eu/jrc/en/publication/eur-scientific-and-technical-research-reports/artificial-intelligence-european-perspective"">Artificial Intelligence - A European Perspective</a>",,European Union,European Commission - Joint Research Centre
Resolution on Civil Law Rules on Robotics,Robotics,Resolution,,International - EU,2/1/2017 0:00,"<a target=""_blank"" href=""https://oeil.secure.europarl.europa.eu/oeil/popups/printsummary.pdf?id=1477231&l=en&t=D"">Resolution on Civil Law Rules on Robotics</a>",,European Union,European Parliament
When Computers Decide: European Recommendations on Machine-Learned Automated Decision Making,Automated Decision Systems,White paper,,International - EU,3/1/2018 0:00,"<a target=""_blank"" href=""http://www.informatics-europe.org/component/phocadownload/category/10-reports.html?download=74:automated-decision-making-report"">When Computers Decide: European Recommendations on Machine-Learned Automated Decision Making</a>",,European Union; Russia; Switzerland; Norway; Serbia; Turkey,Informatics Europe; EUACM
"City of Espoo's AI Experiment",Public services,Pilot,,City,6/1/2017 0:00,"[url=https://www.espoo.fi/en-US/Espoo_and_Tieto_testing_artificial_intel(121565)]City of Espoo’s AI Experiment<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span><br>[url=https://www.espoo.fi/en-US/Jobs_and_enterprise/A_dynamic_city/Glimpses_into_the_future/AI_experiment_phase_1_Helping_artificial(133974)]AI Experiment Phase 1 description<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span><br>[font=Verdana, Arial, Helvetica, sans-serif]<a target=""_blank"" href=""https://www.computerweekly.com/news/252451496/Finnish-city-Espoo-trials-artificial-intelligence-for-community-support"">Computer Weekly coverage of experiment</a><br><a target=""_blank"" href=""https://customers.microsoft.com/en-us/story/city-of-espoo-government-azure"">Microsoft case study about Espoo</a>",,Finland,City of Espoo
AI Ethics Challenge,AI in general,Self-regulation,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.tekoalyaika.fi/en/background/ethics/"">AI Ethics Challenge</a>","The AI Ethics Challenge is an initiative by the Ministry of Economic Affairs and Employment of Finland. It seeks to make Finland a model country for the adoption of ethical AI. The challenge invites Finnish companies to develop principles for ethical AI practice in order to respond to the challenges around safety, bias, trustworthiness, and AI-based discrimination.<br><br><br><br>A 5-step process is offered as a way for developing ethical AI practices.",Finland,AI Finland @ Ministry of Economic Affairs and Employment of Finland
"Toward a Controlled, Useful and Demystified Artificial Intelligence",AI in general,Report,,National,3/1/2017 0:00,"<a target=""_blank"" href=""http://www.senat.fr/rap/r16-464-1/r16-464-1-syn-en.pdf"">Toward a Controlled, Useful and Demystified Artificial Intelligence</a>",,France,Parliamentary Office for Scientific and Technological Assessment
Charlevoix Common Vision for the Future of AI,AI in general,Declaration,,International - G7,6/1/2018 0:00,"<a target=""_blank"" href=""https://g7.gc.ca/wp-content/uploads/2018/06/FutureArtificialIntelligence.pdf"">Charlevoix Common Vision for the Future of AI </a>",,Canada; France; Germany; Italy; Japan; United Kingdom; USA,G7
"G7 Innovation Ministers' Statement on AI",AI in general,Statement,,International - G7,3/1/2018 0:00,"<a target=""_blank"" href=""https://g7.gc.ca/en/g7-presidency/themes/preparing-jobs-future/g7-ministerial-meeting/chairs-summary/annex-b/"">G7 Innovation Ministers' Statement on AI</a>",,Canada; France; Germany; Italy; Japan; United Kingdom; USA,G7
DIN SPEC 92001 - Quality requirements and life cycle management for AI modules,AI in general,Standardisation,,National,3/1/2018 0:00,"<a target=""_blank"" href=""https://www.din.de/en/about-standards/din-spec-en/business-plans/wdc-beuth:din21:288723757?sourceLanguage&destinationLanguage"">DIN SPEC 92001 - Quality requirements and life cycle management for AI modules</a>",,Germany,German Institute for Standardization (DIN)
Position paper on AI and standards,AI in general,Standardisation,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.din.de/blob/306690/74b9d17abcab164b65aff765587a2ace/position-paper-artificial-intelligence-english--data.pdf"">Position paper on AI and standards</a>",,Germany,German Institute for Standardization (DIN)
"Partnership on AI's Basic Tenets",AI in general,Ethics guidelines,,International - Global,9/1/2016 0:00,"<a target=""_blank"" href=""https://www.partnershiponai.org/tenets/"">Partnership on AI's Basic Tenets</a>",,Global,Partnership on AI
Telefonica AI Ethics Guidelines,AI in general,Ethics guidelines,,International - Global,10/1/2018 0:00,"<a target=""_blank"" href=""https://www.telefonica.com/documents/737979/143948154/infografia-ia-eng.pdf/c203ade4-caf5-8664-c065-c5cc66cacca2?version=1.0"">Telefonica AI Ethics Guidelines</a>",,Global,Telefonica
COMEST Robot Ethics Guidelines,Robotics,Ethics guidelines,,International - Global,9/1/2017 0:00,"<a target=""_blank"" href=""http://unesdoc.unesco.org/images/0025/002539/253952E.pdf"">COMEST Robot Ethics Guidelines</a>",,Global,UNESCO
Draft AI R&D Guidelines for International Discussion,AI in general,Guidelines,,National,7/1/2017 0:00,"<a target=""_blank"" href=""http://www.soumu.go.jp/main_content/000507517.pdf"">Draft AI R&D Guidelines for International Discussion</a>",,Japan,Ministry of Internal Affairs and Communications
AI Policy Observatory,AI in general,Observatory,,International - OECD,9/1/2018 0:00,"<a target=""_blank"" href=""http://www.oecd.org/going-digital/ai/about-the-oecd-ai-policy-observatory.pdf"">OECD AI Policy Observatory</a>","The OECD AI Policy Observatory builds on the OECD’s Recommendation on Artificial Intelligence issued in May 2019. It will be an online repository, combining resources from across the OECD and its partners from various stakeholder groups. The goal of the observatory is to facilitate dialogue and provide multidisciplinary, evidence-based policy analysis on AI. It is scheduled to launch in early 2020 and will comprise 4 main components:<br><br>- AI Principles<br><br>- Policy areas, such as jobs, skills, health, transport, etc. <br><br>- Metrics on AI trends<br><br>- National and AI policies and initiatives.",OECD,OECD
Maximising the benefits of Artificial Intelligence through future-proof rules on Text and Data Mining,Data mining,Proposal,,International - EU,4/1/2018 0:00,"<a target=""_blank"" href=""https://cdt.org/files/2018/04/OpenLetter-to-European-Commission-on-AI-and-TDM-9-April-2018-copy.pdf"">Open letter to EU Commission on Text and Data Mining</a>",,Global,Center for Technology and Democracy
Governing AI - Upholding Human Rights and Dignity,AI in general,Report,,International - Global,10/1/2018 0:00,"<a target=""_blank"" href=""https://datasociety.net/wp-content/uploads/2018/10/DataSociety_Governing_Artificial_Intelligence_Upholding_Human_Rights.pdf"">Governing AI - Upholding Human Rights and Dignity</a>",,Global,Data & Society
Applying AI for Social Good,AI in general,Report,,International - Global,12/1/2018 0:00,"<a target=""_blank"" href=""https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/applying%20artificial%20intelligence%20for%20social%20good/mgi-applying-ai-for-social-good-discussion-paper-dec-2018.ashx"">Notes from the Frontier - Applying AI for Social Good</a>",,Global,McKinsey
"Ethical, Social and Political Challenges of AI in Health",Health,Report,,National,4/1/2018 0:00,"<a target=""_blank"" href=""https://wellcome.ac.uk/sites/default/files/ai-in-health-ethical-social-political-challenges.pdf"">Ethical, Social and Political Challenges of AI in Health</a>",,Global,Wellcome Trust
"Microsoft's Fairness, Accountability, Transparency and Ethics in AI Group",AI in general,Research,,International - Global,3/1/2017 0:00,"<a target=""_blank"" href=""https://www.microsoft.com/en-us/research/group/fate/"">Microsoft's Fairness, Accountability, Transparency and Ethics in AI Group</a>",,Global,Microsoft
Government AI Readiness Index,AI in general,Research,,International - Global,12/1/2017 0:00,"<a target=""_blank"" href=""https://www.oxfordinsights.com/government-ai-readiness-index/"">Government AI Readiness Index</a>",,Global,Oxford Insights
Mitigating the Negative Impacts of Computing Through a Change to the Peer Review Process,AI in general,Self-regulation,,International - Global,3/1/2018 0:00,"<a target=""_blank"" href=""https://acm-fca.org/2018/03/29/negativeimpacts/"">Mitigating the Negative Impacts of Computing Through a Change to the Peer Review Process</a>",,Global,Association for Computing Machinery
Global Data Ethics Pledge,Model and data management,Self-regulation,,International - Global,2/1/2018 0:00,"<a target=""_blank"" href=""https://github.com/Data4Democracy/ethics-resources"">Global Data Ethics Pledge</a>",,Global,Data for Democracy
Responsible AI Practices,AI in general,Self-regulation,,International - Global,6/1/2018 0:00,"<a target=""_blank"" href=""https://ai.google/education/responsible-ai-practices"">Responsible AI Practices</a>",,Global,Google
Microsoft AI Principles,AI in general,Self-regulation,,International - Global,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.microsoft.com/en-us/ai/our-approach-to-ai"">AI Principles</a>",,Global,Microsoft
Guiding Principles for Artificial Intelligence,AI in general,Self-regulation,,International - Global,9/1/2018 0:00,"<a target=""_blank"" href=""https://news.sap.com/2018/09/sap-guiding-principles-for-artificial-intelligence/"">Guiding Principles for Artificial Intelligence</a>",,Global,SAP
Ethical Principles for Artificial Intelligence and Data Analytics,Model and data management,Self-regulation,,International - Global,9/1/2017 0:00,"<a target=""_blank"" href=""http://www.siia.net/Portals/0/pdf/Policy/Ethical%20Principles%20for%20Artificial%20Intelligence%20and%20Data%20Analytics%20SIIA%20Issue%20Brief.pdf?ver=2017-11-06-160346-990"">Ethical Principles for Artificial Intelligence and Data Analytics</a>",,Global,Software and Information Industry Association
Open AI Charter,AI in general,Self-regulation ; Ethics guidelines,,International - Global,4/1/2018 0:00,"<a target=""_blank"" href=""https://blog.openai.com/openai-charter/"">Open AI Charter</a>",,Global,Open AI
Ethically Aligned Design - Global Initiative on Ethics of Autonomous and Intelligent Systems,AI in general,Standardisation,,International - Global,12/1/2017 0:00,"<a target=""_blank"" href=""https://ethicsinaction.ieee.org"">Ethically Aligned Design - Global Initiative on Ethics of Autonomous and Intelligent Systems</a>",,Global,IEEE
Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS),AI in general,Standardisation,,International - Global,7/1/2018 0:00,"<a target=""_blank"" href=""https://ethicsstandards.org/"">OCEANIS website</a>",,Global,"IEEE; Afirca Organisation for Standardisation; Austrian Electrotechnical Association; Austrian Standards; Bureau of Indian Standards; British Standards Institution; China Electronics Standardization Institute; CIO Strategy Council; German Commission for Electrical, Electronic & Information Technologies; International Electrotechnical Commission; Ecuadorian Service for Standardization; Japanese Standards Association; National Standards Authority of Ireland; Turkish Standards Institution"
ISO AI Committee,AI in general,Standardisation,,International - Global,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.iso.org/committee/6794475.html"">ISO/IEC JTC 1/SC 42 Standardisation</a>",ISO/IEC JTC 1/SC 42,Global,ISO
A Practical Guide to Managing Risk in Machine Learning Models,Model and data management,White paper,Risk management;,International - Global,6/1/2018 0:00,"<a target=""_blank"" href=""https://fpf.org/wp-content/uploads/2018/06/Beyond-Explainability.pdf"">Beyond Explainability - A Practical Guide to Managing Risk in Machine Learning Models</a>","The Future of Privacy Forum is a US-based non-profit organisation dedicated to privacy leadership and scholarship.<Br><Br><br><br>This white paper provides a template for managing the practical risks of deploying an individual machine learning model. It is primarily aimed at lawyers, compliance personnel, data scientists and engineers. The paper highlights the importance of clearly documenting the initial objectives and underlying assumptions of any ML project.<Br><Br><br><br>Building on the US Federal Reserve’s SR 11-7 regulatory standard on model risk management, the authors of the white paper put forward a “three lines of defence” approach. This approach assigns specific roles and responsibilities to different actors involved in the creation, deployment, management and auditing of ML systems throughout the system’s entire lifecycle. The first line of defence is focused on the development and testing of models, the second line on model validation and legal and data review, and the third line on periodic auditing. <Br><Br><br><br>The framework also offers guidance on minimising the risks related to input data by documenting model requirements, assessing data quality, encapsulating the model, monitoring for data drift, and creating actionable alerts. <Br><Br><br><br>Finally, the framework offers recommendations on using outputs from the ML model as a way of assessing and understanding the workings of the model itself.<Br><Br><br><br>The paper describes effective risk management as an ongoing, never-ending task. The framework includes a comprehensive Model Management Checklist to help operationalise the 3 lines of defence outlined in the paper.",Global,Future of Privacy Forum; Immuta;
Artificial intelligence across industries,AI in general,White paper,,International - Global,12/1/2018 0:00,"<a target=""_blank"" href=""https://basecamp.iec.ch/download/iec-white-paper-artificial-intelligence-across-industries-en/"">Artificial intelligence across industries</a>",,Global,International Electrotechnical Commission
Algorithms and AI in Latin America,Public services,White paper,,International - Latin America,9/1/2018 0:00,"<a target=""_blank"" href=""http://webfoundation.org/docs/2018/09/WF_AI-in-LA_Report_Screen_AW.pdf"">White paper</a>",,Argentina; Uruguay,World Wide Web Foundation
Algorithmic Accountability in Low and Middle Income Countries,Automated Decision Systems,White paper,,International - Global,7/1/2017 0:00,"<a target=""_blank"" href=""https://webfoundation.org/docs/2017/07/Algorithms_Report_WF.pdf"">White Paper</a>",,Global,World Wide Web Foundation
Expert Group on AI in Society,AI in general,Working group,,International - OECD,9/1/2018 0:00,"<a target=""_blank"" href=""http://www.oecd.org/going-digital/ai/oecd-creates-expert-group-to-foster-trust-in-artificial-intelligence.htm"">Expert Group on AI in Society</a>",,OECD,OECD
United Nations Activities on Artificial Intelligence,AI in general,,,International - Global,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.itu.int/dms_pub/itu-s/opb/gen/S-GEN-UNACT-2018-1-PDF-E.pdf"">Complete list of activities"">s</a>",,Global,United Nations
Code of Practice for the testing of autonomous vehicles,Autonomous mobility,Code of practice,,National,2/1/2017 0:00,"<a target=""_blank"" href=""https://www.gov.im/media/1355386/isle-of-man-code-of-practice-for-testing-of-autonomous-vehicles-final.pdf"">Code of Practice</a>",,Isle of Man,Department of Infrastructure
AI at the Service of Citizens,AI in general,White paper,,National,3/1/2018 0:00,"<a target=""_blank"" href=""https://ia.italia.it/assets/whitepaper.pdf"">White paper</a>",,Italy,The Agency for Digital Italy
Ethical Guidelines,AI in general,Ethics guidelines,,National,2/1/2017 0:00,"<a target=""_blank"" href=""http://ai-elsi.org/wp-content/uploads/2017/05/JSAI-Ethical-Guidelines-1.pdf"">The Japanese Society for Artificial Intelligence Ethical Guidelines</a>",,Japan,The Japanese Society for Artificial Intelligence
Draft AI Utilisation Principles,AI in general,Guidelines,,National,7/1/2018 0:00,"<a target=""_blank"" href=""http://www.soumu.go.jp/main_content/000581310.pdf"">Draft AI Utilisation Principles</a>",,Japan,Ministry of Internal Affairs and Communications
Society 5.0,AI in general,Strategy,,National,1/1/2016 0:00,"<a target=""_blank"" href=""https://www.gov-online.go.jp/cam/s5/eng/"">Society 5.0 official website</a><br><a target=""_blank"" href=""https://www.japan.go.jp/abenomics/_userdata/abenomics/pdf/society_5.0.pdf"">Society 5.0 Presentation</a><br><a target=""_blank"" href=""https://www8.cao.go.jp/cstp/english/society5_0/index.html"">Cabinet Office Description of Society 5.0</a>",,Japan,Japanese Cabinet
AI Technology Strategy,AI in general,Strategy,,National,3/1/2017 0:00,"<a target=""_blank"" href=""http://www.nedo.go.jp/content/100865202.pdf"">AI Technology Strategy</a>",,Japan,Strategic Council for AI Technology
Taskforce Distributed Ledgers and AI,AI in general,Task force,,National,2/1/2018 0:00,"<a target=""_blank"" href=""http://www.ict.go.ke/taskforce-on-distributed-ledgers-and-artificial-intelligence-presentation-schedule"">Taskforce Distributed Ledgers and AI</a><br><a target=""_blank"" href=""https://www.standardmedia.co.ke/article/2001303499/blockchain-taskforce-ready-with-report"">Report finished in November but not yet released to the public.</a>",,Kenya,"Ministry of Information, Communications and Technology"
Industry 4WRD - National Policy on Industry 4.0,AI in general,Strategy,,National,11/1/2018 0:00,"<a target=""_blank"" href=""http://www.miti.gov.my/miti/resources/National%20Policy%20on%20Industry%204.0/Industry4WRD_Final.pdf"">Industry 4WRD - National Policy on Industry 4.0</a>",,Malaysia,Ministry of International Trade and Industry
Draft Bill Governing the Experimental Use of Self-Driving Vehicles,Autonomous mobility,Legislation,,National,11/1/2017 0:00,"<a target=""_blank"" href=""https://www.government.nl/latest/news/2017/11/22/new-legislation-allows-for-the-testing-of-cars-with-remote-drivers"">Draft Bill Governing the Experimental Use of Self-Driving Vehicles</a><br><a target=""_blank"" href=""https://www.government.nl/topics/mobility-public-transport-and-road-safety/self-driving-vehicles"">Ministry overview of AV</a>",,Netherlands,Ministry of Infrastructure and Water Management
Essential H&S requirements for industrial machines equipped with machine learning,Robotics,Report,,National,9/1/2018 0:00,"<a target=""_blank"" href=""http://publications.tno.nl/publication/34627075/1L54hT/TNO-2018-R10499Engels.pdf"">Essential H&S requirements for industrial machines equipped with machine learning</a>",,Netherlands,Netherlands Organisation for Applied Scientific Research (TNO)
Legislation as code,Public services,Pilot,,National,1/1/2018 0:00,"<a target=""_blank"" href=""https://www.digital.govt.nz/dmsdocument/95-better-rules-for-government-discovery-report/html"">Legislation as code pilot</a>",,New Zealand,NZ Service Innovation Lab
AI - Shaping the Future of New Zealand,AI in general,Self-regulation,,National,5/1/2018 0:00,"<a target=""_blank"" href=""https://aiforum.org.nz/wp-content/uploads/2018/07/AI-Report-2018_web-version.pdf"">AI - Shaping the Future of New Zealand report</a>","The Artificial Intelligence Forum of New Zealand (AI Forum) is a not-for-profit, non-governmental organisation that founded in 2017. It is a member of the New Zealand Tech Alliance, and the Partnership on AI. <br><br><br><br>The AI Forum brings together New Zealand’s community of artificial intelligence technology innovators, end users, investor groups, regulators, researchers, educators, entrepreneurs and interested public. <br><br><br><br>It maintains 6 Working Groups, which cover strategy creation, public awareness, AI adoption, trusted data accessibility, talent pool enhancement, and law, ethics and society. <br><br><br><br>The report provides an introduction to the topic of AI, as well as a detailed mapping of the AI ecosystem in New Zealand and investigates the technology’s potential for the economy and society. The report also formulates a set of recommendations derived from expert interviews and research carried out over a one-year period. The recommendations fall under six themes, which overlap with the AI Forum’s working groups.",New Zealand,AI Forum New Zealand
Advisory Council on the Ethical Use of AI and Data,AI in general,Advisory body,,National,6/1/2018 0:00,"<a target=""_blank"" href=""https://www.imda.gov.sg/about/newsroom/media-releases/2018/composition-of-the-advisory-council-on-the-ethical-use-of-ai-and-data"">Advisory Council on the Ethical Use of AI and Data</a>",,Singapore,Infocomm Media Development Authority
Discussion Paper On AI and Personal Data,AI in general,Report,,National,6/1/2018 0:00,"<a target=""_blank"" href=""https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/Discussion-Paper-on-AI-and-PD---050618.pdf"">Discussion Paper On AI and Personal Data</a>",,Singapore,Personal Data Protection Commission
Singapore Autonomous Vehicle Initiative,Autonomous mobility,Partnership,,National,8/1/2014 0:00,"<a target=""_blank"" href=""https://www.lta.gov.sg/content/ltaweb/en/roads-and-motoring/managing-traffic-and-congestion/intelligent-transport-systems/savi.html"">Singapore Autonomous Vehicle Initiative</a>","The deployment of autonomous vehicles features prominently in Singapore’s Smart Nation strategy. Acting sooner than other countries, in 2014 the government formed the Committee on Autonomous Road Transport for Singapore (CARTS) “to holistically chart the strategic direction for AV-enabled land mobility concepts in Singapore” and launched the Singapore Autonomous Vehicle Initiative (SAVI) as a partnership between the Land Transport Authority and the Agency for Science, Technology and Research. <br>The aim of the initiative is to provide a technology platform for the R&D and test-bedding of AV technology solutions. These efforts form parts of Singapore’s broader strategy towards attaining a sustainable transport ecosystem, which seeks to reduce reliance on private transport through ride sharing and mobility on demand, to increases use of public transport. AVs can play a role in achieving these aims through increased road safety, increased productivity and optimised road capacity. The plans include autonomous bus services and truck platooning as well.<br>Singapore built an artificial 2-hectare mini-town for the testing of AVs by companies, where all the gathered data is shared with the Land Transport Authority. This data will be used to evaluate the technology’s readiness for broad deployment. The city-state’s Road Traffic Act was also updated in 2017 to allow the Land Transport Authority to issue rules about the testing of AVs on public roads and some testing sites have been designated. This sandbox was initially restricted to 5 years at the end of which period more permanent legislation may be crafted.<br>According to KPMG’s 2018 Autonomous Vehicles Readiness Index, Singapore tops the list in terms of policy and legislation.",Singapore,Land Transport Authority
Mid-to Long-term Master Plan in Preparation for the Intelligent Information Society,AI in general,Strategy,,National,7/1/2017 0:00,"<a target=""_blank"" href=""http://english.msit.go.kr/cms/english/pl/policies2/__icsFiles/afieldfile/2017/07/20/Master%20Plan%20for%20the%20intelligent%20information%20society.pdf"">Mid-to Long-term Master Plan in Preparation for the Intelligent Information Society</a>",,South Korea,Government of the Republic of Korea
National Approach to AI,AI in general,Strategy,,National,5/1/2018 0:00,"<a target=""_blank"" href=""https://www.regeringen.se/4aa638/contentassets/a6488ccebc6f418e9ada18bae40bb71f/national-approach-to-artificial-intelligence.pdf"">Swedish national approach to AI</a>",,Sweden,Swedish Government
AI Principles and Ethics,AI in general,Ethics guidelines,,National,1/1/2019 0:00,"<a target=""_blank"" href=""https://www.smartdubai.ae/initiatives/ai-principles-ethics"">Smart Dubai AI Principles</a>",,United Arab Emirates,Smart Dubai
Center for Data Ethics and Innovation,AI in general,Advisory body,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.gov.uk/government/groups/centre-for-data-ethics-and-innovation-cdei"">Center for Data Ethics & Innovation</a>",,United Kingdom,"UK Department for Digital, Culture, Media & Sport ; UK Department for Business, Energy & Industrial Strategy"
All-Party Parliamentary Group on AI,AI in general,Advisory body,,National,1/1/2017 0:00,"<a target=""_blank"" href=""https://www.appg-ai.org/"">All-Party Parliamentary Group on AI</a>",,United Kingdom,UK Parliament
The AI Council,AI in general,Advisory body,,National,6/1/2018 0:00,"<a href=""https://www.gov.uk/government/groups/ai-council"" target=_blank>UK AI Council</a>","The AI Council was established as part of the UK's AI Sector Deal. Its role is to oversee the implementation of the Sector Deal, providing ""strategic leadership and momentum in delivery"". It is comprised of respected leaders from academia and industry as well as ministry representatives.",United Kingdom,UK Government
"Pricing algorithms research, collusion and personalised pricing",Pricing algorithms,Research,Pricing algorithms,National,6/1/2018 0:00,"<a target=""_blank"" href=""https://www.gov.uk/government/publications/pricing-algorithms-research-collusion-and-personalised-pricing"">Pricing algorithms research, collusion and personalised pricing</a>",,United Kingdom,UK Competition and Markets Authority
Principles of Robotics,Robotics,Ethics guidelines,,National,9/1/2010 0:00,"<a target=""_blank"" href=""https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofrobotics/"">Principles of Robotics</a>",,United Kingdom,UK Engineering and Physical Sciences Research Council
Government Office for AI,AI in general,Government body,Accountability; Labour market effects;,National,6/1/2018 0:00,"<a href=""https://www.gov.uk/government/organisations/office-for-artificial-intelligence"" target=_blank>UK Government Office for AI</a>","The Office is a joint unit between Digital & Tech Policy Directorate in Department for Digital, Culture, Media and Sport, and the Business Growth Directorate in Department for Business, Energy & Industrial Strategy (BEIS). The Office will work on cutting edge issues at the intersection of government and technology in collaboration with industry partners and researchers. <br>The Office's aim is to establish the UK as a world leader in the responsible, innovative and effective use of AI and it will work across government departments and with external stakeholders, as well cooperate with the Centre for Data Ethics and Innovation. <br>Four major areas for the Office will be:<br> - Access to data;<br> - Skills development;<br> - Leadership; <br> - Industry adoption. <br>Actions in these areas will build on the recommendations of the 2017 AI review 'Growing the Artificial Intelligence Industry in the UK'. <br>The Office will address broader questions related to AI, such as its labour market implications.",United Kingdom,UK Government
Initial code of conduct for data-driven health and care technology,Health,Guidelines,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.gov.uk/government/publications/code-of-conduct-for-data-driven-health-and-care-technology/initial-code-of-conduct-for-data-driven-health-and-care-technology"">Initial code of conduct for data-driven health and care technology</a>",,United Kingdom,UK Department of Health and Social Care
Artificial Intelligence Procurement Policy,Public services,Partnership,Procurement,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.weforum.org/press/2018/09/united-kingdom-partners-with-world-economic-forum-to-develop-first-artificial-intelligence-procurement-policy/"">Artificial Intelligence Procurement Policy project</a>",,United Kingdom,World Economic Forum; UK Government
"Regulator's Pioneer Fund",AI in general,Pilot,,National,10/1/2018 0:00,"<a target=""_blank"" href=""https://www.gov.uk/government/news/projects-lay-the-groundwork-for-a-future-of-robolawyers-and-flying-cars"">Regulator's Pioneer Fund</a>",,United Kingdom,"Department for Business, Energy & Industrial Strategy"
Data Trust pilots,Model and data management,Pilot,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://theodi.org/article/uks-first-data-trust-pilots-to-be-led-by-the-odi-in-partnership-with-central-and-local-government/"">ODI Data Trust pilots</a>",,United Kingdom,Open Data Institute
Machine Intelligence Commission Proposal,AI in general,Proposal,,National,2/1/2016 0:00,"<a target=""_blank"" href=""https://media.nesta.org.uk/documents/a_machine_intelligence_commission_for_the_uk_-_geoff_mulgan.pdf"">Nesta - Machine Intelligence Commission Proposal</a>",,United Kingdom,Nesta
Vehicle Technology and Aviation Bill,Autonomous mobility,Bill,,National,2/1/2017 0:00,"<a target=""_blank"" href=""https://publications.parliament.uk/pa/bills/cbill/2016-2017/0143/cbill_2016-20170143_en_2.htm"">Vehicle Technology and Aviation Bill</a>",,United Kingdom,Parliament
Algorithms in decisionmaking,Automated Decision Systems,Report,,National,5/1/2018 0:00,"<a target=""_blank"" href=""https://publications.parliament.uk/pa/cm201719/cmselect/cmsctech/351/351.pdf"">Algorithms in decisionmaking</a>",,United Kingdom,House of Commons Science and Technology Committee
"The Malicious Use of AI: Forecasting, Prevention, and Mitigation",AI in general,Report,,International - Global,2/1/2018 0:00,"<a target=""_blank"" href=""https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/1c6q2kc4v_50335.pdf"">The Malicious Use of AI report</a>",,Global,Future of Humanity Institute
Data Ethics Canvas,Model and data management,Resource,,National,8/1/2017 0:00,"<a target=""_blank"" href=""https://theodi.org/article/data-ethics-canvas/"">Data Ethics Canvas</a>",,United Kingdom,Open Data Institute
AI Select Committee,AI in general,Select Committee,,National,6/1/2017 0:00,"<a target=""_blank"" href=""https://www.parliament.uk/ai-committee"">AI Select Committee</a><br><a target=""_blank"" href=""https://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/10002.htm"">AI in the UK: ready, willing and able? report of the HoL Select Committee</a><br><a target=""_blank"" href=""https://www.parliament.uk/documents/lords-committees/Artificial-Intelligence/AI-Government-Response.pdf"">Government response to Select Committee report</a>",,United Kingdom,House of Lords
DeepMind Ethics & Society,AI in general,Self-regulation,,International - Global,10/1/2017 0:00,"<a target=""_blank"" href=""https://deepmind.com/applied/deepmind-ethics-society/"">DeepMind Ethics & Society</a>",,Global,DeepMind
Guide to the ethical design and application of robots and robotic systems,Robotics,Standardisation,,National,4/1/2016 0:00,"<a target=""_blank"" href=""https://www.bsigroup.com/en-GB/about-bsi/media-centre/press-releases/2016/april/-Standard--highlighting-the-ethical-hazards-of-robots-is-published/"">Guide to the ethical design and application of robots and robotic systems</a>",,United Kingdom,British Standards Institute
AI Sector Deal,AI in general,Strategy,,National,4/1/2018 0:00,"<a target=""_blank"" href=""https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/702810/180425_BEIS_AI_Sector_Deal__4_.pdf"">AI Sector Deal</a>",,United Kingdom,UK Government
Group of Governmental Experts on Lethal Autonomous Weapons Systems (LAWS),Lethal autonomous weapon systems,Report,,International - Global,11/1/2017 0:00,"[url=https://www.unog.ch/80256EDD006B8954/(httpAssets)/B5B99A4D2F8BADF4C12581DF0048E7D0/$file/2017_CCW_GGE.1_2017_CRP.1_Advanced_+corrected.pdf]Group of Governmental Experts on Lethal Autonomous Weapons Systems (LAWS)<span style=""color: red""><span style=""color: red""><span style=""color: red""><span style=""color: red"">[/url]</span></span></span></span>",,Global,United Nations
AI in Government Act,Public services,Bill,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/senate-bill/3502"">AI in Government Act</a>",,USA,US Senate
Open Government Data Act,Public services,Bill,,National,7/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/senate-bill/760"">Open Government Data Act</a><br><a target=""_blank"" href=""https://www.datacoalition.org/open-government-data-act/"">Data Coalition Resources on US Open Gov Data</a>",,USA,US Senate
AI Caucus,AI in general,Caucus,,National,"May 1, 2017 00:00","<a target=""_blank"" href=""https://artificialintelligencecaucus-olson.house.gov/"">AI Caucus</a>",,USA,US Congress
Ethical guidelines for applying predictive tools within human services,Public services,Ethics guidelines,,National,9/1/2017 0:00,"<a target=""_blank"" href=""https://metrolabnetwork.org/wp-content/uploads/2017/09/Ethical-Guidelines-for-Applying-Predictive-Tools-within-Human-Services_Sept-2017.pdf"">Ethical guidelines for applying predictive tools within human services</a>",,USA,Metrolab Network
Equal Credit Opportunity Act,Finance,Federal law,,National,10/1/1974 0:00,"<a target=""_blank"" href=""http://uscode.house.gov/view.xhtml?path=/prelim@title15/chapter41/subchapter4&edition=prelim"">Equal Credit Opportunity Act</a>",,USA,US House of Representatives
Artificial Intelligence for Citizen Services,Public services,Government community,,National,10/1/2016 0:00,"<a target=""_blank"" href=""https://www.gsa.gov/technology/government-it-initiatives/emerging-citizen-technology/artificial-intelligence-for-citizen-services"">Artificial Intelligence for Citizen Services</a>",,USA,US General Services Administration
Communications Decency Act of 1996,Intermediaries,Legislation,,National,2/1/1996 0:00,"<a target=""_blank"" href=""https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/13069a-ads2.0_090617_v9a_tag.pdf"">Communications Decency Act of 1996</a>",,USA,US Senate
AB-375 Privacy: personal information: businesses,Data protection,Proposed law,,Regional,"Jun 1, 2018 00:00",https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=201720180AB375]AB-375 Privacy: personal information: businesses,,USA,California State Legislature
An Act relative to criminal justice reform (S.2185),Justice system,Bill,,Regional,10/1/2017 0:00,"<a target=""_blank"" href=""https://malegislature.gov/Bills/190/S2185/BillHistory"">An Act relative to criminal justice reform (S.2185)</a><br><a target=""_blank"" href=""https://medium.com/berkman-klein-center/the-following-letter-signed-by-harvard-and-mit-based-faculty-staff-and-researchers-chelsea-7a0cf3e925e9"">Open Letter by Harvard-MIT faculty</a>",,USA,Massachusetts Senate
National Security Commission Artificial Intelligence Act of 2018 (HR 5356 / S 2806,National security,Bill,,National,5/1/2018 0:00,"<a target=""_blank"" href=""https://scipol.duke.edu/track/hr-5356-national-security-commission-artificial-intelligence-act-2018/national-security"">National Security Commission Artificial Intelligence Act of 2018 (HR 5356 / S 2806)</a>",,USA,US House ; US Senate
Artificial Intelligence Job Opportunities and Background Summary Act of 2018 (AI JOBS Act of 2018),AI in general,Bill,,National,1/1/2018 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/house-bill/4829"">AI JOBS Act of 2018</a>",,USA,US House of Representatives
Innovation Corps Act of 2017 (H.R.1576),AI in general,Bill,,National,3/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/house-bill/1576?q=%7B%22search%22%3A%5B%22%5C%22Artificial+Intelligence%5C%22%22%5D%7D&r=5"">Innovation Corps Act of 2017</a> [font=Verdana, Arial, Helvetica, sans-serif]H.R.1576",,USA,US House of Representatives
SELF-DRIVE Act,Autonomous mobility,Bill,,National,9/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/house-bill/3388/"">SELF-DRIVE Act</a>",,USA,US House of Representatives
American Vision for Safer Transportation through Advancement of Revolutionary Technologies (AV START) Act,Autonomous mobility,Bill,,National,11/1/2017 0:00,"<a target=""_blank"" href=""https://www.congress.gov/bill/115th-congress/senate-bill/1885"">AV START Act</a>",,USA,US Senate
Driverless Testing of Vehicles,Autonomous mobility,Regulation,,Regional,4/1/2018 0:00,"<a target=""_blank"" href=""https://www.dmv.ca.gov/portal/dmv/detail/vr/autonomous/auto"">California Driverless Testing of Vehicles</a>",,USA,California Department of Motor Vehicles
Preparing for the Future of Transportation Automated Vehicles 3.0,Autonomous mobility,Regulation,,National,10/1/2018 0:00,"<a target=""_blank"" href=""https://www.transportation.gov/sites/dot.gov/files/docs/policy-initiatives/automated-vehicles/320711/preparing-future-transportation-automated-vehicle-30.pdf"">Preparing for the Future of Transportation Automated Vehicles 3.0</a><br>[font=Verdana, Arial, Helvetica, sans-serif]<a target=""_blank"" href=""https://www.autosafety.org/center-for-auto-safety-petitions-nhtsa-to-begin-rulemaking-to-immediately-mandate-submission-of-safety-information-by-companies-testing-self-driving-technology-on-public-road/"">Center for Auto Safety Petition to NHTSA</a>",,USA,US Department of Transport
Supervisory Guidance on Model Risk Management (SR-11-7),Finance,Regulation,,National,4/1/2011 0:00,"<a target=""_blank"" href=""https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf"">Federal Reserve SR-11-7</a>",,USA,US Federal Reserve
NHTSA Action on AVs,Autonomous mobility,Regulation,,National,12/1/2016 0:00,"<a target=""_blank"" href=""All NHTSA Action on AVs"">All NHTSA Action on AVs</a>",,USA,US National Highway Traffic Safety Administration
Automated Driving Systems - A Vision for Safety 2.0,Autonomous mobility,Regulation,,National,9/1/2017 0:00,"<a target=""_blank"" href=""https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/13069a-ads2.0_090617_v9a_tag.pdf"">Automated Driving Systems - A Vision for Safety 2.0</a>",,USA,US National Highway Traffic Safety Administration
Federal Automated Vehicles Policy,Autonomous mobility,Regulation,,National,9/1/2016 0:00,"<a target=""_blank"" href=""https://www.transportation.gov/sites/dot.gov/files/docs/AV%20policy%20guidance%20PDF.pdf"">Federal Automated Vehicles Policy</a>",,USA,US National Highway Traffic Safety Administration
State-level AV laws,Autonomous mobility,Legislation,,National,3/1/2011 0:00,"<a target=""_blank"" href=""http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx"">NCSL state-level AV legislation database</a><br><a target=""_blank"" href=""http://cyberlaw.stanford.edu/wiki/index.php/Automated_Driving:_Legislative_and_Regulatory_Action"">Stanford collection of State-level AV laws</a>","The National Conference on State Legislatures hosts a searchable database of all enacted pieces of legislation with regard to autonomous vehicles. As of 14 January 2019, it lists 64 items from 30 different states. The legislations cover a range of topics, such as commercial AV use, cybersecurity of vehicles, definitions, infrastructure and connected vehicles, insurance and liability, licensing and registration, operation on public roads, operator requirements, the privacy of collected vehicle data, requests for study, vehicle inspection requirements and vehicle testing.",USA,US States
AI and National Security,National security,Research,,National,7/1/2017 0:00,"<a target=""_blank"" href=""https://www.belfercenter.org/sites/default/files/files/publication/AI%20NatSec%20-%20final.pdf"">AI and National Security</a>",,USA,Belfer Centre at Harvard
AI Next Campaign,AI in general,Research,,National,9/1/2018 0:00,"<a target=""_blank"" href=""https://www.darpa.mil/work-with-us/ai-next-campaign"">AI Next Campaign</a>","AI Next is a multi-year, $2 billion research program by the US Defense Advanced Research Projects Agency. Its aim is to develop ‘Third Wave’ AI technologies capable of acquiring new knowledge through generative and contextual explanatory models.<br><br><br><br>Key areas of the campaign include automating critical DoD business processes, such as security clearance vetting or accrediting software systems for operational deployment; improving the robustness and reliability of AI systems; enhancing the security and resiliency of machine learning and AI technologies; reducing power, data, and performance inefficiencies; and pioneering the next generation of AI algorithms and applications, such as “explainability” and common sense reasoning.<br><br><br><br>An important element of the research is the AI Exploration program, which offers 18 months’ funding to selected, high-risk high-payoff projects and uses a streamlined contracting process to expedite project development.",USA,DARPA
Narrative Analysis of AI,AI in general,Research,,National,7/1/2017 0:00,"<a target=""_blank"" href=""https://www.oodaloop.com/wp-content/uploads/2017/07/OCIA-NetAssessment-Artificial_Intelligence_Narrative_Analysis.pdf"">Narrative Analysis of AI</a>",,USA,Department of Homeland Security
Nondisclosed-by-default policy,AI in general,Self-regulation,,National,11/1/2018 0:00,"<a target=""_blank"" href=""https://intelligence.org/2018/11/22/2018-update-our-new-research-directions/"">Nondisclosed-by-default research policy</a>",,USA,Machine Intelligence Research Institute
NIST AI Standards Programme,AI in general,Standardisation,,National,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.nist.gov/topics/artificial-intelligence"">AI Programme</a>",,USA,National Institute of Standards and Technology
Pretrial release or detention: pretrial services (SB-10),Justice system,State legislation,,Regional,8/1/2018 0:00,"<a target=""_blank"" href=""https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB10"">SB-10 Bill text</a><br><a target=""_blank"" href=""https://policylab.stanford.edu/media/improving-california-bail.pdf"">Stanford Computational Policy Lab opinion</a><br><a target=""_blank"" href=""https://www.eff.org/deeplinks/2018/11/if-pre-trial-risk-assessment-tool-does-not-satisfy-these-criteria-it-needs-stay"">Electronic Frontier Foundation opinion</a><br><a target=""_blank"" href=""https://www.hrw.org/sites/default/files/supporting_resources/hrw_sb_10_opposition_letter.pdf"">Human Rights Watch opinion</a>",,USA,California State Legislature
Bots: disclosure Act (SB-1001),Bots,,,Regional,9/1/2018 0:00,"<a target=""_blank"" href=""https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1001"">SB-1001 Bill text</a><br><a target=""_blank"" href=""https://www.eff.org/deeplinks/2018/05/should-ai-always-identify-itself-its-more-complicated-you-might-think"">Electronic Frontier Foundation opinion</a>",,USA,California State Legislature
National AI R&D Strategic Plan,AI in general,Strategy,,National,10/1/2016 0:00,https://www.nitrd.gov/PUBS/national_ai_rd_strategic_plan.pdf]National AI R&D Strategic Plan,,USA,National Science and Technology Council
Lethal Autonomous Weapons Pledge,Lethal autonomous weapon systems,Self-regulation,Human control;,International - Global,7/1/2018 0:00,"<a target=""_blank"" href=""https://futureoflife.org/lethal-autonomous-weapons-pledge/"">The pledge</a>",Those who sign the pledge call upon governments to develop strong international norms and rules against lethal autonomous weapon systems. They also commit to not participating in the development or trade of such systems in any way. <br>The pledge has been endorsed by hundreds of companies and thousands of AI researchers from across the world.,Global,Future of Life Institute
Responsible AI in the Canadian Government,Public services,White paper,Bias; Accountability; Oversight; Ethical design; Transparency;,National,4/1/2018 0:00,"<a target=""_blank"" href=""https://docs.google.com/document/d/1Sn-qBZUXEUG4dVk909eSg5qvfbpNlRhzIefWPtBwbxY/edit"">White paper</a>","The white paper lays out 7 principles that will guide the Canadian Treasury Board’s policy on the use of AI in government. It forms part of the Canadian Government’s efforts to take global leadership on AI policy development and showcasing that strong ethical principles support positive outcomes. The principles are intended for the use of federal institutions looking to use AI for the delivery of public services, to help design policy and respond to risk, or to the internal services of government.<br><ol><br><li>“People should always be governed – and perceive to be governed – by people;”</li><br><li>“AI systems deployed on behalf of government should be trained to reflect the <em>Values and Ethics of the Public Sector</em> as well as Canadian and international human rights obligations; they should be used to reinforce these values where possible;”</li><br><li>“Organizations are accountable for the actions of AI systems, and should build systems that are auditable;”</li><br><li>“Understanding the need to protect privacy and national security, AI systems should be deployed in the most transparent manner possible;”</li><br><li>“Organizations should ensure that reliable contingencies are in place for when AI systems fail, or to provide services to those unable to access these systems;”</li><br><li>“AI systems should be developed in a diverse team that includes individuals capable of assessing the ethical and socioeconomic implications of the system;“</li><br><li>“AI systems should be deployed in a manner that minimizes negative impact to employees where possible, and should, where feasible, be created alongside the employees that will work with them.”</li><br></ol><br>The report also recommends institutions to invest in their data science and business intelligence capacity, which is the foundation of using AI tools. Chief Data Officers should manage investments in building up data science capacity and the deployment of AI tools should come with a multidisciplinary team comprised of social scientists, ethicists, data scientists, change management professionals and user experience designers.<br>The paper also proposes the establishment of some oversight body, such as an ad-hoc Automation Advisory Board, to provide guidance to Federal institutions on the ethical design and deployment of AI-driven tools.",Canada,Government of Canada
Police Directive,Law enforcement,Directive,,International - EU,4/1/2016 0:00,"<a target=""_blank"" href=""https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=uriserv%3AOJ.L_.2016.119.01.0089.01.ENG"">Police Directive</a>",The Police Directive seeks to apply the key data protection principles of the GDPR to EU police authorities.,European Union,European Parliament and Council
Stanford 100 Year Study,AI in general,Research,,International - Global,12/1/2014 0:00,"<a target=""_blank"" href=""https://ai100.stanford.edu/"">Stanford 100 Year Study</a>",,Global,Stanford University
"Principles to Promote Fairness, Ethics, Accountability and Transparency in the Use of AI and Data Analytics in Singapore’s Financial Sector",Finance,Ethics guidelines,,National,11/1/2018 0:00,"<a target=""_blank"" href=""http://www.mas.gov.sg/~/media/MAS/News%20and%20Publications/Monographs%20and%20Information%20Papers/FEAT%20Principles%20Final.pdf"">Principles to Promote Fairness, Ethics, Accountability and Transparency in the Use of AI and Data Analytics in Singapore’s Financial Sector</a>",,Singapore,Monetary Authority of Singapore
Catalonia Living Lab for Connected and Automated Driving,Autonomous mobility,Test environment,,National,10/1/2017 0:00,"<a target=""_blank"" href=""http://catalonialivinglab.com/"">Catalonia Living Lab for Connected and Automated Driving</a>",,Spain,Catalan Government
Driverless Futures,Autonomous mobility,Research,,National,1/1/2019 0:00,"<a target=""_blank"" href=""https://driverless-futures.com/"">Driverless Futures</a>",,United Kingdom,UK Economic and Social Research Council
IBM AI Ethical Principles,AI in general,Self-regulation,,International - Global,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.ibm.com/watson/ai-ethics/"">IBM AI Ethical Principles</a>",,Global,IBM
Safe Face Pledge,Facial recognition,Self-regulation,,International - Global,12/1/2018 0:00,"<a target=""_blank"" href=""https://www.safefacepledge.org/"">Safe Face Pledge</a>",,Global,Algorithmic Justice League
Deutsche Telekom AI Guidelines,AI in general,Self-regulation,,International - Global,11/1/2018 0:00,"<a target=""_blank"" href=""https://www.telekom.com/en/company/digital-responsibility/details/artificial-intelligence-ai-guideline-524366"">Deutsche Telekom AI Guidelines</a>",,Global,Deutsche Telekom
ITU Focus Group on AI for Health,Health,Working group,,International - Global,7/1/2018 0:00,"<a target=""_blank"" href=""https://www.itu.int/en/ITU-T/focusgroups/ai4h/Pages/default.aspx"">ITU Focus Group on AI for Health</a>",,Global,International Telecommunications Union ; Wolrd Health Organization
Study On The Human Rights Dimensions Of Automated Data Processing Techniques (In Particular Algorithms) And Possible Regulatory Implications,Automated Decision Systems,Report,,International - EU,3/1/2018 0:00,"<a target=""_blank"" href=""https://rm.coe.int/algorithms-and-human-rights-study-on-the-human-rights-dimension-of-aut/1680796d10"">Study On The Human Rights Dimensions Of Automated Data Processing Techniques (In Particular Algorithms) And Possible Regulatory Implications</a>",,European Union,Council of Europe; Committee of Experts on Internet Intermediaries (MSI-NET)
Comprehensive European industrial policy on AI and robotics,AI in general,Report,,International - EU,11/1/2018 0:00,"<a target=""_blank"" href=""http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//NONSGML+COMPARL+PE-630.525+01+DOC+PDF+V0//EN&language=EN"">Comprehensive European industrial policy on AI and robotics</a>",,European Union,"European Parliament Committee on Industry, Research and Energy"
Ethical Accountability Framework,Model and data management,Report,,National,10/1/2018 0:00,"<a target=""_blank"" href=""https://www.pcpd.org.hk/misc/files/Ethical_Accountability_Framework.pdf"">Ethical Accountability Framework</a>",,Hong Kong,Privacy Commissioner for Personal Data
FRR Certificate,Robotics,Self-regulation ; Standardisation,,International - Global,9/1/2018 0:00,"<a target=""_blank"" href=""https://responsiblerobotics.org/can-ai-survive-without-public-trust/"">FRR Certificate</a>",,Global,Foundation for Responsible Robotics
Axon AI and Policing Technology Ethics Board,Law enforcement,Self-regulation ; Ethics guidelines,,International - Global,4/1/2018 0:00,"<a target=""_blank"" href=""https://global.axon.com/info/ai-ethics"">Axon AI and Policing Technology Ethics Board</a>",,Global,Axon
Protocol amending the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data,Data protection,Treaty,,International - EU,10/10/2018 12:12,"<a target=""_blank"" href=""https://www.coe.int/en/web/conventions/full-list/-/conventions/rms/09000016808ac918"">Protocol amendment text</a><br><br><a target=""_blank"" href=""https://rm.coe.int/CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=09000016808ac91a"">Explanatory Report<br>to the Protocol</a>","The Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data is a Council of Europe treaty that was originally signed in 1981. Its aim was to strengthen data protection with respect to the automatic processing of personal data. It was prompted by the growing use of computers for administrative purposes and the move away from manual files. It was the first legally binding international instrument on data protection. It outlawed the collection of ""sensitive"" data on a person's race, politics, health, religion, sexual life, criminal record, etc., in the absence of proper legal safeguards. It also guaranteed individuals the right to know what information is stored about them and to have that information corrected. In October 2018 a Protocol amending the Convention was opened for signature.<br><br>The protocol aims to modernise the Convention and ensure consistency with other EU data protection activities, such as the GDPR and the Police Directive. The Convention is also an instrument of spreading the EU approach to data protection because it serves as the basis of privacy legislation in several countries outside the EU, providing a flexible multilateral framework. The Protocol contains several updates, such as 1) Stronger requirements regarding the proportionality and data minimisation principles; 2) Extension of the types of sensitive data, which will now include genetic and biometric data, trade union membership and ethnic origin; 3) the obligation to declare data breaches; 4) increased transparency of data processing; 5) new rights for the persons in an algorithmic decision making context; 6) stronger accountability of data controllers; 7) the requirement that the “privacy by design” principle is applied; 8) requiring the application of the data protection principles to all processing activities, including for national security reasons; 9) clear regime of transborder data flows; 10) reinforced powers and independence of the data protection authorities and enhancing legal basis for international cooperation.",European Union,Council of Europe
Unfairness by algorithm,Automated Decision Systems,Report,,International - Global,12/11/2017 0:00,"<a target=""_blank"" href=""https://fpf.org/wp-content/uploads/2017/12/FPF-Automated-Decision-Making-Harms-and-Mitigation-Charts.pdf"">Report</a>","The Future of Privacy Forum is a US-based ""nonprofit organization that serves as a catalyst for privacy leadership and scholarship, advancing principled data practices in support of emerging technologies.""<br>In order to advance the debate on the fair use of data and algorithms, the FPF has conducted an extensive review of the academic and grey literature of algorithmic discrimination. This resulted in two condensed charts offering a categorisation of possible algorithmic harms and strategies for their mitigation. The harms are grouped into individual and collective/societal harms, and include loss of opportunity, economic loss, social detriment, and loss of liberty. Individual harms are further broken down into illegal and unfair.",Global,Future of Privacy Forum
Automating Society,Automated Decision Systems,Report,,International - EU,1/29/2019 0:00,"<a target=""_blank"" href=""https://algorithmwatch.org/en/automating-society/"">Automating Society report</a>","Based in Germany, AlgorithmWatch is ""a non-profit research and advocacy organisation to evaluate and shed light on algorithmic decision making processes that have a social relevance, meaning they are used either to predict or prescribe human action or to make decisions automatically.""<br>The report was produced in collaboration with the Bertelsmann Foundation with support from the Open Society Foundations. It takes stock of automated decision-making at the EU level and in 12 Member States: Belgium, Denmark, Finland, France, Germany, Italy, Netherlands Poland, Slovenia, Spain, Sweden and the UK. The report covers societal discussions on the topic of automated decision-making, the regulatory proposals that have been put forward, as well as the oversight institutions and mechanisms that are in place. Finally, it contains an extensive list of automated decision-making systems 'in action' in both the private and public sectors at the time of publication.",European Union,AlgorithmWatch
Guidelines on AI and Data Protection,Data protection,Guidelines,,International - EU,1/25/2019 0:00,"<a target=""_blank"" href=""https://rm.coe.int/guidelines-on-artificial-intelligence-and-data-protection/168091f9d8"">Guidelines on AI and Data Protection</a>","The guidelines were issues by the Consultative Committee of the Convention for the Protection of Individuals with Regard to Automatic Processing of Personal Data. The Convention is a cornerstone of international data protection rules. The document offers general guidance, as well as specific points for developers, manufacturers and service providers, and a set of recommendations for legislators and policy makers.",European Union,Council of Europe
Perspectives on Issues in AI Governance,AI in general,White paper,,International - Global,1/22/2019 0:00,"<a target=""_blank"" href=""https://ai.google/static/documents/perspectives-on-issues-in-ai-governance.pdf"">White paper</a>","Google's white paper discusses 5 areas where governments, civil society and AI practitioners can collaborate on AI governance mechanisms. The five areas are ""explainability standards, approaches to appraising fairness, safety considerations, requirements for human-AI collaboration, and general liability frameworks."" For each of the 5 areas the paper outlines suggested actions. The document expresses the view that a significant portion of the AI governance debate has focused on high-level issues but it is time to advance pragmatic solutions to particular challenges.",Global,Google
A Proposed Model AI Governance Framework,AI in general,Proposal,,National,1/23/2019 0:00,"<a target=""_blank"" href=""https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Resource-for-Organisation/AI/A-Proposed-Model-AI-Governance-Framework-January-2019.pdf"">Model Framework</a>","The model outlines the PDPC's the first edition of a proposed AI Governance Framework, which is intended to ""help chart the language and frame the discussions around harnessing AI in a responsible way.""<br>It is built on two guiding principles, stating that AI decisions should be explainable, transparent and fair, and the overall AI systems should be human-centric. These overarching principles are translated into practical measures that organisations can implement. These measures include internal governance structures, risk management, operations management, and customer relationship management. <br>The document is intended as a resource to help organisations, trade associations, progressional bodies conduct internal discussions about how to adapt their processes to ensure responsible AI development and deployment. The PDPC is also looking to receive comments from such organisations to further improve upon the framework.",Singapore,Personal Data Protection Commission
Algorithmic Impact Assessment - A Practical Framework for Public Agency Accountability,Public services,Proposal,"accountability, trust, explainability, transparency, evaluation",International - Global,4/1/2018 0:00,"<a target=""_blank"" href=""https://ainowinstitute.org/aiareport2018.pdf"">AI Now AIA report</a>","<span style=""color: #000000"">Researchers at NYU’s AI Now Institute are proposing an Algorithmic Impact Assessment framework, designed to support governments, public agencies and other communities and stakeholders to assess claims made about automated decision systems and to determine whether their use is acceptable. </span><br><br><span style=""color: #000000"">Key elements of the proposed framework are: </span><br><span style=""color: #000000"">1. Agencies should conduct a self-assessment of existing and proposed automated decision systems, evaluating potential impacts on fairness, justice, bias, or other concerns across affected communities; </span><br><span style=""color: #000000"">2. Agencies should develop meaningful external researcher review processes to discover, measure, or track impacts over time; </span><br><span style=""color: #000000"">3. Agencies should provide notice to the public disclosing their definition of “automated decision system,” existing and proposed systems, and any related self-assessments and researcher review processes before the system has been acquired; </span><br><span style=""color: #000000"">4. Agencies should solicit public comments to clarify concerns and answer outstanding questions; and </span><br><span style=""color: #000000"">5. Governments should provide enhanced due process mechanisms for affected individuals or communities to challenge inadequate assessments or unfair, biased, or otherwise harmful system uses that agencies have failed to mitigate or correct. </span><br><br><span style=""color: #000000"">""An Algorithmic Impact Assessment, [..] gives both the agency and the public the opportunity to evaluate the adoption of an automated decision system before the agency has committed to its use. This allows the agency and the public to identify concerns that may need to be negotiated or otherwise addressed before a contract is signed."" </span><br><br><span style=""color: #000000"">Steps of an AIA: </span><br><br><ol><br><li><span style=""color: #000000""><span style=""color: #000000"">Establishing scope, defining ""automated decision systems"" in a way that is appropriate to the case at hand -- A challenge may arise around drawing the appropriate boundaries and accurately defining ADS. Reasonable example: “systems, tools, or statistical models used to measure or evaluate an individual criminal defendant’s risk of reoffending.” </span></span></li><br><li><span style=""color: #000000""><span style=""color: #000000"">Public notice: Alerting communities about systems that may affect their lives: public disclosure of proposed and existing automated decision systems, including their purpose, reach, internal use policies, and potential impacts on communities or individuals. -- A challenge may arise due to company trade secrecy claims. Here AI Now recommends that ""[a]t minimum, vendors should be contractually required by agencies to waive any proprietary or trade secrecy interest in information related to accountability, such as those surrounding testing, validation, and/or verification of system performance and disparate impact."" </span></span></li><br><li><span style=""color: #000000""><span style=""color: #000000"">Internal self-assessment: Agencies must evaluate how ADS systems might impact communities and how they can resolve any issues. This process should be standardized to ensure its comparability, and sufficiently detailed to allow external review/research. A non-technical summary should also be made available to enhance public trust and engagement. The evaluation should make clear how the overall impact of using any ADS will be net beneficial to the affected communities. Procedures for appealing decisions and for mitigating any undesirable effects should be articulated as well. This self-assessment builds agency expertise when buildign or commissing ADSs, including testing for biases. ""The benefits of self assessments to public agencies go beyond algorithmic accountability: it encourages agencies to better manage their own technical systems and become leaders in the responsible integration of increasingly complex computational systems in governance."" This practice would benefit vendors that prioritise fairness, accountability, and transparency, leading to a competitive advantage and contributing to more responsible practices overall. This expertise and standardisation will enhance transparency and accountability in public records requests. Challenge: how to assess cultural and societal impacts, especially those that target communities other than the dominant culture. How to prevent both allocative (groups denied access to resources/opportunities) and representational harms (reinforcing the subordination of a group)?  </span></span></li><br><li><span style=""color: #000000""><span style=""color: #000000"">Meaningful access: allow researchers and auditors rapid and ongoing access to review systems on they are in place. Sometimes pre-deployment reviews may be necessary as well. The type and level of access required to do this will vary among agencies, systems and communities. This will likely include providing access to training data and or a record of past decisions. Research and auditing should be accountable to the public, inlcuding a public log of who has access. Affected communities should be free to nominate reviewers/researchers they trust represent their interests. Findings should be openly available and subject to peer review. Challenge: Funding! Will external reviewers and researchers be expected to review without compensation? Will internal auditors be captured by the incentives of the organisation? Legislative solutions might include funding an independent, government-wide oversight body, like an inspector general’s office, to support research, access, and community engagement. Community institutional review boards could be supported and funding set aside for the compensation of external auditors.</span></span></li><br></ol>",USA,AI Now Institute
ITI AI Policy Principles,AI in general,Self-regulation ; Policy principles,Safety; Human control; Liability; Accountability; Bias; Transparency; Labour market effects; Security,International - Global,10/1/2017 0:00,"<a target=""_blank"" href=""https://www.itic.org/dotAsset/50ed66d5-404d-40bb-a8ae-9eeeef55aa76.pdf"">ITI AI Policy Principles </a>","The ITI is a Washington, DC-based trade association representing the ICT industry. It has been described as a ‘lobbying group’ and its membership includes the largest technology companies, like Apple, Amazon, Google, Intel, IBM, and others.<br>The paper offers a general outline of possible future cooperation between the private and the public sector, globally. ITI highlights industry’s responsibility in promoting responsible development and use of AI, the opportunity for governments to invest in and enable the AI ecosystem, and the opportunity for public-private partnerships, and groups its policy principles under these 3 headings.<br>Industry’s responsibility includes:<br>[ul]<br><li>Responsible Design and Deployment, meaning the “responsibility to integrate principles into the design of AI technologies, beyond compliance with existing laws”, in short, a commitment to ‘ethics-by-design’;</li><br><li>Safety and Controllability, meaning that AI systems must be safe, minimise risk to humans and remain controllable by them;</li><br><li>Robust and Representative Data, meaning that “ industry has a responsibility to understand the parameters and characteristics of the data, to demonstrate the recognition of potentially harmful bias, and to test for potential bias before and throughout the deployment of AI systems.”</li><br><li>Interpretability entails a commitment to working with partners to mitigate bias, inequity and other harms;</li><br><li>Liability of AI Systems Due to Autonomy, expresses the commitment to work with relevant stakeholders to create an accountability framework for autonomous systems.</li><br>[/ul]<br>With regard to governments’ role, ITI has several proposals:<br>[ul]<br><li>Investment in AI R&D, especially cyber-defence, data analytics, detection of fraudulent transactions, robotics, human augmentation, natural language processing, interfaces, visualizations;</li><br><li>Flexible regulatory approach, including especially the avoidance of overregulation. The application of sector-specific approaches is encouraged instead of making general policies. It also urges governments to evaluate existing policy tools before implementing changes in order to not “impede the responsible development and use of AI”;</li><br><li>Promoting innovation and the security of the Internet, with special care to government absence: companies should not be obliged to “transfer or provide access to technology, source code, algorithms, or encryption keys” as a condition of doing business;</li><br><li>Cybersecurity and privacy, encouraging the governments to use strong, globally accepted and deployed cryptography to ensure trust and interoperability; voluntary information sharing on hacks is proposed as a way of enabling consumer protection;</li><br><li>Voluntary, industry-led, consensus-based standards and best practices should be developed in order to promote competition and international collaboration.</li><br>[/ul]<br>ITI also embraces public-private partnerships to democratise access to AI resources, strengthening STEM education, and efforts aimed at managing the labour market transformations brought about by AI.",Global,The Information Technology Industry Council (ITI)
Congressional AI Caucus,AI in general,Caucus,,National,5/1/2017 0:00,"<a target=""_blank"" href=""https://artificialintelligencecaucus-olson.house.gov/"">AI Caucus</a>","A congressional caucus is comprised of a group of member of the US Congress who seek to advance a common legislative purpose. The tenure of a caucus expires when the mandate of a given Congress comes to an end. US congressional causes are similar to parliamentary groups in other countries.<br><Br><br><br>The AI Caucus of the 115th US Congress was launched by Democratic Congressman John K. Delaney in May 2017 and was co-chaired by Republican Congressman Pete Olson. The caucus’ goal was to inform policymakers of the technological, economic and social impacts of advances in AI in order to ensure that the technology’s benefits reach as many Americans as possible. To accomplish that goal the caucus brought together experts from academia, government and the private sector to discuss AI’s challenges and opportunities. <br><Br><br><br>Members of the Caucus played a key role in introducing the FUTURE of AI Act in December 2017, a bill that would have established a federal advisory committee to examine the societal implications of AI. <br><Br><br><br>The Caucus also released a statement in April 2018 calling on Facebook to clarify the ways in which it plans to use AI and how it will ensure respect for users’ privacy and unbiased algorithms.<Br><br><br><br>The formation of the bipartisan Senate Artificial Intelligence Caucus was announced in March 2019.",USA,US Congress
California Consumer Privacy Act (Assembly Bill No. 375),Data protection,Proposed law,Privacy; Data protection; Data brokerage;,Regional,6/1/2018 0:00,"<a href='https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=201720180AB375' target=""_newwindow"">AB-375 Privacy: personal information: businesses</a><br><br><a href=""https://fpf.org/wp-content/uploads/2019/12/ComparingPrivacyLaws_GDPR_CCPA.pdf"" target=""_newwindow"">Future of Privacy Forum - Comparing privacy laws: GDPR v. CCPA</a>","The California Consumer Privacy Act (CCPA) was signed into law on the 28th of June 2018 and came into effect on the 1st of January 2020, with a 6 months grace period before enforcement of the law begins. The CCPA is the most comprehensive privacy law in the United States and it grants California residents a range of new tools to protect their personal information online. These include<br>-	the right to know what personal information is being collected about them;<br><br>-	the right to access this information; <br><br>-	the right to know whether this data is sold and to whom; <br><br>-	the right to request that personal data be deleted, and to disallow its continued sale; <br><br>-	the right to receive equal service at an equal price, even if a user decides to opt-out of the sale of their data.<br><br><br>The CCPA also includes special protections for minors, prohibiting companies to sell the data of anyone under age 16 without prior authorization by the minor or their parents. .<br><br><br>The CCPA’s definition of ‘selling data’ does not only include financial compensation in exchange for sharing data, but also the exchange of information between entities. .<br><br><br>According to the CCPA ""personal information"" comprises non-public information that directly or indirectly relates to, is reasonably capable of being associated with, or could reasonably be linked to a particular consumer or household. .<br><br><br>The law applies to for-profit organisations that collect consumer’s personal information, does business and California and either has an annual gross revenue in excess of $25 million or buys/receives/sells/shares the personal data of at least 50 000 consumers, households or devices, or derives 50% or more of its annual revenues from selling consumers' personal information.<br><br><br>The law also requires businesses to place a “clear and conspicuous” link “Do Not Sell My Personal Information” on their websites, to enable consumers to opt out of the sale of their personal information. Importantly, businesses cannot require consumers to create an account in order to request the cessation of the sale of their personal information.<br><br><br>In addition, at least two designated methods must be made available to consumers – including a toll-free telephone number - to allow consumers to submit data requests. Businesses must supply the requested information free of charge within 45 days. <br><br><br>The law prescribes fines of up to $7500 for each intentional violation and $2500 for each unintentional violation.",USA,California State Legislature
Recommendations for an AI Strategy in Switzerland,AI in general,White paper,,National,11/12/2019,"<a href=""https://www.satw.ch/fileadmin/user_upload/documents/02_Themen/08_Kuenstliche-Intelligenz/SATW-Swiss_AI_Strategy.pdf"" target=""blank"">Recommendations for an AI Strategy in Switzerland</a>","The white paper by the Swiss Academy of Engineering Sciences puts forward recommendations for an AI strategy. The recommendations focus on 5 key areas.<br><br><br><br>First, the country should create national data platforms, for citizens to store their data in a way that allows them to maintaining full control over how their data is shared and used, while providing the opportunity to allow data to be used for socially beneficial purposes. The suggested model is that of a cooperative organization, such as the MIDATA health data platform. MIDATA was developed at ETH Zurich and Bern University of Applied Sciences. It allows the IT platform to be separated from the data applications, thereby creating an open innovation ecosystem. The goal is to empower and enable citizens to become active data aggregators. For that to happen, Switzerland must adopt the EU’s data portability framework, introduce a system of electronic identity, and take steps towards the creation of democratically controlled personal data ecosystem.<Br><br><br><br>Second, an institution should be established, at the governmental level in Switzerland, which would be tasked with the responsibility to establish requirements and perform verification and certification of AI systems.<Br><br><br><br>Third, steps should be taken to increase societal trust in AI and improve AI’s public image. On the one hand, positive AI images should be shared. At the same time, transparency should be enhanced and broad societal dialogue undertaken.<Br><br><br><br>Fourth, research on and with AI should be encouraged and its use in higher education strengthened. <Br><br><br><br>Fifth, an appropriate environment should be created for Swiss SME’s to benefit from AI.",Switzerland,Swiss Academy of Engineering Sciences
California Consumer Privacy Act (AB-375),Data protection,State legislation,Privacy; Data protection; Data brokerage;,Regional,6/1/2018 0:00,"<a href='https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=201720180AB375' target=""_newwindow"">AB-375 Privacy: personal information: businesses</a><br><br><a href=""https://fpf.org/wp-content/uploads/2019/12/ComparingPrivacyLaws_GDPR_CCPA.pdf"" target=""_newwindow"">Future of Privacy Forum - Comparing privacy laws: GDPR v. CCPA</a>","The California Consumer Privacy Act (CCPA) was signed into law on the 28th of June 2018 and came into effect on the 1st of January 2020, with a 6 months grace period before enforcement of the law begins. The CCPA is the most comprehensive privacy law in the United States and it grants California residents a range of new tools to protect their personal information online. These include<br>-	the right to know what personal information is being collected about them;<br><br>-	the right to access this information; <br><br>-	the right to know whether this data is sold and to whom; <br><br>-	the right to request that personal data be deleted, and to disallow its continued sale; <br><br>-	the right to receive equal service at an equal price, even if a user decides to opt-out of the sale of their data.<br><br><br><br>The CCPA also includes special protections for minors, prohibiting companies to sell the data of anyone under age 16 without prior authorization by the minor or their parents. .<br><br><br><br>The CCPA’s definition of ‘selling data’ does not only include financial compensation in exchange for sharing data, but also the exchange of information between entities. .<br><br><br><br>According to the CCPA ""personal information"" comprises non-public information that directly or indirectly relates to, is reasonably capable of being associated with, or could reasonably be linked to a particular consumer or household. .<br><br><br><br>The law applies to for-profit organisations that collect consumer’s personal information, does business and California and either has an annual gross revenue in excess of $25 million or buys/receives/sells/shares the personal data of at least 50 000 consumers, households or devices, or derives 50% or more of its annual revenues from selling consumers' personal information.<br><br><br><br>The law also requires businesses to place a “clear and conspicuous” link “Do Not Sell My Personal Information” on their websites, to enable consumers to opt out of the sale of their personal information. Importantly, businesses cannot require consumers to create an account in order to request the cessation of the sale of their personal information.<br><br><br><br>In addition, at least two designated methods must be made available to consumers – including a toll-free telephone number - to allow consumers to submit data requests. Businesses must supply the requested information free of charge within 45 days. <br><br><br><br>The law prescribes fines of up to $7500 for each intentional violation and $2500 for each unintentional violation.",USA,California State Legislature
BOT: Disclosure Act (SB-1001),Bots,State legislation,,Regional,9/1/2018 0:00,"<a target=""_blank"" href=""https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1001"">SB-1001 Bill text</a><br><a target=""_blank"" href=""https://www.eff.org/deeplinks/2018/05/should-ai-always-identify-itself-its-more-complicated-you-might-think"">Electronic Frontier Foundation opinion</a>",,USA,California State Legislature
Facial recognition technology: fundamental rights considerations in the context of law enforcement,Facial recognition,Report,,International - EU,11/1/2019,"<a href=""https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-facial-recognition-technology-focus-paper-1_en.pdf"" target=_blank>FRA Report on Facial Recognition and fundamental rights in the context of law enforcement</a>",,European Union,European Union Agency for Fundamental Rights (FRA)
Data quality and artificial intelligence - mitigating bias and error to protect fundamental rights,Model and data management,Report,bias; fundamental rights;,International - EU,6/1/2019,"<a href=""https://fra.europa.eu/sites/default/files/fra_uploads/fra-2019-data-quality-and-ai_en.pdf"" target=_blank>FRA Report data quality and AI</a>","""This paper sets out to contribute to the many ongoing policy discussions around AI and big data by highlighting one aspect that needs attention from a fundamental rights perspective; namely the awareness and avoidance of poor data quality. It does not aim at explaining how to use high quality data, but how to become aware of and avoid using low quality data.""",European Union,European Union Agency for Fundamental Rights (FRA)
#BigData: Discrimination in data-supported decision making,Model and data management,Report,discrimination; algorithmic decision-making; bias; fundamental rights; transparency;,International - EU,5/1/2019,"<a href=""https://fra.europa.eu/sites/default/files/fra_uploads/fra-2018-focus-big-data_en.pdf"" target=_blank>FRA Report on discrimination in data-supported decision making</a>",,European Union,European Union Agency for Fundamental Rights (FRA)
Mapping Regulatory Proposals For Artificial Intelligence In Europe,AI in general,Report,regulation;,International - EU,11/1/2018,"<a href=""https://www.accessnow.org/cms/assets/uploads/2018/11/mapping_regulatory_proposals_for_AI_in_EU.pdf"" target=_blank>AccessNow report on regulatory proposals for AI in Europe</a>",,European Union,Access Now
New York City Automated Decision Systems Task Force Report,Automated Decision Systems,Report,,City,11/1/2019,"<a href=""https://www1.nyc.gov/assets/adstaskforce/downloads/pdf/ADS-Report-11192019.pdf"" target=_blank>NYC ADS Task Force Report</a>",,USA,New York City Automated Decision Systems Task Force
Artificial Intelligence Profiling Act (HB2644),Profiling,Bill,surveillance; fundamental rights;,Regional,1/16/2020,"<a href=""http://lawfilesext.leg.wa.gov/biennium/2019-20/Pdf/Bills/House%20Bills/2644.pdf?q=20200124083150"" target=_blank>Text of proposed law HB2644</a>","The bill seeks to provide Washingtonians with important privacy protections against use of AI technology. Specifically, the Act would prohibit the use of artificial intelligence-based profiling in ""places of public resort, accommodation, assemblage, or amusement"". Moreover, similar to Europe's GDPR, the Act would would prohibit the use of AI-enabled profiling to make decisions that produce legal effects or similarly significant effects.
Finally, it would provide consumer protection remedies and a private right of action for individuals impacted by artificial intelligence-enabled profiling technology.",USA,Washington State Legislature
A Framework for Developing a National Artificial Intelligence Strategy,AI in general,White paper,national strategy;,International - Global,8/1/2019,"<a href=""http://www3.weforum.org/docs/WEF_National_AI_Strategy.pdf"" target=_blank>WEF Framework for developing a national AI strategy</a>",,Global,World Economic Forum
Algorithmic Accountability Act of 2019 (HR2231),Automated Decision Systems,Bill,,National,4/10/2019,"<a href=""https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf"" target=_blank>Text of the Algorithmic Accountability Act</a>",,USA,US Congress
"Establishing guidelines for government procurement and use of automated decision systems in order to protect consumers, improve transparency, and create more market predictability (HB1655; SB5527)",Automated Decision Systems,Bill,,Regional,1/25/2019,"<a href=""https://legiscan.com/WA/drafts/HB1655/2019"" target=_blank>Text of HB1655</a> ; <a href=""http://lawfilesext.leg.wa.gov/biennium/2019-20/Pdf/Bills/Senate%20Bills/5527.pdf"" target=_blank>Text of SB5527</a>","The bill was first introduced in the House of Representatives in January 2019 and, by resolution, reintroduced in January 2020. <br><br> It would establish guidelines for government procurement and use of automated decision systems in order to protect consumers, improve transparency, and create more market predictability.",USA,Washington State Legislature
Structure for the White Paper on AI - A European Approached [leaked],AI in general,White paper,,International - EU,12/12/2019,"<a href=""https://www.euractiv.com/wp-content/uploads/sites/2/2020/01/AI-white-paper-EURACTIV.pdf"" target=_blank>Text of leaked draft white paper</a>",,European Union,European Commission
Privacy 2030 - A New Vision for Europe,Data protection,Report,privacy; Data protection;,International - EU,11/1/2019,"<a href=""https://iapp.org/media/pdf/resource_center/giovanni_manifesto.pdf"" target=_blank>Privacy 2030 document</a>",,European Union,International Association of Privacy Professionals
AI 4 Belgium,AI in general,Strategy,,National,4/1/2019,"<a href=""https://www.ai4belgium.be/wp-content/uploads/2019/04/report_en.pdf"" target=_blank>Belgian national AI strategy</a>",,Belgium,AI4Belgium Coalition
Danish National Strategy for AI,AI in general,Strategy,,National,3/1/2019,"<a href=""https://eng.em.dk/media/13081/305755-gb-version_4k.pdf"" target=_blank>Danish national AI strategy</a>",,Denmark,Danish Government
Spanish RDI Strategy in AI,AI in general,Strategy,,National,7/22/2019,"<a href=""http://www.ciencia.gob.es/stfls/MICINN/Ciencia/Ficheros/Estrategia_Inteligencia_Artificial_EN.PDF"" target=_blank>Spanish national RDI AI strategy</a>",,Spain,"Ministry of Science, Innovation and Universities"
Artificial Intelligence: a strategic vision for Luxembourg,AI in general,Strategy,,National,5/1/2019,"<a href=""https://digital-luxembourg.public.lu/sites/default/files/2019-05/AI_EN_1.pdf"" target=_blank>Luxembourg's national AI strategy</a>",,Luxembourg,The Government of the Grand Duchy of Luxembourg
"Estonia's National AI Strategy 2019-20201",AI in general,Strategy,,National,7/1/2019,"<a href=""https://www.kratid.ee/in-english"" target=_blank>Estonia's national AI strategy</a>",,Estonia,Estonian Ministry of Economic Affairs and Communications; Estonian Government Office;
AI Portugal 2030,AI in general,Strategy,,National,6/1/2019,"<a href=""https://www.incode2030.gov.pt/sites/default/files/incode_aiportugal2030_june19.pdf"" target=_blank>Portuguese national AI strategy</a>",,Portugal,Portuguese Foundation for Science and Technology
Lithuanian Artificial Intelligence Strategy,AI in general,Strategy,,National,9/1/2019,"<a href=""http://kurklt.lt/wp-content/uploads/2018/09/StrategyIndesignpdf.pdf"" target=_blank>Lithuanian national AI strategy</a>",,Lithuania,Ministry of Economy of the Republic of Lithuania
Malta - Towards an AI Strategy - High-level policy document for public consultation,AI in general,Strategy,,National,3/1/2019,"<a href=""https://malta.ai/wp-content/uploads/2019/04/Draft_Policy_document_-_online_version.pdf"" target=_blank>Malta.AI policy document for public consultation</a>",,Malta,"Malta.AI Taskforce; Parliamentary Secretary for Financial Services, Digital Economy and Innovation - Malta"
Norwegian National Strategy for Artificial Intelligence,AI in general,Strategy,,National,1/1/2020,"<a href=""https://www.regjeringen.no/contentassets/1febbbb2c4fd4b7d92c67ddd353b6ae8/en-gb/pdfs/ki-strategi_en.pdf"" target=_blank>Norwegian AI Strategy</a>","The Norwegian AI strategy outlines the ways in which the country can reap the benefits of artificial intelligence, focusing on civilian applications in both the private and public sectors. The strategy is intended as a living document and will need to be reevaluated periodically in light of dynamic developments in the field. Furthermore, it should be considered in connection with other relevant work by the government on areas such as the digitalisation strategy, skills reform, etc.<br><br>
Norway already benefits from high levels of public trust in government and business, a highly digitised business sector,
excellent infrastructure and decades of high quality data, advanced forms of e-governance, and a cooperation between employers, unions and government. <br><br> The strategy describes that Norwegian AI should be built on ethical principles, adhere to principles of responsible and trustworthy AI, safeguard the privacy of individuals. In addition, high levels of cybersecurity protections should be embedded into AI technologies, and supervisory authorities should oversee that the technology develops in accordance with these principles. 
The government commits to advancing AI development by ""digitalisation-friendly regulations, good language resources, fast and robust communication networks, and sufficient computing power"", as well as facilitating data-sharing. <br> <br>
With regard to the regulatory environment, the government will assess where regulation impede innovation and will embed requirements for accountability and transparency in public sector uses of AI. It will support regulatory sandboxes and will specifically establish a advisory body and a regulatory sandbox for AI in the area of data protection.<br><Br>
Norway seeks to invest in areas of AI development where the country already has a competitive advantage, such as health, seas and oceans, public administration, energy and mobility. <br> <br>The strategy calls on universities to evaluate how AI-related topics can be integrated into their existing curricula, specially with regard to law and ethics. The importance reskilling and upskilling the Norwegian workforce is emphasised and there is ongoing work on creating flexible educational programmes. The strategy also expresses the government's intention to continue to participate in European and international efforts to promote responsible and trustworthy AI.",Norway,Norwegian Ministry of Local Government and Modernisation
Leading the way into the era of artificial intelligence,AI in general,Strategy,,National,6/18/2019,"<a href=""http://julkaisut.valtioneuvosto.fi/bitstream/handle/10024/161688/41_19_Leading%20the%20way%20into%20the%20age%20of%20artificial%20intelligence.pdf?sequence=4&isAllowed=y"" target=_blank>Final report of Finland's Artificial Intelligence Programme 2019</a>",,Finland,Ministry of Economic Affairs and Employment of Finland
Hungarian AI Action Plan,AI in general,Action plan,,National,10/21/2019,"<a href=""https://www.lexology.com/library/detail.aspx?g=d0882959-b5ee-46d6-95bf-13d5df70f269"" target=_blank>Summary of Hungary's AI Action Plan</a>",,Hungary,Ministry for Innovation and Technology
Artificial Intelligence in the Governance Sector in India,AI in Government,Report,,National,9/14/2018,"<a href=""https://cis-india.org/internet-governance/ai-and-governance-case-study-pdf"" target=_blank>CIS Report</a>",,India,The Centre for Internet and Society
Draft Italian National AI Strategy,AI in general,Strategy,,National,7/1/2019,"<a href=""https://www.mise.gov.it/images/stories/documenti/Strategia-Nazionale-Intelligenza-Artificiale-Bozza-Consultazione.pdf"" target=_blank>Draft Italian AI Strategy</a>",,Italy,Italian Ministry of the Economic Development
Social Principles of Human-Centric AI,AI in general,Strategy,,National,3/28/2019,"<a href=""https://www8.cao.go.jp/cstp/english/humancentricai.pdf"" target=_blank>Social Principles of Human-Centric Artificial Intellengence</a>","The social principles consist of seven principles: (1) Human-Centric; (2) Education/Literacy; (3) Privacy Protection; (4) Ensuring Security; (5) Fair Competition; (6) Fairness, Accountability and Transparency; and (7) Innovation.",Japan,Council for Social Principles of Human-centric AI
Strategy for the Development of Artificial Intelligence in the Republic of Serbia for the period 2020-2025,AI in general,Strategy,,National,1/1/2020,"<a href=""https://www.media.srbija.gov.rs/medsrp/dokumenti/strategy_artificial_intelligence.pdf"" target=_blank>Serbian AI strategy 2020-2025</a>",,Serbia,Government of Serbia
Government AI Readiness Index 2019,AI in general,Report,,International - Global,5/1/2019,"<a href=""https://ai4d.ai/wp-content/uploads/2019/05/ai-gov-readiness-report_v08.pdf"" target=_blank>Gov AI Readiness Index 2019</a>",,Global,Oxford Insights
Draft Guidelines for AI procurement,AI in Government,Guidelines,,National,9/20/2019,"<a href=""https://www.gov.uk/government/publications/draft-guidelines-for-ai-procurement"" target=_blank>Draft AI Procurement Guidelines</a>",,United Kingdom,UK Office for Artificial Intelligence
A guide to using artificial intelligence in the public sector,AI in Government,Guidelines,,National,6/10/2019,"<a href=""https://www.gov.uk/government/collections/a-guide-to-using-artificial-intelligence-in-the-public-sector"" target=_blank>UK Office for Artificial Intelligence</a>",,United Kingdom,UK Office for Artificial Intelligence
Introduction to artificial intelligence in government,AI in Government,Education,,National,1/30/2019,"<a href=""https://www.gov.uk/guidance/introduction-to-artificial-intelligence-in-government"" target=_blank>Introduction to artificial intelligence in government</a>",,United Kingdom,"UK Digital, Data and Technology Profession"
Executive Order on Maintaining American Leadership in Artificial Intelligence,AI in general,Policy,,National,2/11/2019,"<a href=""https://www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/"" target=_blank>Executive Order on AI</a>",,USA,The White House
The National Artificial Intelligence Research And Development Strategic Plan: 2019 Update,AI in general,Strategy; Report,,National,6/1/2019,"<a href=""https://www.whitehouse.gov/wp-content/uploads/2019/06/National-AI-Research-and-Development-Strategic-Plan-2019-Update-June-2019.pdf"" target=_blank>Select Committee Report on AI R&D</a>",,USA,Select Committee On Artificial Intelligence Of The National Science & Technology Council
Federal Data Strategy,Data Governance,Strategy,public sector data;,National,6/1/2019,"<a href=""https://strategy.data.gov/overview/"" target=_blank>US Federal Data Strategy</a>",,USA,US Office of Management and Budget
Federal Data Strategy 2020 Action Plan,Data Governance,Action plan,public sector data;,National,12/23/2019,"<a href=""https://strategy.data.gov/action-plan/"" target=_blank>US Federal Data Strategy 2020 Action Plan</a>",,USA,US Office of Management and Budget
2016-2019 Progress Report: Advancing Artificial Intelligence R&D,AI in general,Report,,National,11/1/2019,"<a href=""https://www.whitehouse.gov/wp-content/uploads/2019/11/AI-Research-and-Development-Progress-Report-2016-2019.pdf"" target=_blank>US 2016-2019 AI R&D Progress Report</a>",,USA,US National Science and Technology Council; US  Office of Science and Technology Policy;  Select Committee on Artificial Intelligence;  Subcommittee on Machine Learning and Artificial Intelligence;  Subcommittee on Networking & Information Technology Research & Development; Artificial Intelligence Research & Development Interagency Working Group;
With Great Tech Comes Great Responsibility,AI in general,Guidelines,,International - Global,1/1/2020,"<a href=""https://foundation.mozilla.org/en/initiatives/great-tech-great-responsibility/"" target=_blank>Mozilla Tech Responsibility Guide</a>",,Global,Mozilla Foundation
Opinion of the German Data Ethics Commission,Data Governance,Report,,National,1/10/2019,"<a href=""https://www.bmjv.de/SharedDocs/Downloads/DE/Themen/Fokusthemen/Gutachten_DEK_EN.pdf?__blob=publicationFile&v=1"" target=_blank>English summary of the Opinion of the German Data Ethics Commission</a>",,Germany,German Data Ethics Commission
Deepfake Report Act of 2019 (S.2065),Deep fakes,Bill,,National,7/1/2019,"<a href=""https://www.congress.gov/bill/116th-congress/senate-bill/2065"" target=_blank>Deepfake Report Act of 2019</a>","A bill to require the Secretary of Homeland Security to publish an annual report on the use of deepfake technology, and for other purposes. It passed the US Senate in October 2019.",USA,US Congress
Elections: deceptive audio or visual media (AB-730),Deep fakes,Bill,,National,2/19/2019,"<a href=""https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201920200AB730"" target=_blank>Text of AB-730</a>",,USA,California State Legislature
G20 Ministerial Statement on Trade and Digital Economy,AI in general,Principles,,International - Multilateral,6/9/2019,"<a href=""https://www.mofa.go.jp/files/000486596.pdf"" target=_blank>G20 Ministerial Statement</a>",,Australia; Canada; Saudi Arabia; USA; India; Russia; South Africa; Turkey; Argentina; Brazil; Mexico; France; Germany; Italy; United Kingdom; China; Indonesia; Japan; South Korea;,G20
Artificial Intelligence Video Interview Act (HB2557),Video analysis,State legislation,,National,2/13/2019,"<a href=""http://www.ilga.gov/legislation/BillStatus.asp?DocNum=2557&GAID=15&DocTypeID=HB&SessionID=108&GA=101"" target=_blank>AI Video Interview Act</a>",,USA,Illinois General Assembly
Reporting on automated decision systems used by city agencies.,Automated Decision Systems,Local law,,Regional,11/26/2019,"<a href=""https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4265421&GUID=FBA29B34-9266-4B52-B438-A772D81B1CB5&Options=&Search="" target=_blank>Local law text</a>","""This bill would require city agencies to provide information regarding every automated decision system used by the agency during the prior calendar year to the Mayor’s Office of Operations. Such information would include what each automated decision system is intended to measure or reveal and a description of the decisions made or based on such system. The Mayor’s Office of Operations would be required to compile the information received by city agencies and report it to the Mayor and the Speaker of the Council every year.""",USA,New York City Council
Artificial Intelligence Strategy of the Valencian Community,AI in general,Strategy,,Regional,2019-11-01,"<a href=""http://www.presidencia.gva.es/documents/80279719/169117420/Dossier_en.pdf/c943f4aa-2822-4c5e-a3db-63a45cca5bf5"" target=_blank>Comunitat Valenciana Artificial Intelligence Strategy</a>",,Spain,Generalitat Valenciana